# Diagnostic √âchec Ground Truth - CRITIQUE

**Date**: 2025-12-21
**Statut**: üö® **√âCHEC CRITIQUE** - Investigation en cours
**Priorit√©**: **BLOQUANT** pour d√©ploiement

---

## üö® R√©sultats Test Rapide (5 √©chantillons)

| M√©trique | R√©sultat | Cible | √âcart | Statut |
|----------|----------|-------|-------|--------|
| **Dice** | 0.8866 | 0.95 | -6.4% | üü† Moyen |
| **AJI** | 0.3091 | 0.80 | **-61%** | üî¥ **CATASTROPHIQUE** |
| **PQ** | 0.1623 | 0.70 | **-77%** | üî¥ **CATASTROPHIQUE** |
| **Pr√©cision** | 14.29% | >80% | **-66%** | üî¥ **CATASTROPHIQUE** |
| **Rappel** | 35.71% | >80% | **-44%** | üî¥ **CRITIQUE** |

### D√©tection

```
TP:   5  (vrais positifs)
FP:  30  (faux positifs) ‚Üê 6x plus de FP que de TP !
FN:   9  (faux n√©gatifs)

Pr√©cision: 5/(5+30) = 14.29%  ‚Üê Le mod√®le d√©tecte 86% de fausses instances
Rappel:    5/(5+9)  = 35.71%  ‚Üê Le mod√®le manque 64% des vraies instances
```

### Type Cellulaire (Exemple le plus flagrant)

```
Epithelial:
  Expert annot√©es:  9 cellules
  Mod√®le d√©tecte:  31 cellules  ‚Üê 3.4x sur-d√©tection !
```

---

## üî¨ Hypoth√®ses (Par Ordre de Probabilit√©)

### 1. üéØ Watershed Post-Processing D√©faillant (90% probable)

**Sympt√¥mes** :
- FP = 30 (6x plus de fausses instances que de vraies)
- Sur-d√©tection massive Epithelial (9 ‚Üí 31)

**Cause probable** : Seuils watershed trop permissifs cr√©ent trop de seeds

**Param√®tres actuels** (`src/inference/hoptimus_hovernet.py:211-216`) :
```python
markers[edge > 0.3] = 0  # Supprimer bords (gradient HV)
markers = (markers > 0.7).astype(np.uint8)  # Seuil NP prob
markers = ndimage.label(markers * (dist > 2))[0]  # Distance seeds
```

**Probl√®mes potentiels** :
- `edge > 0.3` : **Trop permissif** ? (devrait √™tre 0.5-0.7 pour fronti√®res nettes)
- `dist > 2` : **Distance minimale trop faible** ‚Üí Trop de seeds cr√©√©s
- R√©sultat : Chaque petit pic de probabilit√© NP cr√©e une instance

**Test √† faire** :
```python
# Essayer des seuils plus stricts
markers[edge > 0.5] = 0  # Au lieu de 0.3
markers = ndimage.label(markers * (dist > 5))[0]  # Au lieu de 2
```

### 2. üß™ Compute_HV_Maps() Incorrect (50% probable)

**Sympt√¥me** : Les m√©triques d'entra√Ænement √©taient bonnes (HV MSE 0.01-0.06), mais √©valuation GT catastrophique

**Cause possible** : Les targets HV pendant l'entra√Ænement ne correspondent pas aux vraies fronti√®res d'instances

**√Ä v√©rifier** :
- Est-ce que `compute_hv_maps()` utilise les **vrais IDs d'instances** de PanNuke ?
- Ou est-ce qu'on recalcule avec `connectedComponents` qui fusionne les cellules qui se touchent ?

**Code √† inspecter** (`scripts/preprocessing/prepare_family_data_FIXED.py`) :
```python
# Si on fait √ßa, c'est FAUX:
_, labels = cv2.connectedComponents(binary_mask)  # Fusionne cellules touchantes
hv_targets = compute_hv_maps(labels)  # HV maps avec instances FUSIONN√âES

# Il faut faire √ßa:
inst_map = extract_true_instance_ids_from_pannuke(mask)  # IDs r√©els
hv_targets = compute_hv_maps(inst_map)  # HV maps avec vraies fronti√®res
```

### 3. üìè R√©solution Mismatch (30% probable)

**Sympt√¥me** : Resize 224‚Üí256 pendant l'√©valuation

**Cause possible** : L'interpolation bilin√©aire floute les gradients HV pr√©cis

**Test** :
- √âvaluer directement √† 224√ó224 (sans resize)
- Ou utiliser INTER_NEAREST pour pr√©server les gradients

### 4. üóÇÔ∏è Conversion Annotations GT Incorrecte (20% probable)

**Sympt√¥me** : Peut-√™tre que le script `convert_annotations.py` ne produit pas le bon format

**√Ä v√©rifier** :
- Les `inst_map` dans les .npz ont-ils des IDs d'instances corrects ?
- Y a-t-il des instances fusionn√©es par erreur ?

---

## üõ†Ô∏è Plan d'Investigation (Ordre de Priorit√©)

### √âtape 1: Diagnostic Visuel (URGENT - 10 min)

```bash
# Lancer diagnostic sur une image
python scripts/evaluation/diagnose_gt_failure.py \
    --npz_file <PREMIER_FICHIER_NPZ_DU_TEST> \
    --checkpoint_dir models/checkpoints_FIXED \
    --output_dir results/diagnostic_gt

# Examiner visuellement:
# - Les gradients HV sont-ils suffisamment forts ?
# - Y a-t-il trop de seeds de watershed ?
# - Les instances GT sont-elles correctes ?
```

**Fichier attendu** : `results/diagnostic_gt/diagnostic_*.png`

### √âtape 2: Test Watershed Thresholds (30 min)

```bash
# Cr√©er script test_watershed_thresholds.py
# Essayer diff√©rentes combinaisons:
#   - edge_threshold: [0.3, 0.4, 0.5, 0.6, 0.7]
#   - dist_threshold: [2, 3, 5, 7, 10]

# Trouver meilleure combinaison qui:
#   - R√©duit FP (actuellement 30)
#   - Am√©liore Rappel (actuellement 35%)
#   - Augmente AJI (actuellement 0.31)
```

### √âtape 3: V√©rifier Compute_HV_Maps() (1h)

```bash
# Inspecter scripts/preprocessing/prepare_family_data_FIXED.py
# Comparer avec masks PanNuke originaux
# V√©rifier si on utilise les vrais IDs d'instances ou connectedComponents
```

**Si bug trouv√©** : R√©-entra√Ænement complet requis (~10h)

### √âtape 4: Test Sans Resize (15 min)

```bash
# Modifier evaluate_ground_truth.py
# √âvaluer √† r√©solution native 224√ó224
# Comparer m√©triques
```

---

## üìä Disconnect Train vs GT

**Observation cl√©** :

| Phase | NP Dice | HV MSE | NT Acc | Statut |
|-------|---------|--------|--------|--------|
| **Training (Glandular)** | 0.9641 | 0.0105 | 0.9107 | ‚úÖ Excellent |
| **Validation (10 samples)** | 0.9655 | 0.0266 | 0.9517 | ‚úÖ Excellent |
| **Ground Truth (5 samples)** | 0.8866 | ? | ? | ‚ùå Catastrophe |

**Pourquoi ce disconnect ?**

1. **Training/Validation** : Compare pr√©dictions vs targets g√©n√©r√©s par `prepare_family_data_FIXED.py`
2. **Ground Truth** : Compare pr√©dictions vs annotations expertes PanNuke originales

**Si `compute_hv_maps()` est incorrect** :
- Le mod√®le apprend correctement les targets incorrects ‚Üí Bonnes m√©triques train/val
- Mais les pr√©dictions ne matchent pas les annotations expertes ‚Üí Mauvaises m√©triques GT

---

## üéØ Crit√®res de Succ√®s (Post-Fix)

### Minimaux (GO)

| M√©trique | Cible | Actuel | Requis |
|----------|-------|--------|--------|
| Dice | 0.95 | 0.8866 | > 0.93 |
| AJI | 0.80 | 0.3091 | > 0.70 |
| PQ | 0.70 | 0.1623 | > 0.60 |
| Pr√©cision | >80% | 14.29% | > 70% |
| Rappel | >80% | 35.71% | > 70% |

### Id√©aux (EXCELLENT)

| M√©trique | Valeur |
|----------|--------|
| Dice | > 0.95 |
| AJI | > 0.75 |
| PQ | > 0.65 |
| Pr√©cision | > 85% |
| Rappel | > 85% |

---

## üìù Actions Imm√©diates

1. **[USER]** Lancer diagnostic visuel :
   ```bash
   # Trouver premi√®re image test
   find /home/amar/data -name "*.npz" | grep -i pannuke | head -1

   # Lancer diagnostic
   python scripts/evaluation/diagnose_gt_failure.py --npz_file <PATH>
   ```

2. **[CLAUDE]** Cr√©er script test watershed thresholds

3. **[USER]** Partager image diagnostic pour analyse visuelle

4. **[CLAUDE]** Selon diagnostic, proposer fix appropri√©

---

## ‚ö†Ô∏è Impact sur le Projet

**Si Watershed Fix Suffit** : ~30 min
- Ajuster seuils
- Re-tester GT
- D√©ployer si OK

**Si Compute_HV_Maps Bug** : ~10h
- Corriger preprocessing
- R√©-entra√Æner 5 familles
- Re-tester GT

**Si Probl√®me Fondamental Architecture** : ~1 semaine
- Revoir HoVer-Net decoder
- R√©-entra√Æner
- Valider

---

**Cr√©√© le** : 2025-12-21
**Par** : Claude (Investigation √©chec GT)
**Statut** : üö® INVESTIGATION EN COURS
**Priorit√©** : **BLOQUANT**
