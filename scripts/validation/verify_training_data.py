#!/usr/bin/env python3
"""
VÃ©rifie quelles donnÃ©es ont Ã©tÃ© utilisÃ©es pour l'entraÃ®nement actuel.

Objectif: DÃ©terminer si FIXED (instances sÃ©parÃ©es) ou OLD (connectedComponents)

Usage:
    python scripts/validation/verify_training_data.py \
        --checkpoint models/checkpoints/hovernet_glandular_best.pth
"""

import argparse
import numpy as np
import torch
from pathlib import Path
import sys

sys.path.insert(0, str(Path(__file__).parent.parent.parent))


def check_data_files():
    """Cherche et analyse les fichiers de donnÃ©es disponibles."""
    print(f"\n{'='*70}")
    print(f"VÃ‰RIFICATION DES DONNÃ‰ES D'ENTRAÃNEMENT")
    print(f"{'='*70}\n")

    # Chercher fichiers de donnÃ©es
    data_patterns = [
        "data/cache/family_data/*.npz",
        "data/cache/family_data_FIXED/*.npz",
        "data/cache/family_data_OLD*/*.npz",
        "data/family_data/*.npz",
        "data/*/glandular*.npz",
        "data/*/digestive*.npz",
    ]

    found_files = []
    for pattern in data_patterns:
        files = list(Path(".").glob(pattern))
        found_files.extend(files)

    if not found_files:
        print("âŒ Aucun fichier de donnÃ©es trouvÃ©!")
        print("\nğŸ’¡ Suggestions:")
        print("   1. Les donnÃ©es sont peut-Ãªtre ailleurs sur le systÃ¨me")
        print("   2. VÃ©rifier dans ~/data/ ou /mnt/data/")
        print("   3. VÃ©rifier les logs d'entraÃ®nement pour le chemin exact")
        return None

    print(f"âœ… {len(found_files)} fichier(s) de donnÃ©es trouvÃ©(s):\n")
    for f in found_files:
        size_mb = f.stat().st_size / (1024*1024)
        print(f"   ğŸ“ {f}")
        print(f"      Taille: {size_mb:.1f} MB")
        print()

    return found_files


def analyze_data_file(data_file: Path, n_samples: int = 10):
    """Analyse un fichier de donnÃ©es pour dÃ©tecter FIXED vs OLD."""
    print(f"\n{'='*70}")
    print(f"ANALYSE: {data_file.name}")
    print(f"{'='*70}\n")

    try:
        data = np.load(data_file)
        print(f"ğŸ“‹ ClÃ©s disponibles: {list(data.keys())}\n")

        # VÃ©rifier prÃ©sence de hv_targets
        if 'hv_targets' not in data:
            print("âŒ Pas de 'hv_targets' trouvÃ©!")
            return

        hv_targets = data['hv_targets']
        print(f"ğŸ“Š HV Targets:")
        print(f"   Shape: {hv_targets.shape}")
        print(f"   Dtype: {hv_targets.dtype}")
        print(f"   Min: {hv_targets.min():.4f}")
        print(f"   Max: {hv_targets.max():.4f}")
        print(f"   Mean: {hv_targets.mean():.4f}")
        print(f"   Std: {hv_targets.std():.4f}")

        # VÃ©rifier la normalisation HV
        print(f"\nğŸ” VÃ©rification Normalisation HV:")
        if hv_targets.dtype == np.int8:
            print(f"   âŒ PROBLÃˆME: dtype int8 (devrait Ãªtre float32)")
            print(f"   âŒ Range [-127, 127] au lieu de [-1, 1]")
            print(f"   â†’ BUG: Anciennes donnÃ©es avec int8!")
            verdict = "OLD (int8 bug)"
        elif hv_targets.min() >= -1.1 and hv_targets.max() <= 1.1:
            print(f"   âœ… Range [-1, 1] correct (float32)")
            verdict = "FIXED (float32)"
        else:
            print(f"   âš ï¸  Range anormal: [{hv_targets.min():.2f}, {hv_targets.max():.2f}]")
            verdict = "INCERTAIN"

        # Analyser les instances
        if 'np_masks' in data:
            np_masks = data['np_masks']
            print(f"\nğŸ“Š NP Masks:")
            print(f"   Shape: {np_masks.shape}")

            # Compter instances par image (Ã©chantillon)
            n_to_check = min(n_samples, len(np_masks))
            inst_counts = []

            for i in range(n_to_check):
                np_mask = np_masks[i]
                # Si np_mask est binaire, on ne peut pas compter les instances
                # Si np_mask a des IDs, on peut
                unique_vals = np.unique(np_mask)
                n_instances = len(unique_vals) - 1  # -1 pour background

                if np_mask.max() <= 1:
                    # Binaire - on ne peut pas conclure
                    inst_counts.append(-1)
                else:
                    inst_counts.append(n_instances)

            valid_counts = [c for c in inst_counts if c > 0]
            if valid_counts:
                mean_inst = np.mean(valid_counts)
                print(f"\nğŸ“Š Instances par image (Ã©chantillon {n_to_check}):")
                print(f"   Moyenne: {mean_inst:.1f}")
                print(f"   Min: {min(valid_counts)}")
                print(f"   Max: {max(valid_counts)}")

                if mean_inst > 40:
                    print(f"   âœ… {mean_inst:.0f} instances/image â†’ FIXED (instances sÃ©parÃ©es)")
                    verdict += " + instances sÃ©parÃ©es"
                elif mean_inst < 20:
                    print(f"   âŒ {mean_inst:.0f} instances/image â†’ OLD (fusionnÃ©es)")
                    verdict += " + instances fusionnÃ©es"
            else:
                print(f"   âš ï¸  NP masks sont binaires, impossible de compter instances")

        print(f"\nğŸ¯ VERDICT: {verdict}")

    except Exception as e:
        print(f"âŒ Erreur lors de l'analyse: {e}")


def check_training_logs():
    """Cherche les logs d'entraÃ®nement pour trouver le chemin des donnÃ©es."""
    print(f"\n{'='*70}")
    print(f"RECHERCHE LOGS D'ENTRAÃNEMENT")
    print(f"{'='*70}\n")

    log_patterns = [
        "logs/*.log",
        "logs/training/*.log",
        "results/**/training.log",
        "*.log",
    ]

    found_logs = []
    for pattern in log_patterns:
        logs = list(Path(".").glob(pattern))
        found_logs.extend(logs)

    if not found_logs:
        print("âŒ Aucun log d'entraÃ®nement trouvÃ©")
        return

    print(f"âœ… {len(found_logs)} log(s) trouvÃ©(s)\n")

    # Chercher mentions de data path dans les logs
    for log_file in found_logs[:5]:  # Limiter Ã  5 pour ne pas surcharger
        try:
            with open(log_file, 'r') as f:
                content = f.read()
                if 'data' in content.lower():
                    print(f"ğŸ“„ {log_file}")
                    # Extraire lignes avec 'data'
                    lines = content.split('\n')
                    data_lines = [l for l in lines if 'data' in l.lower() or 'family' in l.lower()][:3]
                    for line in data_lines:
                        print(f"   {line[:100]}")
                    print()
        except:
            pass


def check_checkpoint_metadata(checkpoint_path: Path):
    """VÃ©rifie les mÃ©tadonnÃ©es du checkpoint."""
    print(f"\n{'='*70}")
    print(f"ANALYSE CHECKPOINT: {checkpoint_path.name}")
    print(f"{'='*70}\n")

    if not checkpoint_path.exists():
        print(f"âŒ Checkpoint introuvable: {checkpoint_path}")
        return

    try:
        checkpoint = torch.load(checkpoint_path, map_location='cpu')

        print(f"ğŸ“‹ ClÃ©s du checkpoint: {list(checkpoint.keys())}\n")

        # VÃ©rifier mÃ©tadonnÃ©es
        if 'metadata' in checkpoint:
            meta = checkpoint['metadata']
            print(f"ğŸ“Š MÃ©tadonnÃ©es:")
            for key, val in meta.items():
                print(f"   {key}: {val}")

        # VÃ©rifier epoch, metrics
        if 'epoch' in checkpoint:
            print(f"\nğŸ“Š Training Info:")
            print(f"   Epoch: {checkpoint['epoch']}")

        if 'metrics' in checkpoint:
            print(f"\nğŸ“Š Metrics:")
            for key, val in checkpoint['metrics'].items():
                print(f"   {key}: {val:.4f}")

        # VÃ©rifier si le checkpoint contient des infos sur les donnÃ©es
        keys_to_check = ['data_path', 'data_version', 'preprocessing', 'family']
        for key in keys_to_check:
            if key in checkpoint:
                print(f"\nğŸ” {key}: {checkpoint[key]}")

    except Exception as e:
        print(f"âŒ Erreur lors de la lecture du checkpoint: {e}")


def main():
    parser = argparse.ArgumentParser(
        description="VÃ©rifie quelles donnÃ©es ont Ã©tÃ© utilisÃ©es pour l'entraÃ®nement"
    )
    parser.add_argument(
        '--checkpoint',
        type=Path,
        help='Chemin vers un checkpoint Ã  analyser'
    )
    parser.add_argument(
        '--data_file',
        type=Path,
        help='Chemin vers un fichier de donnÃ©es Ã  analyser'
    )
    parser.add_argument(
        '--n_samples',
        type=int,
        default=10,
        help='Nombre d\'Ã©chantillons Ã  analyser (default: 10)'
    )

    args = parser.parse_args()

    # 1. Chercher fichiers de donnÃ©es
    data_files = check_data_files()

    # 2. Si un fichier spÃ©cifique fourni, l'analyser
    if args.data_file:
        analyze_data_file(args.data_file, args.n_samples)
    elif data_files:
        # Analyser le premier fichier trouvÃ©
        analyze_data_file(data_files[0], args.n_samples)

    # 3. Chercher logs d'entraÃ®nement
    check_training_logs()

    # 4. Si checkpoint fourni, l'analyser
    if args.checkpoint:
        check_checkpoint_metadata(args.checkpoint)

    print(f"\n{'='*70}")
    print(f"RÃ‰SUMÃ‰")
    print(f"{'='*70}\n")
    print("Pour confirmer, vÃ©rifier:")
    print("  1. Les scripts d'entraÃ®nement utilisÃ©s (train_hovernet_family.py)")
    print("  2. Les logs d'entraÃ®nement pour le data_path exact")
    print("  3. Comparer avec prepare_family_data.py vs prepare_family_data_FIXED.py")
    print()


if __name__ == '__main__':
    main()
