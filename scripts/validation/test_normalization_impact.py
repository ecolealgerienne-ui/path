#!/usr/bin/env python3
"""
Test l'impact de la normalisation (H-optimus-0 vs ImageNet) sur CLS std.

L'expert suspecte que:
- Training features: std=0.82 (avec une certaine normalisation)
- Inference features: std=0.66 (avec une autre normalisation)

Ce script teste les DEUX normalisations pour identifier laquelle √©tait utilis√©e au training.
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

import numpy as np
import torch
from torchvision import transforms
from src.models.loader import ModelLoader

# Normalisations √† tester
NORMALIZATIONS = {
    "H-optimus-0": {
        "mean": (0.707223, 0.578729, 0.703617),
        "std": (0.211883, 0.230117, 0.177517),
    },
    "ImageNet": {
        "mean": (0.485, 0.456, 0.406),
        "std": (0.229, 0.224, 0.225),
    },
}


def create_transform(norm_name: str):
    """Cr√©e transform avec normalisation sp√©cifi√©e."""
    norm = NORMALIZATIONS[norm_name]
    return transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=norm["mean"], std=norm["std"]),
    ])


def test_normalization(image: np.ndarray, norm_name: str, backbone):
    """Teste une normalisation et retourne CLS std."""
    transform = create_transform(norm_name)

    # Pr√©traitement
    if image.dtype != np.uint8:
        image = image.clip(0, 255).astype(np.uint8)

    tensor = transform(image).unsqueeze(0).to("cuda")

    # Extraction features
    with torch.no_grad():
        features = backbone.forward_features(tensor)

    # CLS token
    cls_token = features[:, 0, :].cpu().numpy()
    cls_std = cls_token.std()

    return cls_std, features


def main():
    print("=" * 70)
    print("TEST NORMALISATION: H-optimus-0 vs ImageNet")
    print("=" * 70)

    # Charger mod√®le
    print("\nüîß Chargement H-optimus-0...")
    backbone = ModelLoader.load_hoptimus0(device="cuda")

    # Charger une image de test
    print("üì∏ Chargement image test...")
    # Utiliser une des images de fold2 samples si disponible
    try:
        sample_path = Path("data/temp_fold2_samples/sample_00000.npz")
        if sample_path.exists():
            data = np.load(sample_path)
            image = data['image']
            print(f"   ‚úì Image charg√©e: {image.shape}, dtype={image.dtype}")
        else:
            # Cr√©er une image synth√©tique si pas de sample
            print("   ‚ö†Ô∏è Pas de sample trouv√©, cr√©ation image synth√©tique")
            image = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)
    except Exception as e:
        print(f"   ‚ö†Ô∏è Erreur chargement: {e}")
        print("   Cr√©ation image synth√©tique")
        image = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)

    # Tester les deux normalisations
    print("\n" + "=" * 70)
    print("R√âSULTATS")
    print("=" * 70)

    results = {}
    for norm_name in ["H-optimus-0", "ImageNet"]:
        print(f"\nüìä Test avec normalisation {norm_name}")
        print(f"   Mean: {NORMALIZATIONS[norm_name]['mean']}")
        print(f"   Std:  {NORMALIZATIONS[norm_name]['std']}")

        cls_std, features = test_normalization(image, norm_name, backbone)
        results[norm_name] = cls_std

        print(f"\n   ‚ûú CLS token std: {cls_std:.4f}")

        # Interpr√©ter
        if 0.70 <= cls_std <= 0.90:
            print(f"   ‚úÖ DANS PLAGE ATTENDUE [0.70, 0.90]")
        elif cls_std < 0.40:
            print(f"   ‚ùå TROP BAS (< 0.40) - LayerNorm manquant?")
        else:
            print(f"   ‚ö†Ô∏è HORS PLAGE [0.70, 0.90]")

        # Comparer avec valeurs connues
        if abs(cls_std - 0.82) < 0.05:
            print(f"   üéØ PROCHE de 0.82 (valeur training suppos√©e)")
        if abs(cls_std - 0.66) < 0.05:
            print(f"   üéØ PROCHE de 0.66 (valeur inference mesur√©e)")

    # Recommandation
    print("\n" + "=" * 70)
    print("RECOMMANDATION")
    print("=" * 70)

    if abs(results["H-optimus-0"] - 0.82) < abs(results["ImageNet"] - 0.82):
        print("\n‚úÖ H-optimus-0 normalisation semble correcte pour training")
        print(f"   CLS std: {results['H-optimus-0']:.4f} (proche de 0.82)")
    else:
        print("\n‚ö†Ô∏è ImageNet normalisation plus proche de training (std=0.82)")
        print(f"   CLS std: {results['ImageNet']:.4f}")
        print("\n   ‚ö†Ô∏è ATTENTION: H-optimus-0 est cens√© utiliser ses propres constantes!")
        print("   Cela sugg√®re que les features de training ont √©t√© g√©n√©r√©es")
        print("   avec une normalisation incorrecte.")

    if abs(results["H-optimus-0"] - 0.66) < 0.05:
        print(f"\n‚ö†Ô∏è Inference actuelle donne std={results['H-optimus-0']:.4f} (proche de 0.66)")
        print("   Cela correspond √† l'alerte 'Features SUSPECTES' observ√©e.")

    print("\n" + "=" * 70)
    print(f"H-optimus-0: {results['H-optimus-0']:.4f}")
    print(f"ImageNet:    {results['ImageNet']:.4f}")
    print(f"Diff:        {abs(results['H-optimus-0'] - results['ImageNet']):.4f}")
    print("=" * 70)


if __name__ == "__main__":
    main()
