#!/usr/bin/env python3
"""
V√©rification des donn√©es V13 Smart Crops.

Ce script v√©rifie que les donn√©es ont √©t√© g√©n√©r√©es avec les fixes critiques:
1. LOCAL relabeling (pas de collision d'IDs)
2. HV rotation mathematics correcte (vecteurs pointent vers l'int√©rieur)
3. HV targets en float32 [-1, 1] (pas int8)
4. inst_maps pr√©sents et valides

Usage:
    python scripts/validation/verify_v13_smart_crops_data.py --family epidermal
    python scripts/validation/verify_v13_smart_crops_data.py --data_file path/to/data.npz
"""

import argparse
import numpy as np
from pathlib import Path
from scipy.ndimage import sobel
import sys


def compute_hv_divergence(hv_map: np.ndarray, np_mask: np.ndarray) -> float:
    """
    Calcule la divergence des vecteurs HV sur les pixels de noyaux.

    Si les vecteurs HV pointent vers l'INT√âRIEUR des noyaux (correct),
    la divergence doit √™tre N√âGATIVE.

    Si la divergence est positive, les vecteurs pointent vers l'ext√©rieur
    (bug de rotation HV).

    Args:
        hv_map: (2, H, W) H et V components
        np_mask: (H, W) masque binaire des noyaux

    Returns:
        Divergence moyenne sur les pixels de noyaux
    """
    h_map = hv_map[0]  # Horizontal component
    v_map = hv_map[1]  # Vertical component

    # Gradient de H selon x, gradient de V selon y
    dh_dx = sobel(h_map, axis=1, mode='constant')
    dv_dy = sobel(v_map, axis=0, mode='constant')

    # Divergence = dH/dx + dV/dy
    divergence = dh_dx + dv_dy

    # Moyenne sur les pixels de noyaux uniquement
    mask = np_mask > 0.5
    if mask.sum() == 0:
        return 0.0

    return divergence[mask].mean()


def check_inst_map_ids(inst_map: np.ndarray) -> dict:
    """
    V√©rifie les IDs dans inst_map pour d√©tecter les collisions.

    LOCAL relabeling correct: IDs s√©quentiels [0, 1, 2, 3, ...]
    Bug collision: IDs non s√©quentiels ou gaps

    Returns:
        {
            'n_instances': int,
            'unique_ids': list,
            'is_sequential': bool,
            'has_gaps': bool,
            'max_id': int
        }
    """
    unique_ids = np.unique(inst_map)
    unique_ids = unique_ids[unique_ids > 0]  # Exclure background (0)

    n_instances = len(unique_ids)

    if n_instances == 0:
        return {
            'n_instances': 0,
            'unique_ids': [],
            'is_sequential': True,
            'has_gaps': False,
            'max_id': 0
        }

    expected_ids = set(range(1, n_instances + 1))
    actual_ids = set(unique_ids.tolist())

    is_sequential = (actual_ids == expected_ids)
    has_gaps = (max(unique_ids) > n_instances)

    return {
        'n_instances': n_instances,
        'unique_ids': sorted(unique_ids.tolist()),
        'is_sequential': is_sequential,
        'has_gaps': has_gaps,
        'max_id': int(max(unique_ids))
    }


def verify_hv_targets(hv_targets: np.ndarray) -> dict:
    """
    V√©rifie le format des HV targets.

    Correct: float32, range [-1, 1]
    Bug #3: int8, range [-127, 127]

    Returns:
        {
            'dtype': str,
            'min': float,
            'max': float,
            'is_float32': bool,
            'is_correct_range': bool,
            'is_bug3': bool
        }
    """
    dtype_str = str(hv_targets.dtype)
    min_val = float(hv_targets.min())
    max_val = float(hv_targets.max())

    is_float32 = (hv_targets.dtype == np.float32)
    is_correct_range = (-1.5 <= min_val <= 0) and (0 <= max_val <= 1.5)
    is_bug3 = (hv_targets.dtype == np.int8) or (abs(min_val) > 10 or abs(max_val) > 10)

    return {
        'dtype': dtype_str,
        'min': min_val,
        'max': max_val,
        'is_float32': is_float32,
        'is_correct_range': is_correct_range,
        'is_bug3': is_bug3
    }


def verify_data_file(data_path: Path, n_samples: int = 10, verbose: bool = True) -> dict:
    """
    V√©rifie un fichier de donn√©es V13 Smart Crops.

    Args:
        data_path: Chemin vers le fichier .npz
        n_samples: Nombre d'√©chantillons √† v√©rifier
        verbose: Afficher les d√©tails

    Returns:
        Dictionnaire avec r√©sultats de v√©rification
    """
    if not data_path.exists():
        return {'error': f"Fichier non trouv√©: {data_path}"}

    print(f"\n{'='*70}")
    print(f"V√âRIFICATION: {data_path.name}")
    print(f"{'='*70}\n")

    # Charger les donn√©es
    data = np.load(data_path, allow_pickle=True)

    available_keys = list(data.keys())
    print(f"Cl√©s disponibles: {available_keys}")

    results = {
        'file': str(data_path),
        'keys': available_keys,
        'checks': {}
    }

    # 1. V√©rifier HV targets
    print(f"\n{'‚îÄ'*50}")
    print("1. V√âRIFICATION HV TARGETS")
    print(f"{'‚îÄ'*50}")

    if 'hv_targets' in data:
        hv_targets = data['hv_targets']
        print(f"   Shape: {hv_targets.shape}")

        hv_check = verify_hv_targets(hv_targets)
        results['checks']['hv_targets'] = hv_check

        if hv_check['is_float32'] and hv_check['is_correct_range']:
            print(f"   ‚úÖ Dtype: {hv_check['dtype']} (correct)")
            print(f"   ‚úÖ Range: [{hv_check['min']:.4f}, {hv_check['max']:.4f}] (correct)")
        elif hv_check['is_bug3']:
            print(f"   ‚ùå BUG #3 D√âTECT√â!")
            print(f"   ‚ùå Dtype: {hv_check['dtype']} (devrait √™tre float32)")
            print(f"   ‚ùå Range: [{hv_check['min']:.4f}, {hv_check['max']:.4f}] (devrait √™tre [-1, 1])")
        else:
            print(f"   ‚ö†Ô∏è Dtype: {hv_check['dtype']}")
            print(f"   ‚ö†Ô∏è Range: [{hv_check['min']:.4f}, {hv_check['max']:.4f}]")
    else:
        print("   ‚ö†Ô∏è Cl√© 'hv_targets' non trouv√©e")
        results['checks']['hv_targets'] = {'error': 'key not found'}

    # 2. V√©rifier inst_maps (LOCAL relabeling)
    print(f"\n{'‚îÄ'*50}")
    print("2. V√âRIFICATION INST_MAPS (LOCAL relabeling)")
    print(f"{'‚îÄ'*50}")

    if 'inst_maps' in data:
        inst_maps = data['inst_maps']
        print(f"   Shape: {inst_maps.shape}")

        # V√©rifier quelques √©chantillons
        n_to_check = min(n_samples, len(inst_maps))
        sequential_count = 0
        collision_samples = []

        for i in range(n_to_check):
            inst_check = check_inst_map_ids(inst_maps[i])
            if inst_check['is_sequential']:
                sequential_count += 1
            else:
                collision_samples.append({
                    'index': i,
                    'n_instances': inst_check['n_instances'],
                    'max_id': inst_check['max_id'],
                    'unique_ids': inst_check['unique_ids'][:10]  # Premiers 10
                })

        results['checks']['inst_maps'] = {
            'sequential_count': sequential_count,
            'total_checked': n_to_check,
            'collision_samples': collision_samples
        }

        if sequential_count == n_to_check:
            print(f"   ‚úÖ {sequential_count}/{n_to_check} √©chantillons avec IDs s√©quentiels")
            print(f"   ‚úÖ LOCAL relabeling correctement appliqu√©")
        else:
            print(f"   ‚ùå {n_to_check - sequential_count}/{n_to_check} √©chantillons avec COLLISIONS")
            print(f"   ‚ùå LOCAL relabeling NON appliqu√© ou bugg√©")
            if collision_samples:
                print(f"   ‚ùå Exemple collision (sample {collision_samples[0]['index']}):")
                print(f"      n_instances={collision_samples[0]['n_instances']}, max_id={collision_samples[0]['max_id']}")
    else:
        print("   ‚ö†Ô∏è Cl√© 'inst_maps' non trouv√©e")
        print("   ‚ö†Ô∏è Les inst_maps sont REQUIS pour √©valuation AJI correcte!")
        results['checks']['inst_maps'] = {'error': 'key not found'}

    # 3. V√©rifier divergence HV (rotation math)
    print(f"\n{'‚îÄ'*50}")
    print("3. V√âRIFICATION DIVERGENCE HV (rotation math)")
    print(f"{'‚îÄ'*50}")

    if 'hv_targets' in data and 'np_targets' in data:
        hv_targets = data['hv_targets']
        np_targets = data['np_targets']

        n_to_check = min(n_samples, len(hv_targets))
        divergences = []
        negative_count = 0

        for i in range(n_to_check):
            div = compute_hv_divergence(hv_targets[i], np_targets[i])
            divergences.append(div)
            if div < 0:
                negative_count += 1

        mean_div = np.mean(divergences)

        results['checks']['hv_divergence'] = {
            'mean_divergence': float(mean_div),
            'negative_count': negative_count,
            'total_checked': n_to_check,
            'divergences': divergences
        }

        if negative_count == n_to_check and mean_div < 0:
            print(f"   ‚úÖ Divergence moyenne: {mean_div:.4f} (n√©gative = correct)")
            print(f"   ‚úÖ {negative_count}/{n_to_check} √©chantillons avec divergence n√©gative")
            print(f"   ‚úÖ Rotation HV math correcte (vecteurs pointent vers l'int√©rieur)")
        elif mean_div > 0:
            print(f"   ‚ùå Divergence moyenne: {mean_div:.4f} (POSITIVE = BUG!)")
            print(f"   ‚ùå Seulement {negative_count}/{n_to_check} √©chantillons corrects")
            print(f"   ‚ùå BUG ROTATION HV: Vecteurs pointent vers l'EXT√âRIEUR!")
        else:
            print(f"   ‚ö†Ô∏è Divergence moyenne: {mean_div:.4f}")
            print(f"   ‚ö†Ô∏è {negative_count}/{n_to_check} √©chantillons avec divergence n√©gative")
    else:
        print("   ‚ö†Ô∏è Cl√©s 'hv_targets' ou 'np_targets' non trouv√©es")
        results['checks']['hv_divergence'] = {'error': 'keys not found'}

    # 4. V√©rifier coh√©rence shapes
    print(f"\n{'‚îÄ'*50}")
    print("4. V√âRIFICATION COH√âRENCE SHAPES")
    print(f"{'‚îÄ'*50}")

    shapes = {}
    for key in ['images', 'np_targets', 'hv_targets', 'nt_targets', 'inst_maps']:
        if key in data:
            shapes[key] = data[key].shape
            print(f"   {key}: {data[key].shape}")

    results['shapes'] = shapes

    # V√©rifier coh√©rence
    n_samples_list = [s[0] for s in shapes.values()]
    if len(set(n_samples_list)) == 1:
        print(f"   ‚úÖ Toutes les arrays ont {n_samples_list[0]} √©chantillons")
    else:
        print(f"   ‚ùå INCOH√âRENCE: Nombres d'√©chantillons diff√©rents!")

    # 5. R√©sum√©
    print(f"\n{'='*70}")
    print("R√âSUM√â")
    print(f"{'='*70}")

    all_ok = True

    # HV targets check
    hv_ok = results['checks'].get('hv_targets', {}).get('is_float32', False) and \
            results['checks'].get('hv_targets', {}).get('is_correct_range', False)
    if hv_ok:
        print("‚úÖ HV targets: float32 [-1, 1]")
    else:
        print("‚ùå HV targets: PROBL√àME D√âTECT√â")
        all_ok = False

    # inst_maps check
    inst_ok = 'inst_maps' in data and \
              results['checks'].get('inst_maps', {}).get('sequential_count', 0) == \
              results['checks'].get('inst_maps', {}).get('total_checked', 0)
    if inst_ok:
        print("‚úÖ inst_maps: LOCAL relabeling OK")
    elif 'inst_maps' not in data:
        print("‚ùå inst_maps: MANQUANTS (requis pour AJI)")
        all_ok = False
    else:
        print("‚ùå inst_maps: COLLISIONS D√âTECT√âES")
        all_ok = False

    # HV divergence check
    div_ok = results['checks'].get('hv_divergence', {}).get('mean_divergence', 1) < 0
    if div_ok:
        print("‚úÖ HV divergence: Rotation math OK")
    else:
        print("‚ùå HV divergence: BUG ROTATION")
        all_ok = False

    print(f"\n{'='*70}")
    if all_ok:
        print("üéâ VERDICT: Donn√©es V13 Smart Crops VALIDES")
        print("   Pr√™tes pour entra√Ænement avec les fixes critiques.")
    else:
        print("‚ö†Ô∏è VERDICT: Donn√©es V13 Smart Crops INVALIDES")
        print("   R√©g√©n√©rer avec: python scripts/preprocessing/prepare_v13_smart_crops.py")
    print(f"{'='*70}\n")

    results['all_ok'] = all_ok
    return results


def main():
    parser = argparse.ArgumentParser(description="V√©rifier les donn√©es V13 Smart Crops")
    parser.add_argument("--family", type=str, default="epidermal",
                        help="Famille √† v√©rifier (epidermal, glandular, etc.)")
    parser.add_argument("--data_file", type=str, default=None,
                        help="Chemin direct vers le fichier .npz")
    parser.add_argument("--data_dir", type=str,
                        default="data/family_data_v13_smart_crops",
                        help="R√©pertoire des donn√©es V13")
    parser.add_argument("--n_samples", type=int, default=20,
                        help="Nombre d'√©chantillons √† v√©rifier")
    parser.add_argument("--split", type=str, default="train",
                        choices=["train", "val", "all"],
                        help="Split √† v√©rifier (train, val, ou all pour les deux)")

    args = parser.parse_args()

    # D√©terminer les splits √† v√©rifier
    if args.split == "all":
        splits_to_check = ["train", "val"]
    else:
        splits_to_check = [args.split]

    all_results = {}
    all_ok = True

    for split in splits_to_check:
        if args.data_file:
            data_path = Path(args.data_file)
        else:
            data_path = Path(args.data_dir) / f"{args.family}_{split}_v13_smart_crops.npz"

        results = verify_data_file(data_path, n_samples=args.n_samples)
        all_results[split] = results

        if 'error' in results:
            print(f"‚ùå ERREUR ({split}): {results['error']}")
            all_ok = False
        elif not results.get('all_ok', False):
            all_ok = False

    # R√©sum√© final si plusieurs splits
    if len(splits_to_check) > 1:
        print(f"\n{'='*70}")
        print("R√âSUM√â GLOBAL (TRAIN + VAL)")
        print(f"{'='*70}")
        for split, results in all_results.items():
            if 'error' in results:
                print(f"  {split.upper()}: ‚ùå ERREUR - {results['error']}")
            elif results.get('all_ok', False):
                print(f"  {split.upper()}: ‚úÖ VALIDE")
            else:
                print(f"  {split.upper()}: ‚ùå INVALIDE")
        print(f"{'='*70}\n")

    sys.exit(0 if all_ok else 1)


if __name__ == "__main__":
    main()
