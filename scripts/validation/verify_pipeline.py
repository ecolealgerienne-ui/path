#!/usr/bin/env python3
"""
V√©rification compl√®te du pipeline avant entra√Ænement.

Ce script v√©rifie:
1. Int√©grit√© des donn√©es PanNuke
2. Coh√©rence du pr√©processing (ToPILImage avec uint8)
3. Extraction de features correcte
4. Scripts d'entra√Ænement

Usage:
    python scripts/validation/verify_pipeline.py --data_dir /home/amar/data/PanNuke
"""

import argparse
import sys
from pathlib import Path
import numpy as np

# Ajouter le chemin racine
sys.path.insert(0, str(Path(__file__).parent.parent.parent))


def check_section(title: str):
    """Affiche un titre de section."""
    print(f"\n{'='*60}")
    print(f"  {title}")
    print('='*60)


def verify_pannuke_data(data_dir: Path) -> dict:
    """V√©rifie l'int√©grit√© des donn√©es PanNuke."""
    check_section("1. V√âRIFICATION DES DONN√âES PANNUKE")

    results = {"valid": True, "folds": {}}

    for fold in [0, 1, 2]:
        fold_dir = data_dir / f"fold{fold}"
        fold_result = {"exists": False, "images": None, "masks": None, "types": None}

        if not fold_dir.exists():
            print(f"‚ùå fold{fold}: R√©pertoire manquant")
            results["valid"] = False
            results["folds"][fold] = fold_result
            continue

        fold_result["exists"] = True

        # V√©rifier images.npy
        images_path = fold_dir / "images.npy"
        if images_path.exists():
            images = np.load(images_path)
            fold_result["images"] = {
                "shape": images.shape,
                "dtype": str(images.dtype),
                "min": float(images.min()),
                "max": float(images.max()),
            }

            # V√©rification critique: format des images
            if images.dtype == np.float64 and images.max() > 1.0:
                print(f"‚ö†Ô∏è  fold{fold}/images.npy: float64 [0, 255] - ATTENTION")
                print(f"   ‚Üí Le script extract_features.py convertira en uint8")
            elif images.dtype == np.uint8:
                print(f"‚úÖ fold{fold}/images.npy: uint8 - Format id√©al")
            else:
                print(f"‚ÑπÔ∏è  fold{fold}/images.npy: {images.dtype} [{images.min():.1f}, {images.max():.1f}]")
        else:
            print(f"‚ùå fold{fold}/images.npy: Manquant")
            results["valid"] = False

        # V√©rifier masks.npy
        masks_path = fold_dir / "masks.npy"
        if masks_path.exists():
            masks = np.load(masks_path)
            fold_result["masks"] = {
                "shape": masks.shape,
                "dtype": str(masks.dtype),
            }
            print(f"‚úÖ fold{fold}/masks.npy: {masks.shape}")
        else:
            print(f"‚ùå fold{fold}/masks.npy: Manquant")
            results["valid"] = False

        # V√©rifier types.npy
        types_path = fold_dir / "types.npy"
        if types_path.exists():
            types = np.load(types_path)
            unique_types = np.unique(types)
            fold_result["types"] = {
                "count": len(types),
                "unique": len(unique_types),
                "organs": list(unique_types),
            }
            print(f"‚úÖ fold{fold}/types.npy: {len(types)} samples, {len(unique_types)} organes")
        else:
            print(f"‚ùå fold{fold}/types.npy: Manquant")
            results["valid"] = False

        results["folds"][fold] = fold_result

    return results


def verify_preprocessing_consistency() -> dict:
    """V√©rifie que le pr√©processing est coh√©rent entre extraction et inf√©rence."""
    check_section("2. V√âRIFICATION DU PR√âPROCESSING")

    results = {"valid": True, "tests": []}

    try:
        from torchvision import transforms
        import torch

        # Constantes H-optimus-0
        HOPTIMUS_MEAN = (0.707223, 0.578729, 0.703617)
        HOPTIMUS_STD = (0.211883, 0.230117, 0.177517)

        # Cr√©er le transform
        transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=HOPTIMUS_MEAN, std=HOPTIMUS_STD),
        ])

        # Test 1: Image uint8 [0, 255]
        print("\nTest 1: Image uint8 [0, 255]")
        img_uint8 = np.random.randint(0, 256, (256, 256, 3), dtype=np.uint8)
        tensor1 = transform(img_uint8)
        print(f"  Input: uint8 [{img_uint8.min()}, {img_uint8.max()}]")
        print(f"  Output: tensor [{tensor1.min():.3f}, {tensor1.max():.3f}]")
        results["tests"].append(("uint8", True))
        print("  ‚úÖ OK")

        # Test 2: Image float64 [0, 255] SANS conversion (probl√®me original)
        print("\nTest 2: Image float64 [0, 255] SANS conversion (bug)")
        img_float = img_uint8.astype(np.float64)
        tensor2_bad = transform(img_float)
        diff_bad = (tensor1 - tensor2_bad).abs().max().item()
        print(f"  Input: float64 [{img_float.min():.1f}, {img_float.max():.1f}]")
        print(f"  Diff√©rence avec uint8: {diff_bad:.3f}")
        if diff_bad > 1.0:
            print(f"  ‚ö†Ô∏è  CORRUPTION D√âTECT√âE - C'√©tait le bug!")
            results["tests"].append(("float64_raw", False))
        else:
            print(f"  ‚úÖ Pas de corruption (inattendu)")
            results["tests"].append(("float64_raw", True))

        # Test 3: Image float64 [0, 255] AVEC conversion (fix)
        print("\nTest 3: Image float64 [0, 255] AVEC conversion uint8 (fix)")
        img_float_fixed = img_float.clip(0, 255).astype(np.uint8)
        tensor3_fixed = transform(img_float_fixed)
        diff_fixed = (tensor1 - tensor3_fixed).abs().max().item()
        print(f"  Apr√®s conversion: uint8 [{img_float_fixed.min()}, {img_float_fixed.max()}]")
        print(f"  Diff√©rence avec uint8 original: {diff_fixed:.6f}")
        if diff_fixed < 0.001:
            print(f"  ‚úÖ IDENTIQUE - Le fix fonctionne!")
            results["tests"].append(("float64_fixed", True))
        else:
            print(f"  ‚ùå Diff√©rence inattendue")
            results["tests"].append(("float64_fixed", False))
            results["valid"] = False

    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        results["valid"] = False
        results["error"] = str(e)

    return results


def verify_extract_features_script() -> dict:
    """V√©rifie le script extract_features.py."""
    check_section("3. V√âRIFICATION DE extract_features.py")

    results = {"valid": True, "checks": []}

    script_path = Path(__file__).parent.parent / "preprocessing" / "extract_features.py"

    if not script_path.exists():
        print(f"‚ùå Script non trouv√©: {script_path}")
        results["valid"] = False
        return results

    # Lire le contenu
    content = script_path.read_text()

    # Check 1: Conversion uint8 pr√©sente
    if "astype(np.uint8)" in content and "clip(0, 255)" in content:
        print("‚úÖ Conversion uint8 avec clip pr√©sente")
        results["checks"].append(("uint8_conversion", True))
    else:
        print("‚ùå Conversion uint8 manquante!")
        results["checks"].append(("uint8_conversion", False))
        results["valid"] = False

    # Check 2: ToPILImage utilis√©
    if "ToPILImage" in content:
        print("‚úÖ ToPILImage utilis√©")
        results["checks"].append(("ToPILImage", True))
    else:
        print("‚ö†Ô∏è  ToPILImage non trouv√©")
        results["checks"].append(("ToPILImage", False))

    # Check 3: Normalisation H-optimus-0
    if "0.707223" in content and "0.211883" in content:
        print("‚úÖ Normalisation H-optimus-0 correcte")
        results["checks"].append(("normalization", True))
    else:
        print("‚ùå Normalisation H-optimus-0 incorrecte")
        results["checks"].append(("normalization", False))
        results["valid"] = False

    return results


def verify_inference_scripts() -> dict:
    """V√©rifie les scripts d'inf√©rence."""
    check_section("4. V√âRIFICATION DES SCRIPTS D'INF√âRENCE")

    results = {"valid": True, "files": {}}

    inference_files = [
        "src/inference/optimus_gate_inference_multifamily.py",
        "src/inference/optimus_gate_inference.py",
        "src/inference/hoptimus_hovernet.py",
    ]

    root = Path(__file__).parent.parent.parent

    for rel_path in inference_files:
        file_path = root / rel_path
        file_result = {"exists": False, "checks": []}

        if not file_path.exists():
            print(f"‚ùå {rel_path}: Fichier manquant")
            results["valid"] = False
            results["files"][rel_path] = file_result
            continue

        file_result["exists"] = True
        content = file_path.read_text()

        # Check: utilise create_hoptimus_transform()
        if "create_hoptimus_transform" in content:
            file_result["checks"].append(("transform_function", True))
        else:
            file_result["checks"].append(("transform_function", False))
            print(f"‚ö†Ô∏è  {rel_path}: create_hoptimus_transform() non utilis√©")

        # Check: conversion uint8
        if "astype(np.uint8)" in content:
            file_result["checks"].append(("uint8_conversion", True))
        else:
            file_result["checks"].append(("uint8_conversion", False))
            print(f"‚ö†Ô∏è  {rel_path}: Conversion uint8 non trouv√©e")

        # R√©sultat
        if all(c[1] for c in file_result["checks"]):
            print(f"‚úÖ {rel_path}: OK")

        results["files"][rel_path] = file_result

    return results


def verify_training_scripts() -> dict:
    """V√©rifie les scripts d'entra√Ænement."""
    check_section("5. V√âRIFICATION DES SCRIPTS D'ENTRA√éNEMENT")

    results = {"valid": True, "files": {}}

    training_files = [
        "scripts/training/train_organ_head.py",
        "scripts/training/train_hovernet.py",
        "scripts/training/train_hovernet_family.py",
    ]

    root = Path(__file__).parent.parent.parent

    for rel_path in training_files:
        file_path = root / rel_path
        file_result = {"exists": False, "issues": []}

        if not file_path.exists():
            print(f"‚ö†Ô∏è  {rel_path}: Fichier non trouv√© (optionnel)")
            results["files"][rel_path] = file_result
            continue

        file_result["exists"] = True
        content = file_path.read_text()

        # Les scripts d'entra√Ænement utilisent des features pr√©-extraites
        # Donc ils ne devraient PAS avoir de pr√©processing d'image

        # Check: pas de ToPILImage (car features d√©j√† extraites)
        if "ToPILImage" in content:
            file_result["issues"].append("ToPILImage trouv√© - devrait utiliser features pr√©-extraites")
            print(f"‚ö†Ô∏è  {rel_path}: Contient ToPILImage (v√©rifier si attendu)")

        # Check: charge des features .npz
        if ".npz" in content or "features" in content.lower():
            print(f"‚úÖ {rel_path}: Utilise des features pr√©-extraites")
        else:
            print(f"‚ÑπÔ∏è  {rel_path}: V√©rifier la source des donn√©es")

        results["files"][rel_path] = file_result

    return results


def run_quick_extraction_test(data_dir: Path) -> dict:
    """Test rapide d'extraction sur quelques images."""
    check_section("6. TEST D'EXTRACTION RAPIDE")

    results = {"valid": True}

    try:
        import torch
        from torchvision import transforms

        # Charger quelques images du fold0
        images_path = data_dir / "fold0" / "images.npy"
        if not images_path.exists():
            print("‚ö†Ô∏è  fold0/images.npy non trouv√©, skip du test")
            return results

        images = np.load(images_path)[:5]  # 5 premi√®res images
        print(f"Test sur {len(images)} images...")

        # Transform
        HOPTIMUS_MEAN = (0.707223, 0.578729, 0.703617)
        HOPTIMUS_STD = (0.211883, 0.230117, 0.177517)

        transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=HOPTIMUS_MEAN, std=HOPTIMUS_STD),
        ])

        # Tester chaque image
        for i, img in enumerate(images):
            # Convertir en uint8 (le fix)
            if img.dtype != np.uint8:
                img = img.clip(0, 255).astype(np.uint8)

            tensor = transform(img)

            # V√©rifier les valeurs
            if tensor.min() < -5 or tensor.max() > 5:
                print(f"  ‚ö†Ô∏è  Image {i}: Valeurs extr√™mes [{tensor.min():.2f}, {tensor.max():.2f}]")
            else:
                print(f"  ‚úÖ Image {i}: [{tensor.min():.2f}, {tensor.max():.2f}] - OK")

        print("\n‚úÖ Test d'extraction r√©ussi!")

    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        results["valid"] = False
        results["error"] = str(e)

    return results


def main():
    parser = argparse.ArgumentParser(description="V√©rification du pipeline")
    parser.add_argument("--data_dir", type=str, required=True,
                        help="Chemin vers PanNuke")
    parser.add_argument("--skip_extraction_test", action="store_true",
                        help="Skip le test d'extraction")
    args = parser.parse_args()

    data_dir = Path(args.data_dir)

    print("\n" + "="*60)
    print("  V√âRIFICATION COMPL√àTE DU PIPELINE")
    print("="*60)
    print(f"Data dir: {data_dir}")

    all_valid = True

    # 1. Donn√©es PanNuke
    result1 = verify_pannuke_data(data_dir)
    all_valid &= result1["valid"]

    # 2. Pr√©processing
    result2 = verify_preprocessing_consistency()
    all_valid &= result2["valid"]

    # 3. Script extract_features.py
    result3 = verify_extract_features_script()
    all_valid &= result3["valid"]

    # 4. Scripts d'inf√©rence
    result4 = verify_inference_scripts()
    all_valid &= result4["valid"]

    # 5. Scripts d'entra√Ænement
    result5 = verify_training_scripts()
    all_valid &= result5["valid"]

    # 6. Test d'extraction
    if not args.skip_extraction_test:
        result6 = run_quick_extraction_test(data_dir)
        all_valid &= result6["valid"]

    # R√©sum√© final
    check_section("R√âSUM√â FINAL")

    if all_valid:
        print("üéâ TOUTES LES V√âRIFICATIONS PASSENT!")
        print("\nVous pouvez lancer l'extraction:")
        print(f"  python scripts/preprocessing/extract_features.py \\")
        print(f"      --data_dir {data_dir} --fold 0 --all_layers")
    else:
        print("‚ö†Ô∏è  CERTAINES V√âRIFICATIONS ONT √âCHOU√â")
        print("Corrigez les probl√®mes avant de continuer.")
        sys.exit(1)


if __name__ == "__main__":
    main()
