#!/usr/bin/env python3
"""
V√©rification DIRECTE: Le mod√®le fonctionne-t-il sur ses propres donn√©es d'entra√Ænement?

Ce script charge les features EXACTES utilis√©es pour l'entra√Ænement
et v√©rifie que le mod√®le pr√©dit correctement.

‚ö†Ô∏è DIAGNOSTIC: Si le mod√®le pr√©dit 100% foreground m√™me sur ses propres donn√©es,
   cela indique un probl√®me avec le checkpoint ou les features.

Usage:
    python scripts/evaluation/verify_model_on_training_data.py \
        --checkpoint models/checkpoints/hovernet_epidermal_best.pth
"""

import argparse
import sys
from pathlib import Path

import numpy as np
import torch

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from src.constants import (
    get_family_features_path,
    get_family_targets_path,
    CURRENT_DATA_VERSION,
)
from src.models.hovernet_decoder import HoVerNetDecoder


def main():
    parser = argparse.ArgumentParser(description="V√©rifie mod√®le sur donn√©es training")
    parser.add_argument("--checkpoint", required=True, help="Checkpoint HoVer-Net")
    parser.add_argument("--family", default="epidermal", help="Famille")
    parser.add_argument("--device", default="cuda", choices=["cuda", "cpu"])
    parser.add_argument("--n_samples", type=int, default=10, help="Nombre d'√©chantillons")
    parser.add_argument("--verbose", action="store_true", help="Affiche d√©tails logits")
    args = parser.parse_args()

    print("=" * 80)
    print("üîç V√âRIFICATION: Mod√®le sur donn√©es d'entra√Ænement")
    print("=" * 80)
    print(f"   Version donn√©es: {CURRENT_DATA_VERSION}")

    # ========================================================================
    # 1. Charger les m√™mes features que l'entra√Ænement
    # ========================================================================
    features_path = get_family_features_path(args.family)
    targets_path = get_family_targets_path(args.family)

    print(f"\nüìÇ Chargement features: {features_path}")
    features_data = np.load(features_path)

    if 'features' in features_data:
        features = features_data['features']
    elif 'layer_24' in features_data:
        features = features_data['layer_24']
    else:
        print(f"‚ùå Cl√©s inattendues: {list(features_data.keys())}")
        return

    print(f"   Features shape: {features.shape}")

    print(f"\nüìÇ Chargement targets: {targets_path}")
    targets_data = np.load(targets_path)
    np_targets = targets_data['np_targets']
    print(f"   NP targets shape: {np_targets.shape}")

    # ========================================================================
    # 2. Charger le mod√®le
    # ========================================================================
    print(f"\nüîß Chargement mod√®le: {args.checkpoint}")
    hovernet = HoVerNetDecoder(embed_dim=1536, n_classes=5).to(args.device)
    checkpoint = torch.load(args.checkpoint, map_location=args.device)
    hovernet.load_state_dict(checkpoint['model_state_dict'])
    hovernet.eval()

    print(f"   Epoch: {checkpoint.get('epoch', 'N/A')}")
    print(f"   Val Dice (sauvegard√©): {checkpoint.get('val_dice', 'N/A')}")

    # ========================================================================
    # 3. Tester sur quelques √©chantillons
    # ========================================================================
    print(f"\nüß™ Test sur {args.n_samples} √©chantillons...")
    print(f"   Features shape: {features.shape}")
    print(f"   Targets shape: {np_targets.shape}")

    all_dice = []
    all_pred_fg = []
    all_target_fg = []
    all_logit_stats = []

    for i in range(min(args.n_samples, len(features))):
        # Features COMPL√àTES (261, 1536) - le d√©codeur g√®re l'extraction des patch tokens
        feat = torch.tensor(features[i:i+1]).to(args.device).float()

        # Target NP (256x256 ou 224x224?)
        np_target = np_targets[i]
        target_fg = (np_target > 0).sum()

        # Pr√©diction
        with torch.no_grad():
            np_out, hv_out, nt_out = hovernet(feat)

        # ========================================================================
        # DIAGNOSTIC: Analyse des logits bruts
        # ========================================================================
        np_logits = np_out[0].cpu().numpy()  # (2, H, W)
        logit_bg = np_logits[0]  # Logit background
        logit_fg = np_logits[1]  # Logit foreground

        logit_stats = {
            'bg_mean': logit_bg.mean(),
            'bg_min': logit_bg.min(),
            'bg_max': logit_bg.max(),
            'fg_mean': logit_fg.mean(),
            'fg_min': logit_fg.min(),
            'fg_max': logit_fg.max(),
            'diff_mean': (logit_fg - logit_bg).mean(),  # Si > 0 partout ‚Üí pr√©dit tout FG
        }
        all_logit_stats.append(logit_stats)

        # Conversion - m√©thode identique au training (argmax)
        pred_class = np_out.argmax(dim=1)[0].cpu().numpy()  # (H, W) - 0=bg, 1=fg
        pred_fg = (pred_class == 1).sum()

        # Alternative: softmax > 0.5 (devrait donner le m√™me r√©sultat)
        np_probs = torch.softmax(np_out, dim=1)  # (1, 2, H, W)
        pred_binary_soft = (np_probs[0, 1] > 0.5).cpu().numpy()

        # V√©rifier coh√©rence argmax vs softmax
        if not np.array_equal(pred_class, pred_binary_soft.astype(int)):
            print(f"   ‚ö†Ô∏è INCOH√âRENCE argmax vs softmax!")

        # Dice avec resize si n√©cessaire
        import cv2
        if np_target.shape != pred_class.shape:
            np_target_resized = cv2.resize(
                np_target.astype(np.float32),
                (pred_class.shape[1], pred_class.shape[0]),
                interpolation=cv2.INTER_NEAREST
            )
            target_binary = np_target_resized > 0
            target_fg_resized = target_binary.sum()
        else:
            target_binary = np_target > 0
            target_fg_resized = target_fg

        pred_binary = (pred_class == 1)
        intersection = (pred_binary & target_binary).sum()
        union = pred_binary.sum() + target_binary.sum()
        dice = 2 * intersection / union if union > 0 else 1.0

        all_dice.append(dice)
        all_pred_fg.append(pred_fg)
        all_target_fg.append(target_fg_resized)

        if i < 3 or args.verbose:  # Print first 3 or all if verbose
            print(f"\n   Sample {i}:")
            print(f"     Target shape: {np_target.shape}, Pred shape: {pred_class.shape}")
            print(f"     Pred FG: {pred_fg} pixels ({100*pred_fg/pred_class.size:.1f}%)")
            print(f"     Target FG: {target_fg_resized} pixels ({100*target_fg_resized/target_binary.size:.1f}%)")
            print(f"     Dice: {dice:.4f}")
            print(f"     Logits BG: mean={logit_stats['bg_mean']:.2f}, min={logit_stats['bg_min']:.2f}, max={logit_stats['bg_max']:.2f}")
            print(f"     Logits FG: mean={logit_stats['fg_mean']:.2f}, min={logit_stats['fg_min']:.2f}, max={logit_stats['fg_max']:.2f}")
            print(f"     Diff (FG-BG): mean={logit_stats['diff_mean']:.2f}")

    # ========================================================================
    # 4. R√©sum√©
    # ========================================================================
    print("\n" + "=" * 80)
    print("üìä R√âSUM√â")
    print("=" * 80)

    mean_dice = np.mean(all_dice)
    mean_pred_fg = np.mean(all_pred_fg)
    mean_target_fg = np.mean(all_target_fg)

    # Statistiques des logits agr√©g√©es
    mean_bg_logit = np.mean([s['bg_mean'] for s in all_logit_stats])
    mean_fg_logit = np.mean([s['fg_mean'] for s in all_logit_stats])
    mean_diff_logit = np.mean([s['diff_mean'] for s in all_logit_stats])

    print(f"""
    Dice moyen:           {mean_dice:.4f}
    Pred FG moyen:        {mean_pred_fg:.0f} pixels ({100*mean_pred_fg/50176:.1f}%)
    Target FG moyen:      {mean_target_fg:.0f} pixels ({100*mean_target_fg/50176:.1f}%)
    Ratio Pred/Target:    {mean_pred_fg/max(mean_target_fg, 1):.2f}x

    üìà ANALYSE LOGITS:
    Logit BG moyen:       {mean_bg_logit:.2f}
    Logit FG moyen:       {mean_fg_logit:.2f}
    Diff (FG-BG) moyen:   {mean_diff_logit:.2f}
    """)

    # Diagnostic bas√© sur les logits
    if mean_diff_logit > 5:
        print("üî¥ DIAGNOSTIC: Logits FG >> BG partout!")
        print("   Le mod√®le a un BIAIS FORT vers foreground.")
        print("   Causes possibles:")
        print("   1. Checkpoint corrompu ou d'un entra√Ænement rat√©")
        print("   2. Les features pendant training √©taient diff√©rentes")
        print("   3. Le mod√®le n'a jamais appris correctement")
    elif mean_diff_logit < -5:
        print("üî¥ DIAGNOSTIC: Logits BG >> FG partout!")
        print("   Le mod√®le pr√©dit tout comme background.")
    elif abs(mean_diff_logit) < 0.1 and mean_dice < 0.5:
        print("üü° DIAGNOSTIC: Logits √©quilibr√©s mais Dice faible")
        print("   Le mod√®le g√©n√®re des pr√©dictions semi-al√©atoires.")

    if mean_dice > 0.90:
        print("‚úÖ Le mod√®le fonctionne correctement sur ses donn√©es d'entra√Ænement!")
    elif mean_dice > 0.50:
        print("‚ö†Ô∏è Le mod√®le a des performances moyennes - v√©rifier les features")
    else:
        print("‚ùå Le mod√®le ne fonctionne PAS sur ses propres donn√©es!")
        print("   ‚Üí Les features utilis√©es pour l'inf√©rence sont probablement")
        print("     DIFF√âRENTES de celles utilis√©es pour l'entra√Ænement.")

    if mean_pred_fg / max(mean_target_fg, 1) > 5:
        print("\nüî¥ ALERTE: Le mod√®le pr√©dit BEAUCOUP trop de pixels comme foreground!")
        print("   Possible causes:")
        print("   1. Features corrompues pendant extraction")
        print("   2. Mod√®le entra√Æn√© sur des features diff√©rentes")
        print("   3. Bug dans le preprocessing")
        print("\n   üí° SOLUTION RECOMMAND√âE:")
        print("   1. V√©rifier que le checkpoint correspond √† la bonne famille")
        print("   2. R√©-extraire les features avec extract_features_from_v9.py")
        print("   3. R√©-entra√Æner avec train_hovernet_family.py")
        print("   4. Utiliser la config de test: fold0, 20 epochs")


if __name__ == "__main__":
    main()
