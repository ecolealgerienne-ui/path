# D√©cision R√©-entra√Ænement Epidermal ‚Äî Synth√®se Ex√©cutive

**Date:** 2025-12-24
**Probl√®me:** AJI 0.09 vs objectif 0.60+ (Giant Blob: 1 instance au lieu de 8)
**Cause racine identifi√©e:** Mismatch de version logique (code Sobel pr√©sent, checkpoint pr√©-Sobel)

---

## üéØ Consensus Claude + Expert

### Points d'accord (100%)

1. ‚úÖ **Architecture actuelle correcte:**
   - Tanh pr√©sent (ligne 118-121)
   - Sobel gradient loss impl√©ment√© (ligne 244-280, poids 2.0√ó)
   - Donn√©es v8 utilisent vraies instances PanNuke

2. ‚úÖ **Giant Blob confirm√©:**
   - HV magnitude 0.022 (50√ó trop faible)
   - 1 instance pr√©dite vs 8 GT
   - 137 peaks d√©tect√©s (mod√®le "voit" mais ne s√©pare pas)

3. ‚úÖ **Cause racine: Checkpoint entra√Æn√© AVANT Sobel fix**
   - Sobel fix dat√©: 2025-12-23 (FIX_SOBEL_GRADIENT_LOSS.md)
   - Code actuel a Sobel, mais checkpoint .pth fig√© sans Sobel
   - Citation expert: "Avoir le code du Sobel dans tes .py ne sert √† rien si les poids ont √©t√© fig√©s √† une √©poque o√π le gradient √©tait encore mou"

4. ‚úÖ **Solution: R√©-entra√Ænement avec Sobel**
   - Dice 0.95 prouve que mod√®le sait O√ô sont les cellules
   - Sobel fix lui apprend COMMENT les s√©parer
   - Pr√©diction expert: AJI 0.60+ apr√®s r√©-entra√Ænement

---

## üî¨ Divergence (Mineure)

| Point | Analyse Claude | Analyse Expert | Consensus |
|-------|----------------|----------------|-----------|
| **Gaussian smoothing** | Hypoth√®se #3 (sigma=0.5 trop agressif) | "Sigma 0.5 tr√®s l√©ger, ne PAS supprimer" | ‚úÖ **Garder le smoothing** |
| **Lambda_hv** | lambda_hv=2.0 (code actuel) | lambda_hv=3.0 (augment√©) | ‚úÖ **Utiliser 3.0** pour "vraiment pousser le gradient" |

---

## üìã Plan de V√©rification (M√©thodique)

### √âtape 1: V√©rifier HV Targets (CRITIQUE - 30s)

**Commande:**
```bash
conda activate cellvit
python scripts/validation/verify_hv_targets_npz.py --family epidermal
```

**D√©cision:**
- ‚úÖ Targets corrects (float32, [-1, 1]) ‚Üí Continuer √âtape 2
- ‚ùå Targets incorrects ‚Üí STOP, r√©g√©n√©rer v9 AVANT r√©-entra√Ænement

---

### √âtape 2: V√©rifier Date Checkpoint (2 min)

**Commande:**
```bash
find models/checkpoints -name "hovernet_epidermal_best.pth" -exec ls -l {} \;
```

**D√©cision:**
- Date < 2025-12-23 ‚Üí ‚úÖ GO r√©-entra√Ænement
- Date ‚â• 2025-12-23 ‚Üí ‚ö†Ô∏è V√©rifier logs training (Sobel actif?)

---

### √âtape 3: GO/NO-GO D√©cision

**Crit√®res GO r√©-entra√Ænement:**
- [x] HV targets v√©rifi√©s ‚úÖ
- [x] Checkpoint pr√©-Sobel ‚úÖ
- [x] Architecture correcte ‚úÖ
- [x] Donn√©es v8 correctes ‚úÖ

**Si tous ‚úÖ ‚Üí LANCER r√©-entra√Ænement**

---

## üöÄ Commande R√©-entra√Ænement (Recommandation Expert)

```bash
conda activate cellvit

python scripts/training/train_hovernet_family.py \
    --family epidermal \
    --epochs 50 \
    --augment \
    --lambda_np 1.0 \
    --lambda_hv 3.0 \
    --lambda_nt 1.0 \
    --batch_size 16
```

**Changement cl√©:** `lambda_hv 2.0 ‚Üí 3.0`

**Dur√©e:** ~40 minutes (571 samples epidermal)

---

## üìä R√©sultats Attendus

### M√©triques Training (√† surveiller)

**HV MSE durant epochs:**
| Epoch | HV MSE | Interpr√©tation |
|-------|--------|----------------|
| 1-5 | 0.30-0.40 | Normal (apprentissage) |
| 10-20 | 0.15-0.25 | Convergence |
| 30-50 | **0.05-0.10** | ‚úÖ Sobel actif (descente lente = travaille sur gradients) |

**Citation expert:**
> "Si [HV MSE] descend plus lentement ou reste plus haute qu'avant tout en √©tant stable, c'est bon signe : le mod√®le travaille plus dur sur les d√©tails complexes du gradient."

---

### M√©triques Post-Training (validation)

**Test visualisation (sample 9):**
| M√©trique | Avant | Apr√®s | Am√©lioration |
|----------|-------|-------|--------------|
| **Instances PRED** | **1** | **5-8** | **+500-700%** üéØ |
| **HV Magnitude** | **0.022** | **>0.50** | **+2200%** üéØ |

**Test AJI (50 √©chantillons):**
| M√©trique | Avant | Apr√®s (Pr√©diction Expert) | Am√©lioration |
|----------|-------|---------------------------|--------------|
| **AJI** | **0.09** | **0.60+** | **+567%** üéØ |
| **PQ** | ~0.10 | **0.65+** | **+550%** üéØ |
| Dice | 0.92 | ~0.95 | Stable/L√©g√®re hausse |

---

## ‚úÖ Crit√®res de Succ√®s

**Minimum acceptable:** AJI ‚â• 0.50, PQ ‚â• 0.55

**Cible (pr√©diction expert):** AJI ‚â• 0.60, PQ ‚â• 0.65

**Excellent:** AJI ‚â• 0.70, PQ ‚â• 0.75

---

## üîÑ Plan de Contingence

**Si √©chec partiel (AJI 0.30-0.50):**
- Test lambda_hv=5.0 (encore plus agressif)
- V√©rifier Gaussian smoothing (r√©g√©n√©rer avec sigma=0.3)

**Si √©chec total (AJI <0.30):**
- Investigation approfondie features H-optimus-0
- V√©rifier fonction compute_hv_maps()
- V√©rifier post-processing Watershed

---

## üéì Le√ßons Apprises

**Citation expert (cl√©):**
> "Le Dice de 0.95 que tu as d√©j√† prouve que le mod√®le sait o√π sont les cellules. En ajoutant le Sobel fix pendant l'entra√Ænement, tu lui apprends enfin comment les s√©parer. C'est comme donner une paire de lunettes de vue √† quelqu'un qui voyait d√©j√† des formes mais sans les d√©tails."

**Takeaway:**
- Magnitude 0.022 = signature d'un mod√®le "peureux" qui reste proche de z√©ro
- Sobel force le mod√®le √† "muscler" ses pr√©dictions (cr√©er relief/barrages)
- Lambda_hv augment√© (3.0) pousse encore plus le gradient
- Gaussian smoothing (sigma=0.5) n'est PAS le probl√®me (√©vite aliasing)

---

## üìù Checklist Pr√©-Lancement

Avant de lancer le r√©-entra√Ænement:

- [ ] √âtape 1: V√©rifier HV targets .npz
- [ ] √âtape 2: V√©rifier date checkpoint
- [ ] D√©cision GO/NO-GO confirm√©e
- [ ] Environnement `cellvit` activ√©
- [ ] GPU disponible (~8-10 GB VRAM)
- [ ] 40 minutes disponibles

**Une fois checklist compl√®te ‚Üí LANCER r√©-entra√Ænement**

---

## üîó Documentation Compl√®te

Voir `PLAN_VERIFICATION_HOVERNET.md` pour:
- Plan d√©taill√© 5 √©tapes
- Arbres de d√©cision
- Commandes compl√®tes de validation
- R√©f√©rences litt√©rature

---

**Recommandation finale:** ‚úÖ GO r√©-entra√Ænement avec lambda_hv=3.0 (confiance √©lev√©e dans succ√®s)
