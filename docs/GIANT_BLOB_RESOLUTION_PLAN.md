# Giant Blob - Plan de R√©solution

**Date:** 2025-12-24
**Probl√®me:** AJI 0.09 (objectif: 0.60+) - 1 instance au lieu de 8 d√©tect√©es
**Diagnostic:** Giant Blob confirm√© par visualisation

---

## üîç R√©sum√© Diagnostic

### Ce Qui Fonctionne ‚úÖ

1. **Mod√®le d√©tecte bien les cellules:**
   - NP Dice: 0.92 (excellent)
   - 137 peaks trouv√©s par `peak_local_max` (mod√®le "voit" les 137 cellules)

2. **Architecture correcte:**
   - ‚úÖ Tanh() sur branche HV (ligne 118-121 hovernet_decoder.py)
   - ‚úÖ Sobel gradient loss utilis√© (ligne 347) avec poids 2.0√ó
   - ‚úÖ HV targets normalis√©s float32 [-1, 1] (donn√©es v8)
   - ‚úÖ Vraies instances PanNuke (pas connectedComponents)

3. **Donn√©es v8 correctes:**
   - Utilise vraies instances des canaux 1-4 PanNuke
   - HV maps bien normalis√©s [-1, 1]

### Ce Qui NE Fonctionne PAS ‚ùå

1. **HV magnitude trop faible:**
   - GT range: [0.0000, 0.9992] ‚úÖ NORMAL
   - PRED range: [0.0022, 0.0221] ‚ùå TR√àS FAIBLE (50√ó trop faible!)

2. **Watershed cr√©√© 1 instance au lieu de 8:**
   - Les 137 peaks sont d√©tect√©s
   - Mais watershed ne s√©pare pas (gradients HV trop faibles)

3. **Scaling HV n'am√©liore pas l'AJI:**
   - Test √ó1, √ó5, √ó10, √ó20, √ó50 ‚Üí AJI stable √† 0.09
   - Prouve que le probl√®me n'est PAS juste une amplitude faible

---

## üìã Documentation Consult√©e

### FIX_SOBEL_GRADIENT_LOSS.md (2025-12-23)

**Probl√®me d√©crit:**
- AJI 0.07 vs cible 0.80
- HV MSE bon (0.05) mais gradients "doux" (pas nets)
- Watershed √©choue car pas de fronti√®res ferm√©es

**Cause:**
- Gradient loss trop faible (signal 0.01 avec diff√©rences finies)
- Mod√®le apprend HV maps lisses au lieu de fronti√®res nettes

**Solution impl√©ment√©e:**
- Op√©rateur Sobel au lieu de diff√©rences finies simples
- Signal 4√ó plus fort

**Statut actuel:** ‚úÖ D√âJ√Ä IMPL√âMENT√â dans notre code

### ARCHITECTURE_HV_ACTIVATION.md (2025-12-21)

**D√©cision:** Conserver architecture SANS Tanh explicite

**Justification:** Tests empiriques montrent que mod√®le produit naturellement [-1, 1] via SmoothL1

**MAIS:** ‚ö†Ô∏è Cette d√©cision a √©t√© CHANG√âE plus tard (ligne 118-121 hovernet_decoder.py AJOUT√â Tanh)

---

## üéØ Hypoth√®ses Restantes

### Hypoth√®se #1: Mod√®le Entra√Æn√© AVANT Sobel Fix

**Possibilit√©:** Le checkpoint `hovernet_epidermal_best.pth` a √©t√© entra√Æn√© AVANT l'ajout de Sobel gradient loss.

**V√©rification:**
```bash
# Voir date de cr√©ation checkpoint
ls -l models/checkpoints/hovernet_epidermal_best.pth

# Comparer avec date de la session Sobel fix (2025-12-23)
```

**Test:**
```bash
# R√©-entra√Æner epidermal AVEC Sobel (d√©j√† dans le code)
python scripts/training/train_hovernet_family.py \
    --family epidermal \
    --epochs 50 \
    --augment \
    --lambda_np 1.0 \
    --lambda_hv 2.0 \
    --lambda_nt 1.0
```

**Attendu:** HV magnitude 0.022 ‚Üí 0.5+ (gain √ó20), AJI 0.09 ‚Üí 0.60+ (gain √ó6)

### Hypoth√®se #2: Gaussian Smoothing Trop Agressif

**Code v8 (ligne 135-136 prepare_family_data_FIXED_v8.py):**
```python
# Gaussian smoothing (sigma=0.5) pour r√©duire le bruit
hv_map[0] = gaussian_filter(hv_map[0], sigma=0.5)
hv_map[1] = gaussian_filter(hv_map[1], sigma=0.5)
```

**Impact:**
- Lisse les gradients HV dans les targets
- Mod√®le apprend √† reproduire cette version liss√©e
- Watershed ne peut pas s√©parer instances

**Test:**
R√©g√©n√©rer donn√©es v8 SANS Gaussian smoothing:

```python
# prepare_family_data_FIXED_v8_nosmooth.py
# Commenter lignes 135-136

# PAS de smoothing
# hv_map[0] = gaussian_filter(hv_map[0], sigma=0.5)
# hv_map[1] = gaussian_filter(hv_map[1], sigma=0.5)
```

**Co√ªt:** 30 min (r√©g√©n√©ration epidermal) + 2h (r√©-entra√Ænement)

### Hypoth√®se #3: Lambda_hv Trop Faible

**Code actuel (ligne 348):**
```python
hv_loss = hv_l1 + 2.0 * hv_gradient  # √âquilibr√©: MSE + 2√ó gradient
```

**Expert recommandation (FIX_SOBEL_GRADIENT_LOSS.md ligne 198):**
```python
--lambda_hv 2.0
```

Mais ce lambda_hv s'applique √† la LOSS TOTALE, pas au gradient:

```python
total = 1.0*np_loss + 2.0*hv_loss + 1.0*nt_loss
```

Donc: `total_hv_contribution = 2.0 * (hv_l1 + 2.0*hv_gradient) = 2.0*hv_l1 + 4.0*hv_gradient`

**Test:** Augmenter poids gradient de 2.0 ‚Üí 5.0:

```python
hv_loss = hv_l1 + 5.0 * hv_gradient  # Plus de pression pour fronti√®res nettes
```

**Risque:** Over-regularization (comme lambda_hv=10.0 qui a cass√© le mod√®le)

---

## ‚ö° Actions Imm√©diates (Ordre de Priorit√©)

### Action 1: V√©rifier Date Checkpoint (2 min)

```bash
ls -l models/checkpoints/hovernet_epidermal_best.pth
```

**Si date < 2025-12-23:** Checkpoint entra√Æn√© AVANT Sobel fix ‚Üí R√©-entra√Ænement requis

**Si date ‚â• 2025-12-23:** Checkpoint entra√Æn√© AVEC Sobel ‚Üí Autre probl√®me

### Action 2A: Si Checkpoint Ancien ‚Üí R√©-entra√Æner (2h)

```bash
conda activate cellvit

python scripts/training/train_hovernet_family.py \
    --family epidermal \
    --epochs 50 \
    --augment \
    --lambda_np 1.0 \
    --lambda_hv 2.0 \
    --lambda_nt 1.0 \
    --batch_size 16
```

**Attendu:** HV magnitude 0.022 ‚Üí 0.5+, AJI 0.09 ‚Üí 0.60+

**Si √©chec:** Passer √† Action 3

### Action 2B: Si Checkpoint R√©cent ‚Üí Test Watershed Params (5 min)

Le mod√®le produit des gradients faibles m√™me avec Sobel ‚Üí Ajuster post-processing:

```python
# visualize_instance_maps.py ligne 44
# AVANT:
dist_threshold = 2  # CONSERVATIVE

# APR√àS:
dist_threshold = 1  # Moins conservateur
min_size = 5        # Au lieu de 10
```

**Attendu:** Plus d'instances d√©tect√©es (1 ‚Üí 5-8)

**Si √©chec:** Passer √† Action 3

### Action 3: Si √âchecs Persistants ‚Üí R√©g√©n√©rer Sans Smoothing (3h)

1. Cr√©er version v9 sans Gaussian smoothing:
   ```bash
   cp scripts/preprocessing/prepare_family_data_FIXED_v8.py \
      scripts/preprocessing/prepare_family_data_v9_nosmooth.py

   # Commenter lignes 135-136 (gaussian_filter)
   ```

2. R√©g√©n√©rer donn√©es epidermal:
   ```bash
   python scripts/preprocessing/prepare_family_data_v9_nosmooth.py \
       --family epidermal \
       --data_dir /home/amar/data/PanNuke \
       --output_dir data/cache/family_data_v9
   ```

3. R√©-entra√Æner:
   ```bash
   python scripts/training/train_hovernet_family.py \
       --family epidermal \
       --cache_dir data/cache/family_data_v9 \
       --epochs 50 \
       --augment
   ```

**Attendu:** HV magnitude plus forte (gradients non liss√©s), AJI am√©lior√©

---

## üìä Timeline Estim√©e

| Sc√©nario | Temps | Probabilit√© |
|----------|-------|-------------|
| **A: Checkpoint ancien** | 2h (r√©-entra√Ænement) | 70% |
| **B: Watershed params** | 5 min (ajustement) | 15% |
| **C: Smoothing trop fort** | 3h (r√©g√©n√©ration + r√©-entra√Ænement) | 15% |

---

## üî¨ V√©rifications Post-Fix

Apr√®s chaque fix, valider avec:

```bash
# 1. Test sur training data
python scripts/validation/test_on_training_data.py \
    --family epidermal \
    --checkpoint models/checkpoints/hovernet_epidermal_best.pth \
    --n_samples 10

# Attendu:
# NP Dice:  ~0.95
# HV magnitude: >0.5 (au lieu de 0.022)

# 2. Visualisation √©chantillon 9
python scripts/evaluation/visualize_instance_maps.py

# Attendu:
# Instances pr√©dites: 5-8 (au lieu de 1)
# Instances GT: 8

# 3. AJI ground truth
python scripts/evaluation/test_aji_v8.py \
    --family epidermal \
    --checkpoint models/checkpoints/hovernet_epidermal_best.pth \
    --n_samples 50

# Attendu:
# AJI: >0.60 (au lieu de 0.09)
# PQ: >0.65 (au lieu de ~0.10)
```

---

## üìù Recommandation Finale

**Sc√©nario le plus probable:** Checkpoint entra√Æn√© AVANT l'impl√©mentation du Sobel gradient loss.

**Action imm√©diate:**
1. V√©rifier date checkpoint (2 min)
2. Si ancien: R√©-entra√Æner avec Sobel (2h)
3. Valider am√©lioration AJI 0.09 ‚Üí 0.60+

**Si √©chec apr√®s r√©-entra√Ænement:** Investiguer Gaussian smoothing (Action 3)

---

**Prochaine action:** V√©rifier date du checkpoint et lancer Action 1.
