# üìù CODE CORRIG√â ‚Äî train_hovernet_family.py (2025-12-24)

**Fichier:** `scripts/training/train_hovernet_family.py`

---

## ‚úÇÔ∏è MODIFICATION 1: Ajouter argument --lambda_magnitude

**Trouver les arguments de loss (lignes 346-353) et AJOUTER:**

```python
    # Options de loss weighting
    parser.add_argument('--lambda_np', type=float, default=1.0,
                       help='Poids loss NP (segmentation)')
    parser.add_argument('--lambda_hv', type=float, default=2.0,
                       help='Poids loss HV (s√©paration instances)')
    parser.add_argument('--lambda_nt', type=float, default=1.0,
                       help='Poids loss NT (classification)')
    # ‚Üì‚Üì‚Üì NOUVELLE LIGNE √Ä AJOUTER ‚Üì‚Üì‚Üì
    parser.add_argument('--lambda_magnitude', type=float, default=5.0,
                       help='Poids magnitude loss (Expert: 5.0 pour forcer gradients forts)')
    # ‚Üë‚Üë‚Üë FIN NOUVELLE LIGNE ‚Üë‚Üë‚Üë
    parser.add_argument('--adaptive_loss', action='store_true',
                       help='Utiliser Uncertainty Weighting (poids appris)')
```

**R√©sultat attendu apr√®s modification:**
```python
    parser.add_argument('--lambda_np', type=float, default=1.0,
                       help='Poids loss NP (segmentation)')
    parser.add_argument('--lambda_hv', type=float, default=2.0,
                       help='Poids loss HV (s√©paration instances)')
    parser.add_argument('--lambda_nt', type=float, default=1.0,
                       help='Poids loss NT (classification)')
    parser.add_argument('--lambda_magnitude', type=float, default=5.0,
                       help='Poids magnitude loss (Expert: 5.0 pour forcer gradients forts)')
    parser.add_argument('--adaptive_loss', action='store_true',
                       help='Utiliser Uncertainty Weighting (poids appris)')
```

---

## ‚úÇÔ∏è MODIFICATION 2: Passer lambda_magnitude √† HoVerNetLoss

**Trouver la cr√©ation du criterion (lignes 408-413) et MODIFIER:**

**AVANT:**
```python
    # Loss et optimizer
    criterion = HoVerNetLoss(
        lambda_np=args.lambda_np,
        lambda_hv=args.lambda_hv,
        lambda_nt=args.lambda_nt,
        adaptive=args.adaptive_loss,
    )
```

**APR√àS:**
```python
    # Loss et optimizer
    criterion = HoVerNetLoss(
        lambda_np=args.lambda_np,
        lambda_hv=args.lambda_hv,
        lambda_nt=args.lambda_nt,
        lambda_magnitude=args.lambda_magnitude,  # ‚Üê NOUVELLE LIGNE
        adaptive=args.adaptive_loss,
    )
```

---

## ‚úÇÔ∏è MODIFICATION 3: Afficher lambda_magnitude dans les logs

**Trouver l'affichage de la configuration loss (lignes 415-420) et MODIFIER:**

**AVANT:**
```python
    # Afficher configuration loss
    if args.adaptive_loss:
        print(f"  Loss: Uncertainty Weighting (poids appris)")
        criterion.to(device)  # Les param√®tres log_var sont sur le device
    else:
        print(f"  Loss: Poids fixes (NP={args.lambda_np}, HV={args.lambda_hv}, NT={args.lambda_nt})")
```

**APR√àS:**
```python
    # Afficher configuration loss
    if args.adaptive_loss:
        print(f"  Loss: Uncertainty Weighting (poids appris)")
        print(f"        Magnitude weight: {args.lambda_magnitude} (fixed)")  # ‚Üê NOUVELLE LIGNE
        criterion.to(device)  # Les param√®tres log_var sont sur le device
    else:
        print(f"  Loss: Poids fixes (NP={args.lambda_np}, HV={args.lambda_hv}, NT={args.lambda_nt}, Magnitude={args.lambda_magnitude})")
        #                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ‚Üê AJOUT
```

---

## üìù Checklist Application

### √âtape 1: Backup (IMPORTANT)

```bash
# Sauvegarder l'ancienne version
cp scripts/training/train_hovernet_family.py scripts/training/train_hovernet_family.py.backup_before_expert_fix
```

### √âtape 2: Appliquer les 3 Modifications

- [ ] **Modification 1:** Ajouter argument `--lambda_magnitude` (apr√®s ligne 351)
- [ ] **Modification 2:** Passer `lambda_magnitude=args.lambda_magnitude` √† HoVerNetLoss (ligne 412)
- [ ] **Modification 3:** Afficher lambda_magnitude dans les logs (lignes 415-420)

### √âtape 3: V√©rifier Syntaxe

```bash
python scripts/training/train_hovernet_family.py --help | grep lambda_magnitude
# Attendu: --lambda_magnitude LAMBDA_MAGNITUDE
```

### √âtape 4: Test Dry-Run (Sans GPU)

```bash
python scripts/training/train_hovernet_family.py \
    --family epidermal \
    --epochs 1 \
    --lambda_hv 3.0 \
    --lambda_magnitude 5.0 \
    --help | grep "Poids magnitude"
# Attendu: affichage aide avec description
```

---

## üöÄ Commande Re-training Compl√®te

**Apr√®s application de TOUS les fixes (hovernet_decoder.py + train_hovernet_family.py):**

```bash
python scripts/training/train_hovernet_family.py \
    --family epidermal \
    --epochs 50 \
    --augment \
    --lambda_hv 3.0 \
    --lambda_magnitude 5.0 \
    --batch_size 8 \
    --lr 1e-4
```

**Sortie attendue dans les logs:**
```
üîß Initialisation du d√©codeur HoVer-Net...
  Param√®tres: 12,345,678 (12.3M)
  Loss: Poids fixes (NP=1.0, HV=3.0, NT=1.0, Magnitude=5.0)
                                                   ^^^^^^^^^^^
                                                   NOUVEAU
```

---

## üî¨ Monitoring pendant Training

**Apr√®s 5 epochs, v√©rifier magnitude:**

```bash
# Vous verrez dans les logs train_losses:
# Epoch 5/50
# Train - Loss: 2.8456
#         hv_l1: 0.0215
#         hv_gradient: 0.0108
#         hv_magnitude: 0.3521  ‚Üê DOIT AUGMENTER (>0.25 apr√®s 5 epochs)
#                       ^^^^^^
#                       ATTENDU: >0.25 (indicateur succ√®s)
```

**Si magnitude <0.10 apr√®s 5 epochs:**
- ‚ùå Le fix n'a pas fonctionn√©
- V√©rifier que `magnitude_loss()` est bien celle corrig√©e (epsilon dans racine)
- V√©rifier que `lambda_magnitude=5.0` est bien pass√©

**Si magnitude >0.25 apr√®s 5 epochs:**
- ‚úÖ Le fix fonctionne! Continuer le training
- Attendu √† epoch 50: magnitude >0.50

---

## üìä R√©sum√© des Changements

| Fichier | Lignes modifi√©es | Description |
|---------|------------------|-------------|
| `hovernet_decoder.py` | 302-361 | Fonction `magnitude_loss()` corrig√©e |
| `hovernet_decoder.py` | ~240 | Param√®tre `lambda_magnitude` ajout√© √† `__init__` |
| `hovernet_decoder.py` | ~416 | Utilisation `self.lambda_magnitude` dans calcul |
| `train_hovernet_family.py` | ~351 | Argument CLI `--lambda_magnitude` |
| `train_hovernet_family.py` | ~412 | Passage param√®tre √† `HoVerNetLoss()` |
| `train_hovernet_family.py` | ~420 | Affichage logs |

**Total:** 2 fichiers modifi√©s, 6 sections touch√©es

---

## ‚ùì Troubleshooting

### Erreur: "HoVerNetLoss() got an unexpected keyword argument 'lambda_magnitude'"

**Cause:** `hovernet_decoder.py` n'a pas √©t√© modifi√© correctement.

**Solution:** V√©rifier que `__init__` accepte `lambda_magnitude` param√®tre.

```python
# V√©rifier dans hovernet_decoder.py ligne ~240
def __init__(self, lambda_np=1.0, lambda_hv=2.0, lambda_nt=1.0, lambda_magnitude=5.0, adaptive=False):
    #                                                           ^^^^^^^^^^^^^^^^^^^^ DOIT √™tre pr√©sent
```

---

### Erreur: "unrecognized arguments: --lambda_magnitude"

**Cause:** `train_hovernet_family.py` n'a pas √©t√© modifi√© correctement.

**Solution:** V√©rifier que l'argument CLI est bien ajout√© ligne ~351.

```python
# V√©rifier dans train_hovernet_family.py ligne ~351
parser.add_argument('--lambda_magnitude', type=float, default=5.0,
                   help='Poids magnitude loss (Expert: 5.0 pour forcer gradients forts)')
```

---

### Magnitude reste √† 0.02 apr√®s 5 epochs

**Cause:** Bug #2 (masking) pas corrig√© correctement dans `magnitude_loss()`.

**Solution:** V√©rifier que la fonction utilise bien:
```python
loss = (mag_true - mag_pred)**2  # Erreur manuelle
weighted_loss = loss * mask.squeeze(1)  # Masque AVANT r√©duction
return weighted_loss.sum() / (mask.sum() + 1e-6)  # Normalisation cellules seulement
```

**PAS:**
```python
mag_loss_sum = F.mse_loss(mag_pred_masked, mag_target_masked, reduction='sum')  # ‚Üê BUGU√â
```

---

**STATUT:** ‚úÖ Code de modification pr√™t

**NEXT STEP:** Appliquer les fixes dans les 2 fichiers, puis lancer re-training
