# Historique Complet des Tests â€” Giant Blob (AJI 0.09)

**Date dÃ©but investigation:** 2025-12-24
**ProblÃ¨me:** AJI 0.09 vs objectif 0.60+ (1 instance au lieu de 8)
**Statut:** Investigation en cours

---

## ğŸ“Š Tests DÃ©jÃ  EffectuÃ©s (Chronologique)

### âœ… Test 1: HV Scaling (Ã—1 Ã  Ã—50) â€” NÃ‰GATIF

**Date:** 2025-12-24 (matin)
**Script:** `scripts/evaluation/test_hv_scaling.py`
**Objectif:** DÃ©terminer si amplifier HV amÃ©liore sÃ©paration instances

**MÃ©thode:**
```python
# Multiplier HV predictions par facteur (1x, 5x, 10x, 20x, 50x)
hv_scaled = hv_pred * scale_factor
energy = np.sqrt(hv_scaled[0]**2 + hv_scaled[1]**2)
instance_map = watershed(-energy, markers, mask=binary_mask)
```

**RÃ©sultats:**
| Scaling | Energy Range | Energy Mean | Peaks Found | AJI Mean |
|---------|--------------|-------------|-------------|----------|
| 1.0x | [0.0019, 0.0209] | 0.0095 | 137 | 0.0905 |
| 5.0x | [0.0093, 0.1043] | 0.0476 | 137 | 0.0905 |
| 10.0x | [0.0186, 0.2086] | 0.0953 | 137 | 0.0905 |
| 20.0x | [0.0371, 0.4171] | 0.1905 | 137 | 0.0905 |
| 50.0x | [0.0928, 1.0428] | 0.4763 | 137 | 0.0905 |

**Conclusion:** âŒ Scaling n'amÃ©liore PAS l'AJI (reste Ã  0.0905)

**Ce qu'on a appris:**
1. Le modÃ¨le dÃ©tecte CORRECTEMENT les 137 centres de cellules (peaks constants)
2. Le problÃ¨me n'est PAS juste une amplitude faible
3. Le problÃ¨me vient APRÃˆS la dÃ©tection des peaks (watershed ou GT comparison)

**HypothÃ¨ses Ã©liminÃ©es:**
- âŒ "Il suffit d'amplifier HV pour amÃ©liorer AJI"
- âŒ "Les peaks ne sont pas dÃ©tectÃ©s"

**Fichiers crÃ©Ã©s:**
- `docs/ANALYSE_TEST_SCALING_NEGATIF.md`

---

### âœ… Test 2: Visualisation Instance Maps â€” GIANT BLOB CONFIRMÃ‰

**Date:** 2025-12-24 (matin)
**Script:** `scripts/evaluation/visualize_instance_maps.py`
**Objectif:** Diagnostic visuel pour confirmer Giant Blob vs ID Mismatch

**MÃ©thode:**
```python
# Resize 224 â†’ 256 avec INTER_NEAREST (recommandation expert)
np_pred_256 = cv2.resize(np_pred, (256, 256), interpolation=cv2.INTER_NEAREST)
hv_pred_256 = np.stack([
    cv2.resize(hv_pred[0], (256, 256), interpolation=cv2.INTER_NEAREST),
    cv2.resize(hv_pred[1], (256, 256), interpolation=cv2.INTER_NEAREST)
])

# Post-processing watershed
inst_pred = post_process_hv(np_pred_256, hv_pred_256)

# Visualisation cÃ´te Ã  cÃ´te
fig, axes = plt.subplots(2, 3)
axes[0, 2].imshow(inst_pred, cmap=colormap)  # Instances PRED
axes[1, 2].imshow(inst_target, cmap=colormap)  # Instances GT
```

**RÃ©sultats (Ã‰chantillon 9):**
```
ğŸ” Analyse Ã©chantillon 9 (index 8)

Instances prÃ©dites: 1
Instances GT:       8

HV magnitude PRED: [0.0022, 0.0221]
HV magnitude GT:   [0.0000, 0.9992]

âŒ GIANT BLOB DÃ‰TECTÃ‰!
   Ratio magnitude: 0.022 / 0.5 = 4.4% (50Ã— trop faible)
```

**Visualisation gÃ©nÃ©rÃ©e:**
- `results/diagnostic_instance_maps_sample9.png`
- Colonne 1: H&E brut, NP masks
- Colonne 2: HV magnitude maps
- Colonne 3: **Instance maps (1 couleur PRED vs 8 couleurs GT)**

**Conclusion:** âœ… Giant Blob confirmÃ© (1 instance violette gÃ©ante)

**Ce qu'on a appris:**
1. Le watershed crÃ©e effectivement 1 instance au lieu de 8
2. HV magnitude 50Ã— trop faible (0.022 vs >0.5 attendu)
3. Les 137 peaks sont dÃ©tectÃ©s mais ne sÃ©parent pas les instances

**HypothÃ¨ses Ã©liminÃ©es:**
- âŒ "C'est un problÃ¨me de resize (INTER_LINEAR dÃ©truisant IDs)"
- âŒ "C'est un ID Mismatch (dÃ©calage spatial)"

**HypothÃ¨ses confirmÃ©es:**
- âœ… Giant Blob (fusion complÃ¨te en 1 instance)
- âœ… HV magnitude trop faible

**Fichiers crÃ©Ã©s:**
- `scripts/evaluation/visualize_instance_maps.py`
- `results/diagnostic_instance_maps_sample9.png`

---

### âœ… Test 3: VÃ©rification Architecture (Code Review) â€” CORRECTE

**Date:** 2025-12-24 (aprÃ¨s-midi)
**MÃ©thode:** Lecture manuelle des fichiers source
**Objectif:** VÃ©rifier que Tanh et Sobel sont prÃ©sents dans le code

**Fichiers vÃ©rifiÃ©s:**

#### 3.1. Tanh HV Branch
**Fichier:** `src/models/hovernet_decoder.py` (lignes 118-121)
```python
self.hv_head = nn.Sequential(
    DecoderHead(64, 2),
    nn.Tanh()  # âœ… PRÃ‰SENT - Force HV dans [-1, 1]
)
```

**Statut:** âœ… Tanh prÃ©sent et actif

---

#### 3.2. Sobel Gradient Loss
**Fichier:** `src/models/hovernet_decoder.py` (lignes 244-280)
```python
def gradient_loss(self, pred: torch.Tensor, target: torch.Tensor, mask: torch.Tensor = None):
    """
    MSGE avec opÃ©rateur Sobel pour signal amplifiÃ©.
    """
    # OpÃ©rateur Sobel (3Ã—3 kernel)
    sobel_h = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], ...)
    sobel_v = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], ...)

    # Convolution avec padding
    pred_grad_h = F.conv2d(pred_reshaped, sobel_h, padding=1)
    pred_grad_v = F.conv2d(pred_reshaped, sobel_v, padding=1)
    # ... masking and MSE ...
```

**Ligne 347 - Usage:**
```python
hv_gradient = self.gradient_loss(hv_pred, hv_target, mask=mask)
hv_loss = hv_l1 + 2.0 * hv_gradient  # Poids 2.0Ã— pour gradients
```

**Statut:** âœ… Sobel gradient loss implÃ©mentÃ© et actif (poids 2.0)

---

#### 3.3. DonnÃ©es v8 (Vraies Instances)
**Fichier:** `scripts/preprocessing/prepare_family_data_FIXED_v8.py` (lignes 190-213)
```python
def extract_instance_map(mask: np.ndarray) -> np.ndarray:
    """
    VRAIES INSTANCES (v8): Utilise IDs des canaux 1-4 directement
    (PAS connectedComponents qui fusionne cellules touchantes)
    """
    inst_map = np.zeros((256, 256), dtype=np.int32)
    instance_counter = 1

    # Canaux 1-4: instances dÃ©jÃ  annotÃ©es (VRAIES instances PanNuke)
    for c in range(1, 5):
        class_instances = mask[:, :, c]
        inst_ids = np.unique(class_instances)
        inst_ids = inst_ids[inst_ids > 0]

        for inst_id in inst_ids:
            inst_mask = class_instances == inst_id
            inst_map[inst_mask] = instance_counter
            instance_counter += 1
```

**Statut:** âœ… DonnÃ©es v8 utilisent vraies instances PanNuke (pas Bug #3)

---

**Conclusion Test 3:** âœ… Architecture complÃ¨te et correcte

**Ce qu'on a appris:**
1. Tout le code nÃ©cessaire est prÃ©sent
2. Tanh force bien HV dans [-1, 1]
3. Sobel gradient loss actif avec poids 2.0
4. DonnÃ©es v8 utilisent vraies instances

**HypothÃ¨ses Ã©liminÃ©es:**
- âŒ "Tanh manquant dans le code"
- âŒ "Sobel pas implÃ©mentÃ©"
- âŒ "Bug #3 (connectedComponents fusionne cellules)"

**Nouvelle hypothÃ¨se Ã©mergente:**
- âš ï¸ "Checkpoint entraÃ®nÃ© AVANT ajout Sobel/Tanh dans le code"

---

### âœ… Test 4: Revue Documentation â€” SOBEL FIX DATÃ‰ 2025-12-23

**Date:** 2025-12-24 (aprÃ¨s-midi)
**MÃ©thode:** Lecture docs existantes
**Objectif:** VÃ©rifier si problÃ¨me dÃ©jÃ  documentÃ©

**Documents consultÃ©s:**

#### 4.1. FIX_SOBEL_GRADIENT_LOSS.md
**Contenu clÃ©:**
```markdown
Date: 2025-12-23
ProblÃ¨me: AJI 0.07 vs cible 0.80
Cause racine: Signal gradient_loss trop faible â†’ HV maps "douces"

Solution: OpÃ©rateur Sobel (3Ã—3 kernel)
- DiffÃ©rences finies: signal ~0.01 (faible)
- Sobel: signal ~0.04 (4Ã— plus fort)
```

**Statut:** âœ… ProblÃ¨me EXACT dÃ©jÃ  documentÃ© et rÃ©solu le 2025-12-23

---

#### 4.2. ARCHITECTURE_HV_ACTIVATION.md
**Date:** 2025-12-21
**DÃ©cision initiale:** Garder architecture SANS Tanh (tests empiriques OK)

**Note importante:**
> Cette dÃ©cision a Ã©tÃ© CHANGÃ‰E plus tard (ligne 118-121 hovernet_decoder.py AJOUTE Tanh)

**Statut:** âš ï¸ DÃ©cision rÃ©visÃ©e, Tanh ajoutÃ© ultÃ©rieurement

---

#### 4.3. GIANT_BLOB_RESOLUTION_PLAN.md (crÃ©Ã© aujourd'hui)
**HypothÃ¨ses formulÃ©es:**
1. ModÃ¨le entraÃ®nÃ© AVANT Sobel fix (70% probabilitÃ©)
2. Watershed params trop conservateurs (15%)
3. Gaussian smoothing trop agressif (15%)

**Statut:** âœ… HypothÃ¨se #1 la plus probable

---

**Conclusion Test 4:** âœ… Documentation confirme hypothÃ¨se temporelle

**Ce qu'on a appris:**
1. Sobel fix implÃ©mentÃ© le 2025-12-23
2. Tanh ajoutÃ© aprÃ¨s dÃ©cision initiale (post 2025-12-21)
3. ProblÃ¨me actuel identique Ã  celui documentÃ© dans FIX_SOBEL_GRADIENT_LOSS.md

**HypothÃ¨se renforcÃ©e:**
- âœ… **"Checkpoint entraÃ®nÃ© AVANT 2025-12-23"** (70% â†’ 90% probabilitÃ©)

---

## ğŸ” Tests EN ATTENTE (Non encore effectuÃ©s)

### â³ Test 5: VÃ©rification HV Targets .npz

**Script crÃ©Ã©:** `scripts/validation/verify_hv_targets_npz.py`
**Commande:**
```bash
conda activate cellvit
python scripts/validation/verify_hv_targets_npz.py --family epidermal
```

**Objectif:** VÃ©rifier que targets stockÃ©s sont bien float32 [-1, 1]

**Checks automatiques:**
1. Dtype (doit Ãªtre float32, pas int8)
2. Range (doit Ãªtre [-1.0, 1.0])
3. SymÃ©trie (mean â‰ˆ 0.0)
4. Variance (std dans [0.3, 0.7])

**ScÃ©narios possibles:**

**A. âœ… Targets corrects:**
```
âœ… Dtype: float32
âœ… Range: [-1.000, 1.000]
âœ… Mean: 0.0006 (centrÃ©)
âœ… Std: 0.4567 (bonne dynamique)
```
â†’ Confirme problÃ¨me vient du checkpoint, pas des donnÃ©es
â†’ Passer Ã  Test 6

**B. âŒ Targets incorrects (int8):**
```
âŒ Dtype: int8
âŒ Range: [-127, 127]
```
â†’ Bug normalization (donnÃ©es v8 corrompues)
â†’ RÃ©gÃ©nÃ©rer v9 AVANT rÃ©-entraÃ®nement

**C. âš ï¸ Variance trop faible:**
```
âœ… Dtype: float32
âœ… Range: [-1.0, 1.0]
âš ï¸ Std: 0.15 (attendu: >0.3)
```
â†’ Gaussian smoothing trop agressif (sigma=0.5)
â†’ RÃ©gÃ©nÃ©rer v9 sans smoothing

**Statut:** â³ NON EXÃ‰CUTÃ‰ (environnement Claude incompatible)

---

### â³ Test 6: VÃ©rification Date Checkpoint

**Commande:**
```bash
find models/checkpoints -name "hovernet_epidermal_best.pth" -exec ls -l {} \;
```

**Objectif:** Comparer date crÃ©ation checkpoint vs date Sobel fix (2025-12-23)

**ScÃ©narios:**

**A. Date < 2025-12-23:**
â†’ âœ… Confirme "mismatch version logique"
â†’ RÃ©-entraÃ®nement rÃ©soudra le problÃ¨me
â†’ Passer Ã  Test 7 (rÃ©-entraÃ®nement)

**B. Date â‰¥ 2025-12-23:**
â†’ âš ï¸ Checkpoint entraÃ®nÃ© AVEC Sobel, mais performances mauvaises
â†’ Investiguer logs training (Test 6b)

**Statut:** â³ NON EXÃ‰CUTÃ‰ (tentative Ã©chouÃ©e: fichier introuvable)

---

### â³ Test 6b: VÃ©rification Logs Training

**Fichier:** `results/training_hovernet_epidermal.log` (ou Ã©quivalent)

**Commande:**
```bash
grep -i "hv_gradient" results/training_hovernet_epidermal.log
grep -i "sobel" results/training_hovernet_epidermal.log
```

**Objectif:** VÃ©rifier si Sobel gradient loss Ã©tait actif durant training

**Attendu si Sobel actif:**
```
Epoch 1: hv_l1=0.45, hv_gradient=0.12, hv_loss=0.69
Epoch 10: hv_l1=0.23, hv_gradient=0.08, hv_loss=0.39
```

**Si Sobel absent:**
â†’ âœ… Confirme checkpoint prÃ©-Sobel
â†’ RÃ©-entraÃ®nement requis

**Statut:** â³ NON EXÃ‰CUTÃ‰ (conditionnel Ã  Test 6 rÃ©sultat B)

---

### â³ Test 7: RÃ©-entraÃ®nement avec Sobel (lambda_hv=3.0)

**Commande recommandÃ©e (Expert):**
```bash
python scripts/training/train_hovernet_family.py \
    --family epidermal \
    --epochs 50 \
    --augment \
    --lambda_np 1.0 \
    --lambda_hv 3.0 \
    --lambda_nt 1.0 \
    --batch_size 16
```

**Changement clÃ©:** `lambda_hv 2.0 â†’ 3.0` (augmentÃ©)

**DurÃ©e:** ~40 minutes (571 samples epidermal)

**MÃ©triques Ã  surveiller:**
| Epoch | HV MSE Attendu | InterprÃ©tation |
|-------|----------------|----------------|
| 1-5 | 0.30-0.40 | Normal |
| 10-20 | 0.15-0.25 | Convergence |
| 30-50 | **0.05-0.10** | âœ… Sobel actif (descente lente = bon signe) |

**Citation expert:**
> "Si [HV MSE] descend plus lentement ou reste plus haute qu'avant tout en Ã©tant stable, c'est bon signe : le modÃ¨le travaille plus dur sur les dÃ©tails complexes du gradient."

**Statut:** â³ NON EXÃ‰CUTÃ‰ (en attente validation Tests 5 et 6)

---

### â³ Test 8: Validation Post-Training

**8a. Test sur Training Data:**
```bash
python scripts/evaluation/test_on_training_data.py \
    --family epidermal \
    --checkpoint models/checkpoints/hovernet_epidermal_best.pth \
    --n_samples 10
```

**Attendu:**
| MÃ©trique | Avant | AprÃ¨s | AmÃ©lioration |
|----------|-------|-------|--------------|
| HV Magnitude | 0.022 | >0.50 | +2200% |

---

**8b. Visualisation Instance Maps:**
```bash
python scripts/evaluation/visualize_instance_maps.py
```

**Attendu:**
| MÃ©trique | Avant | AprÃ¨s | AmÃ©lioration |
|----------|-------|-------|--------------|
| Instances PRED | 1 | 5-8 | +500-700% |

---

**8c. AJI Ground Truth:**
```bash
python scripts/evaluation/test_aji_v8.py \
    --family epidermal \
    --checkpoint models/checkpoints/hovernet_epidermal_best.pth \
    --n_samples 50
```

**Attendu:**
| MÃ©trique | Avant | AprÃ¨s | AmÃ©lioration |
|----------|-------|-------|--------------|
| AJI | 0.09 | >0.60 | +567% |
| PQ | 0.10 | >0.65 | +550% |

**Statut:** â³ NON EXÃ‰CUTÃ‰ (aprÃ¨s Test 7)

---

## ğŸ“ˆ Graphe de DÃ©pendances des Tests

```
Test 1 (Scaling) â”€â”€â”€â”€â”€â”€â”
Test 2 (Visualisation) â”¤â”€â”€â”€â†’ Giant Blob confirmÃ©
Test 3 (Architecture)  â”¤     HV magnitude 0.022
Test 4 (Documentation) â”˜
         â”‚
         â–¼
Test 5 (HV Targets .npz) â† CRITIQUE - Point de dÃ©cision
         â”‚
         â”œâ”€ âœ… Targets OK â”€â”€â”€â”€â”€â†’ Test 6 (Date Checkpoint)
         â”‚                              â”‚
         â”‚                              â”œâ”€ < 2025-12-23 â”€â†’ Test 7 (RÃ©-entraÃ®nement)
         â”‚                              â”‚                          â”‚
         â”‚                              â””â”€ â‰¥ 2025-12-23 â”€â†’ Test 6b (Logs) â”€â†’ Test 7
         â”‚                                                          â”‚
         â””â”€ âŒ Targets KO â”€â”€â”€â”€â†’ STOP â”€â”€â†’ RÃ©gÃ©nÃ©ration v9 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                                                 â–¼
                                         Test 7 (RÃ©-entraÃ®nement)
                                                 â”‚
                                                 â–¼
                                         Test 8a/b/c (Validation)
                                                 â”‚
                                                 â–¼
                                         âœ… AJI 0.60+ RÃ‰SOLU
```

---

## ğŸ¯ HypothÃ¨ses Actuelles (Mise Ã  Jour)

### HypothÃ¨se #1: Checkpoint PrÃ©-Sobel (90% probabilitÃ©) âœ… PROBABLE

**Preuves:**
1. âœ… Sobel fix datÃ© 2025-12-23 (FIX_SOBEL_GRADIENT_LOSS.md)
2. âœ… Code actuel a Sobel implÃ©mentÃ©
3. âœ… HV magnitude 0.022 = signature modÃ¨le prÃ©-Sobel
4. â³ Date checkpoint non vÃ©rifiÃ©e (Test 6 en attente)

**Si confirmÃ©:**
â†’ RÃ©-entraÃ®nement avec lambda_hv=3.0 (Test 7)
â†’ PrÃ©diction expert: AJI 0.60+ fortement probable

---

### HypothÃ¨se #2: Watershed Params Conservateurs (5% probabilitÃ©) âŒ IMPROBABLE

**Contre-preuves:**
1. âŒ Scaling Ã—50 n'amÃ©liore PAS l'AJI (Test 1)
2. âŒ 137 peaks dÃ©tectÃ©s (modÃ¨le "voit" les cellules)
3. âŒ HV magnitude 0.022 trop faible mÃªme pour watershed optimal

**Statut:** HypothÃ¨se Ã©cartÃ©e (Test 1 nÃ©gatif)

---

### HypothÃ¨se #3: Gaussian Smoothing Agressif (5% probabilitÃ©) âŒ IMPROBABLE

**Avis expert:**
> "Sigma 0.5 trÃ¨s lÃ©ger, sert Ã  Ã©viter aliasing. Ne PAS le supprimer. Vrai problÃ¨me: Sobel au training, pas smoothing au preprocessing."

**Contre-preuves:**
1. âŒ Sigma 0.5 considÃ©rÃ© optimal par expert
2. âŒ Smoothing Ã©vite crÃ©nelage pixels (nÃ©cessaire pour watershed)

**Statut:** HypothÃ¨se Ã©cartÃ©e (recommandation expert)

**Test conditionnel:** Si Test 5 montre std < 0.3, rÃ©gÃ©nÃ©rer sans smoothing

---

## ğŸ”‘ Conclusion Actuelle

**Ã‰tat de l'investigation:**
- Tests effectuÃ©s: 4/8 (50%)
- Tests critiques restants: 2 (Tests 5 et 6)
- HypothÃ¨se principale: 90% confiance (checkpoint prÃ©-Sobel)

**Prochaine action CRITIQUE:**
â†’ **Test 5: VÃ©rifier HV targets .npz**

**Si Test 5 âœ…:**
â†’ Test 6 â†’ Test 7 â†’ RÃ©solution probable

**Si Test 5 âŒ:**
â†’ RÃ©gÃ©nÃ©ration v9 â†’ Test 7 â†’ RÃ©solution

**Confiance rÃ©solution:** Ã‰levÃ©e (expert + documentation alignÃ©s)

---

## ğŸ“ Fichiers CrÃ©Ã©s Durant Investigation

| Fichier | Type | Description |
|---------|------|-------------|
| `scripts/evaluation/test_hv_scaling.py` | Test | Scaling HV Ã—1 Ã  Ã—50 |
| `scripts/evaluation/visualize_instance_maps.py` | Diagnostic | Visualisation Giant Blob |
| `scripts/validation/verify_hv_targets_npz.py` | VÃ©rification | Check dtype/range targets |
| `docs/ANALYSE_TEST_SCALING_NEGATIF.md` | Doc | Analyse test scaling |
| `docs/GIANT_BLOB_RESOLUTION_PLAN.md` | Plan | 3 hypothÃ¨ses + actions |
| `docs/PLAN_VERIFICATION_HOVERNET.md` | Plan | 5 Ã©tapes vÃ©rification |
| `docs/DECISION_RE_ENTRAINEMENT.md` | SynthÃ¨se | Consensus Claude+Expert |
| `docs/HISTORIQUE_TESTS_GIANT_BLOB.md` | **Ce fichier** | Historique complet |

---

**DerniÃ¨re mise Ã  jour:** 2025-12-24
**Prochaine action:** ExÃ©cuter Test 5 (verify_hv_targets_npz.py)
