# CellViT-Optimus â€” Contexte Projet

> **IMPORTANT : Ce fichier est la source de vÃ©ritÃ© du projet.**
>
> Claude doit maintenir ce fichier Ã  jour avec toute information importante :
> - DÃ©cisions techniques prises durant le dÃ©veloppement
> - ProblÃ¨mes rencontrÃ©s et solutions appliquÃ©es
> - Changements d'architecture ou de stratÃ©gie
> - DÃ©pendances ajoutÃ©es et leurs versions
> - Bugs connus et workarounds
> - Toute information qui serait utile pour reprendre le contexte
>
> **Si une information est jugÃ©e importante pour la continuitÃ© du projet, elle doit Ãªtre ajoutÃ©e ici.**

> **OBLIGATOIRE : Avant toute implÃ©mentation, Claude DOIT lire le fichier `CellViT-Optimus_Specifications.md` et s'assurer que le code respecte les spÃ©cifications techniques dÃ©finies.**

---

## Vue d'ensemble

**CellViT-Optimus** est un systÃ¨me d'assistance au triage histopathologique. Il ne remplace pas le pathologiste mais l'aide Ã  :
- Prioriser les lames et rÃ©gions Ã  forte valeur diagnostique
- RÃ©duire le temps de lecture
- SÃ©curiser la dÃ©cision grÃ¢ce Ã  une maÃ®trise explicite de l'incertitude

**Statut :** POC / Exploration
**Objectif immÃ©diat :** CrÃ©er un prototype dÃ©montrable pour discussions avec professionnels de santÃ©

---

## Architecture Technique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      LAME H&E (WSI)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              COUCHE 1 â€” EXTRACTION SÃ‰MANTIQUE                  â”‚
â”‚                     H-OPTIMUS-0 (gelÃ©)                         â”‚
â”‚  â€¢ EntrÃ©e : tuiles 224Ã—224 @ 0.5 MPP                          â”‚
â”‚  â€¢ Sortie : CLS token (1536) + Patches (256Ã—1536)             â”‚
â”‚  â€¢ ViT-Giant/14, 1.1 milliard paramÃ¨tres                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â–¼                                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  COUCHE 2A â€” FLUX GLOBAL    â”‚        â”‚  COUCHE 2B â€” FLUX LOCAL     â”‚
â”‚       OrganHead             â”‚        â”‚   5 HoVer-Net SpÃ©cialisÃ©s   â”‚
â”‚                             â”‚        â”‚                             â”‚
â”‚  â€¢ CLS token â†’ MLP          â”‚        â”‚  â€¢ Patches â†’ Router         â”‚
â”‚  â€¢ Classification organe    â”‚        â”‚  â€¢ Router â†’ Famille         â”‚
â”‚  â€¢ 19 organes PanNuke       â”‚        â”‚  â€¢ HoVer-Net spÃ©cialisÃ©     â”‚
â”‚  âœ… Accuracy 99.94%         â”‚        â”‚  â€¢ NP/HV/NT par famille     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                      â”‚
          â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚    â”‚
          â–¼    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ROUTAGE PAR FAMILLE                         â”‚
â”‚                                                                â”‚
â”‚  OrganHead prÃ©dit l'organe â†’ Router sÃ©lectionne le dÃ©codeur   â”‚
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”‚ Digestif â”‚ â”‚Glandulaireâ”‚ â”‚Urologiqueâ”‚ â”‚Respirat. â”‚ â”‚Ã‰piderm.  â”‚
â”‚  â”‚ HoVerNet â”‚ â”‚ HoVerNet â”‚ â”‚ HoVerNet â”‚ â”‚ HoVerNet â”‚ â”‚ HoVerNet â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              COUCHE 3 â€” SÃ‰CURITÃ‰ & INCERTITUDE                 â”‚
â”‚                                                                â”‚
â”‚  â€¢ Incertitude alÃ©atorique (entropie NP/HV)                   â”‚
â”‚  â€¢ Incertitude Ã©pistÃ©mique (Conformal Prediction)             â”‚
â”‚  â€¢ DÃ©tection OOD (distance latente Mahalanobis)               â”‚
â”‚  â€¢ Calibration locale (Temperature Scaling par centre)        â”‚
â”‚                                                                â”‚
â”‚  Sortie : {Fiable | Ã€ revoir | Hors domaine}                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              COUCHE 4 â€” INTERACTION EXPERT                     â”‚
â”‚                                                                â”‚
â”‚  â€¢ SÃ©lection automatique des ROIs                             â”‚
â”‚  â€¢ Visualisation (cellules + heatmaps attention)              â”‚
â”‚  â€¢ Validation humaine finale                                   â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Composants ModÃ¨les

### H-optimus-0 (Backbone)
| Attribut | Valeur |
|----------|--------|
| Source | Bioptimus (HuggingFace) |
| Architecture | ViT-Giant/14 avec 4 registres |
| ParamÃ¨tres | 1.1 milliard |
| EntrÃ©e | 224Ã—224 pixels @ 0.5 MPP |
| Sortie | Embedding 1536-dim |
| Licence | Apache 2.0 (usage commercial OK) |

**Normalisation requise :**
```python
mean = (0.707223, 0.578729, 0.703617)
std = (0.211883, 0.230117, 0.177517)
```

**Chargement :**
```python
import timm
model = timm.create_model(
    "hf-hub:bioptimus/H-optimus-0",
    pretrained=True,
    init_values=1e-5,
    dynamic_img_size=False
)
```

### CellViT (RÃ©fÃ©rence segmentation)
| Attribut | Valeur |
|----------|--------|
| Source | TIO-IKIM (GitHub) |
| Architecture | U-Net + ViT encoder |
| EntrÃ©e inference | 1024Ã—1024 pixels |
| Classes | 5 (Neoplastic, Inflammatory, Connective, Dead, Epithelial) |

---

## Environnement de DÃ©veloppement

### Configuration validÃ©e
| Composant | Version |
|-----------|---------|
| OS | WSL2 Ubuntu 24.04.2 LTS |
| GPU | RTX 4070 SUPER (12.9 GB VRAM) |
| NVIDIA Driver | 566.36 |
| CUDA | 12.7 (systÃ¨me) / 12.4 (PyTorch) |
| Docker | 29.1.3 (natif, pas Docker Desktop) |
| NVIDIA Container Toolkit | InstallÃ© |
| Python | 3.10 (via Miniconda) |
| Conda | 25.11.1 |
| PyTorch | 2.6.0+cu124 |
| Environnement conda | `cellvit` |

### Contraintes VRAM (12 GB)
| TÃ¢che | VRAM estimÃ©e | FaisabilitÃ© |
|-------|--------------|-------------|
| InfÃ©rence H-optimus-0 (FP16, batch=1) | ~3-4 GB | âœ… OK |
| InfÃ©rence H-optimus-0 (FP16, batch=8) | ~6-8 GB | âœ… OK |
| EntraÃ®nement dÃ©codeur (backbone gelÃ©) | ~8-10 GB | âš ï¸ SerrÃ© |
| EntraÃ®nement complet avec gradients | >16 GB | âŒ Impossible |

---

## Sources de DonnÃ©es

### Branche Cellule (Segmentation)
| Dataset | Contenu | Usage |
|---------|---------|-------|
| **PanNuke** | ~200k noyaux, 5 types, 19 organes | EntraÃ®nement NP/HV/NT |
| **MoNuSeG** | Multi-organes | Robustesse segmentation |
| **CoNSeP** | Morphologie colique | Calibration HV |

### Branche Lame (Biomarqueurs)
| Dataset | Contenu | Usage |
|---------|---------|-------|
| **TCGA** | Milliers de WSI + donnÃ©es molÃ©culaires | EntraÃ®nement AMIL |
| **CPTAC** | WSI + protÃ©omique | TÃªtes expertes |

---

## Structure Projet Cible

```
cellvit-optimus/
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.base
â”‚   â”œâ”€â”€ Dockerfile.worker
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ calibration/
â”‚   â”œâ”€â”€ ood_detection/
â”‚   â””â”€â”€ benchmarking/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â””â”€â”€ integration/
â”œâ”€â”€ configs/
â”œâ”€â”€ notebooks/
â””â”€â”€ src/
    â”œâ”€â”€ models/
    â”œâ”€â”€ data/
    â”œâ”€â”€ inference/
    â””â”€â”€ utils/
```

---

## DÃ©cisions Techniques ClÃ©s

1. **Backbone gelÃ©** â€” H-optimus-0 n'est jamais fine-tunÃ©, seules les tÃªtes s'entraÃ®nent
2. **HoVer-Net par famille** â€” 5 dÃ©codeurs spÃ©cialisÃ©s (Glandulaire, Digestive, Urologique, Respiratoire, Ã‰pidermoÃ¯de)
3. **Tiling adaptatif** â€” Recall 0.999 sur tissu tumoral, garde-fou basse rÃ©solution
4. **Cache d'embeddings versionnÃ©** â€” Hash [Backbone]+[Preprocessing]+[Resolution]+[Date]
5. **Distillation limitÃ©e au prÃ©-triage** â€” Le modÃ¨le original reste obligatoire pour diagnostic
6. **Cartes HV prÃ©-calculÃ©es** â€” Stockage int8 pour Ã©conomie mÃ©moire (voir section ci-dessous)

---

## âš ï¸ GUIDE CRITIQUE: PrÃ©paration des DonnÃ©es pour l'EntraÃ®nement

> **ATTENTION: Cette section est OBLIGATOIRE Ã  lire avant tout entraÃ®nement.**
>
> Trois bugs critiques ont causÃ© des semaines de travail perdu. Ne pas rÃ©pÃ©ter ces erreurs.

### Vue d'ensemble du Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIPELINE DE PRÃ‰PARATION DES DONNÃ‰ES                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  1. IMAGE BRUTE (uint8 [0-255])                                        â”‚
â”‚         â”‚                                                               â”‚
â”‚         â–¼                                                               â”‚
â”‚  2. CONVERSION OBLIGATOIRE â†’ uint8                                     â”‚
â”‚     âš ï¸ ToPILImage multiplie les floats par 255!                        â”‚
â”‚         â”‚                                                               â”‚
â”‚         â–¼                                                               â”‚
â”‚  3. TRANSFORM TORCHVISION (identique train/inference)                  â”‚
â”‚     â€¢ ToPILImage()                                                      â”‚
â”‚     â€¢ Resize((224, 224))                                                â”‚
â”‚     â€¢ ToTensor()                                                        â”‚
â”‚     â€¢ Normalize(mean=HOPTIMUS_MEAN, std=HOPTIMUS_STD)                  â”‚
â”‚         â”‚                                                               â”‚
â”‚         â–¼                                                               â”‚
â”‚  4. H-OPTIMUS-0: forward_features()                                    â”‚
â”‚     âš ï¸ JAMAIS blocks[X] directement! (pas de LayerNorm)               â”‚
â”‚         â”‚                                                               â”‚
â”‚         â–¼                                                               â”‚
â”‚  5. FEATURES NORMALISÃ‰ES (CLS std ~0.77)                               â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Constantes de Normalisation H-optimus-0

```python
# OBLIGATOIRE: Ces valeurs sont FIXES et ne doivent JAMAIS changer
HOPTIMUS_MEAN = (0.707223, 0.578729, 0.703617)
HOPTIMUS_STD = (0.211883, 0.230117, 0.177517)
```

### BUG #1: ToPILImage avec float64 (CORRIGÃ‰)

**ProblÃ¨me:** `ToPILImage()` multiplie les floats par 255.

```python
# âŒ BUG: ToPILImage avec float64 [0,255]
img_float64 = np.array([100, 150, 200], dtype=np.float64)
# ToPILImage pense que c'est [0,1] â†’ multiplie par 255
# â†’ [25500, 38250, 51000] â†’ overflow uint8 â†’ COULEURS FAUSSES!

# âœ… SOLUTION: Toujours convertir en uint8 AVANT ToPILImage
if image.dtype != np.uint8:
    image = image.clip(0, 255).astype(np.uint8)
```

**Impact:** Features corrompues â†’ modÃ¨les inutilisables â†’ rÃ©-entraÃ®nement complet.

### BUG #2: LayerNorm Mismatch (CORRIGÃ‰)

**ProblÃ¨me:** IncohÃ©rence entre extraction et infÃ©rence.

```python
# âŒ BUG: Hooks sur blocks[23] (SANS LayerNorm final)
# extract_features.py utilisait:
output = model.blocks[23](x)  # CLS std ~0.28

# Mais l'infÃ©rence utilisait:
output = model.forward_features(x)  # CLS std ~0.77

# â†’ Ratio 2.7x entre train et inference â†’ prÃ©dictions FAUSSES!

# âœ… SOLUTION: Utiliser forward_features() PARTOUT
features = backbone.forward_features(tensor)  # Inclut LayerNorm
```

**VÃ©rification:** CLS token std doit Ãªtre entre **0.70 et 0.90**.

### BUG #3: Training/Eval Instance Mismatch (DÃ‰COUVERT 2025-12-21)

**ProblÃ¨me:** Le modÃ¨le crÃ©e UNE INSTANCE GÃ‰ANTE au lieu de plusieurs petites instances sÃ©parÃ©es.

**Cause racine:** IncohÃ©rence entre la gÃ©nÃ©ration des targets d'entraÃ®nement et l'Ã©valuation Ground Truth:

```python
# âŒ TRAINING PIPELINE (prepare_family_data.py):
# Utilise connectedComponents qui FUSIONNE les cellules qui se touchent
np_mask = mask[:, :, 1:].sum(axis=-1) > 0  # Union binaire
_, labels = cv2.connectedComponents(binary_uint8)
hv_targets = compute_hv_maps(labels)  # HV maps pour instances FUSIONNÃ‰ES

# âŒ Ã‰VALUATION GROUND TRUTH (convert_annotations.py):
# Utilise Ã©galement connectedComponents pour matcher le training
# MAIS le modÃ¨le prÃ©dit des gradients HV FAIBLES car il a appris des instances fusionnÃ©es!

# RÃ©sultat: Watershed post-processing ne peut PAS sÃ©parer les cellules
# car les gradients HV ne sont pas assez forts aux frontiÃ¨res
```

**Impact visuel (image_00002_diagnosis.png):**
- GT: 9 instances sÃ©parÃ©es (connectedComponents sur union)
- PrÃ©diction: 1 INSTANCE VIOLETTE GÃ‰ANTE couvrant toute l'image
- Recall: 7.69% (TP: 9, FP: 53, FN: 108)

**ProblÃ¨me fondamental:**

PanNuke contient les VRAIES instances sÃ©parÃ©es dans les canaux 1-4:
- Canal 1: IDs d'instances Neoplastic [88, 96, 107, ...]
- Canal 2: IDs d'instances Inflammatory
- etc.

Mais le training **IGNORE** ces IDs et recalcule avec `connectedComponents`, fusionnant les cellules qui se touchent!

**Solutions possibles:**

1. **Court terme**: Ajuster les paramÃ¨tres watershed (edge_threshold, dist_threshold)
   - Peu de chances de succÃ¨s si les gradients HV sont vraiment faibles
   - Voir `scripts/evaluation/test_watershed_params.py`

2. **Long terme**: RÃ©-entraÃ®ner avec les VRAIES instances PanNuke
   ```python
   # âœ… SOLUTION CIBLE:
   # Extraire les IDs d'instances de PanNuke au lieu de connectedComponents
   inst_map = np.zeros((256, 256), dtype=np.int32)
   instance_counter = 1

   # Canaux 1-4: instances dÃ©jÃ  annotÃ©es
   for c in range(1, 5):
       class_instances = mask[:, :, c]
       inst_ids = np.unique(class_instances)
       inst_ids = inst_ids[inst_ids > 0]
       for inst_id in inst_ids:
           inst_mask = class_instances == inst_id
           inst_map[inst_mask] = instance_counter
           instance_counter += 1

   # Canal 5 (Epithelial) est binaire, garder connectedComponents
   _, epithelial_labels = cv2.connectedComponents(mask[:, :, 5])
   # Fusionner avec inst_map

   # Maintenant compute_hv_maps() aura des frontiÃ¨res RÃ‰ELLES entre cellules
   hv_targets = compute_hv_maps(inst_map)
   ```

   **CoÃ»t**: RÃ©-entraÃ®nement complet des 5 familles HoVer-Net (~10 heures)

**Diagnostics crÃ©Ã©s:**
- `results/DIAGNOSTIC_REPORT_LOW_RECALL.md`: Rapport complet avec analyse visuelle
- `image_00002_diagnosis.png`: Visualisation GT vs PrÃ©dictions (1 instance gÃ©ante)
- `scripts/evaluation/visualize_raw_predictions.py`: Inspection NP/HV/gradients
- `scripts/evaluation/test_watershed_params.py`: Sweep paramÃ¨tres watershed

**Statut:** âš ï¸ BLOQUANT pour Ã©valuation Ground Truth - DÃ©cision requise sur stratÃ©gie

### Transform Canonique (Ã€ COPIER)

```python
from torchvision import transforms

HOPTIMUS_MEAN = (0.707223, 0.578729, 0.703617)
HOPTIMUS_STD = (0.211883, 0.230117, 0.177517)

def create_hoptimus_transform():
    """
    Transform CANONIQUE pour H-optimus-0.

    DOIT Ãªtre IDENTIQUE dans:
    - scripts/preprocessing/extract_features.py
    - src/inference/hoptimus_hovernet.py
    - src/inference/optimus_gate_inference.py
    - src/inference/optimus_gate_inference_multifamily.py
    - scripts/validation/test_organ_prediction_batch.py
    """
    return transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=HOPTIMUS_MEAN, std=HOPTIMUS_STD),
    ])

def preprocess_image(image: np.ndarray) -> torch.Tensor:
    """
    PrÃ©traitement CANONIQUE d'une image.

    Args:
        image: Image RGB (H, W, 3) - uint8 ou float

    Returns:
        Tensor (1, 3, 224, 224) normalisÃ©
    """
    # Ã‰TAPE CRITIQUE: Convertir en uint8 AVANT ToPILImage
    if image.dtype != np.uint8:
        if image.max() <= 1.0:
            image = (image * 255).clip(0, 255).astype(np.uint8)
        else:
            image = image.clip(0, 255).astype(np.uint8)

    transform = create_hoptimus_transform()
    tensor = transform(image).unsqueeze(0)

    return tensor
```

### Extraction des Features (Ã€ COPIER)

```python
def extract_features(backbone, tensor: torch.Tensor) -> torch.Tensor:
    """
    Extraction CANONIQUE des features H-optimus-0.

    IMPORTANT: Utilise forward_features() qui inclut le LayerNorm final.

    Args:
        backbone: ModÃ¨le H-optimus-0
        tensor: Image prÃ©traitÃ©e (B, 3, 224, 224)

    Returns:
        Features (B, 261, 1536) - CLS token + 256 patch tokens
    """
    with torch.no_grad():
        # âœ… forward_features() inclut le LayerNorm final
        features = backbone.forward_features(tensor)

    return features.float()

# RÃ©cupÃ©ration des tokens
cls_token = features[:, 0, :]      # (B, 1536) - Pour OrganHead
patch_tokens = features[:, 1:257, :]  # (B, 256, 1536) - Pour HoVer-Net
```

### Script de VÃ©rification

```bash
# VÃ©rifier que les features sont correctes AVANT entraÃ®nement
python scripts/validation/verify_features.py --features_dir data/cache/pannuke_features

# Sortie attendue:
# âœ… Fold 0: CLS std = 0.768 (attendu: 0.70-0.90)
# âœ… Fold 1: CLS std = 0.771 (attendu: 0.70-0.90)
# âœ… Fold 2: CLS std = 0.769 (attendu: 0.70-0.90)
```

### Checklist Avant EntraÃ®nement

| # | VÃ©rification | Commande |
|---|--------------|----------|
| 1 | Images en uint8 | `print(image.dtype)` â†’ `uint8` |
| 2 | Transform identique | Comparer avec `create_hoptimus_transform()` |
| 3 | forward_features() utilisÃ© | Pas de hooks sur `blocks[X]` |
| 4 | CLS std ~0.77 | `verify_features.py` |
| 5 | ClÃ© 'features' dans .npz | `data.keys()` â†’ `['features', ...]` |

### Format des Features SauvegardÃ©es

```python
# Structure attendue dans les fichiers .npz
{
    'features': np.array,  # (N, 261, 1536) - CLS + 256 patches
    # ou pour compatibilitÃ© ancienne:
    'layer_24': np.array,  # MÃªme format
}

# Les scripts d'entraÃ®nement supportent les deux clÃ©s:
if 'features' in data:
    features = data['features']
elif 'layer_24' in data:
    features = data['layer_24']
```

### Scripts de RÃ©fÃ©rence

| Script | RÃ´le | VÃ©rifie |
|--------|------|---------|
| `scripts/preprocessing/extract_features.py` | Extraction features | uint8 + forward_features() |
| `scripts/validation/verify_features.py` | VÃ©rification CLS std | Range 0.70-0.90 |
| `scripts/validation/test_organ_prediction_batch.py` | Test infÃ©rence | CohÃ©rence train/inference |

### Commandes de RÃ©-extraction ComplÃ¨te

```bash
# Si les features sont corrompues, rÃ©-extraire les 3 folds:

# 1. Supprimer les anciennes features
rm -rf data/cache/pannuke_features/*.npz

# 2. RÃ©-extraire chaque fold (avec chunking pour Ã©conomiser la RAM)
for fold in 0 1 2; do
    python scripts/preprocessing/extract_features.py \
        --data_dir /home/amar/data/PanNuke \
        --fold $fold \
        --batch_size 8 \
        --chunk_size 500
done

# 3. VÃ©rifier
python scripts/validation/verify_features.py --features_dir data/cache/pannuke_features

# 4. RÃ©-entraÃ®ner OrganHead
python scripts/training/train_organ_head.py --folds 0 1 2 --epochs 50

# 5. RÃ©-entraÃ®ner HoVer-Net par famille
for family in glandular digestive urologic respiratory epidermal; do
    python scripts/training/train_hovernet_family.py --family $family --epochs 50 --augment
done
```

---

## Cartes HV (Horizontal/Vertical) â€” SÃ©paration d'Instances

### ProblÃ¨me
Dans les tissus denses, les noyaux se chevauchent. Un masque binaire ne permet pas de distinguer oÃ¹ finit un noyau et oÃ¹ commence le suivant.

### Solution HoVer-Net
Pour chaque pixel d'un noyau, on calcule sa distance normalisÃ©e au centre:

```
Masque binaire:          Carte H (horizontal):       Carte V (vertical):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â”‚          â”‚  -1  0  +1  â”‚            â”‚  -1 -1 -1   â”‚
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â”‚    â†’     â”‚  -1  0  +1  â”‚            â”‚   0  0  0   â”‚
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â”‚          â”‚  -1  0  +1  â”‚            â”‚  +1 +1 +1   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **H** = distance horizontale normalisÃ©e au centre [-1, +1]
- **V** = distance verticale normalisÃ©e au centre [-1, +1]

### UtilitÃ©
- Le **gradient** des cartes HV est maximal aux **frontiÃ¨res** entre noyaux
- Post-processing: `sobel(HV)` â†’ contours â†’ watershed â†’ instances sÃ©parÃ©es
- Permet de sÃ©parer des noyaux qui se touchent

### Optimisation Stockage
```
float32 [-1, 1] â†’ int8 [-127, 127]
Ã‰conomie: 75% d'espace disque
PrÃ©cision: 127 niveaux suffisent pour le Sobel/Watershed
```

**PrÃ©-calcul obligatoire** car `cv2.connectedComponents` est lent (~5-10ms/image).

### âš ï¸ MISE Ã€ JOUR CRITIQUE: Normalisation HV (2025-12-21)

**Bug dÃ©couvert et corrigÃ©** : Les anciennes donnÃ©es utilisaient int8 [-127, 127] au lieu de float32 [-1, 1].

| Version | Dtype | Range | Conforme HoVer-Net ? | Impact |
|---------|-------|-------|----------------------|--------|
| **OLD** (â‰¤ 2025-12-20) | int8 | [-127, 127] | âŒ NON | HV MSE 0.0150, NT Acc 0.8800 |
| **NEW** (â‰¥ 2025-12-21) | float32 | [-1, 1] | âœ… OUI | HV MSE 0.0105 (-30%), NT Acc 0.9107 (+3.5%) |

**RÃ©sultats validation Glandular (10 Ã©chantillons test)** :
- NP Dice: 0.9655 Â± 0.0184 (identique train: 0.9641)
- HV MSE: 0.0266 Â± 0.0104 (acceptable variance)
- NT Acc: 0.9517 Â± 0.0229 (meilleur que train: 0.9107, **+7.2% vs OLD**)
- HV Range: âœ… 10/10 samples dans [-1, 1]

**Activation HV** : Le dÃ©codeur n'a PAS de `tanh()` explicite, mais produit naturellement des valeurs dans [-1, 1] grÃ¢ce Ã  :
1. SmoothL1Loss qui pÃ©nalise les valeurs Ã©loignÃ©es
2. Targets normalisÃ©s Ã  [-1, 1]
3. Tests empiriques concluants (voir `docs/ARCHITECTURE_HV_ACTIVATION.md`)

**RÃ©tro-compatibilitÃ©** : âŒ ModÃ¨les OLD incompatibles avec NEW data â†’ RÃ©-entraÃ®nement OBLIGATOIRE.

**Fichiers FIXED** :
- DonnÃ©es : `data/family_FIXED/*_data_FIXED.npz`
- Checkpoints : `models/checkpoints_FIXED/hovernet_*_best.pth`
- Scripts : `scripts/preprocessing/prepare_family_data_FIXED.py`

---

## Explication du ModÃ¨le HoVer-Net

### Architecture Ã  3 Branches

HoVer-Net est un rÃ©seau de segmentation et classification de noyaux cellulaires conÃ§u spÃ©cifiquement pour l'histopathologie. Il produit **3 sorties simultanÃ©es** Ã  partir d'une seule image :

```
                    Image H&E (256Ã—256)
                           â”‚
                           â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ H-optimus-0 â”‚  â† Backbone gelÃ© (1.1B params)
                    â”‚   Encoder   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    features (1536-dim)
                           â”‚
                           â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  HoVer-Net  â”‚  â† DÃ©codeur entraÃ®nable
                    â”‚   Decoder   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                 â–¼                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   NP    â”‚       â”‚   HV    â”‚       â”‚   NT    â”‚
    â”‚ Branch  â”‚       â”‚ Branch  â”‚       â”‚ Branch  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                 â”‚                 â”‚
         â–¼                 â–¼                 â–¼
    Masque binaire    Cartes H/V      Classification
    (noyau/fond)     (distances)       (5 types)
```

### Branche NP (Nuclei Presence)

**Objectif** : DÃ©tecter la prÃ©sence de noyaux cellulaires

```
EntrÃ©e : Features encodeur
Sortie : Masque binaire 256Ã—256 (2 classes : fond/noyau)
MÃ©trique : Dice Score (chevauchement prÃ©dit/rÃ©el)

InterprÃ©tation :
  Dice = 2 Ã— |PrÃ©dit âˆ© RÃ©el| / (|PrÃ©dit| + |RÃ©el|)

  0.96+ = Excellent - DÃ©tecte 96%+ des noyaux
```

### Branche HV (Horizontal/Vertical)

**Objectif** : SÃ©parer les noyaux qui se touchent

```
ProblÃ¨me : Dans les tissus denses, les noyaux se chevauchent.
           Un masque binaire ne distingue pas oÃ¹ finit un noyau
           et oÃ¹ commence le suivant.

Solution : Pour chaque pixel d'un noyau, calculer sa distance
           normalisÃ©e au centre de l'instance.

Masque binaire:          Carte H:              Carte V:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â”‚       â”‚  -1  0  +1  â”‚       â”‚  -1 -1 -1   â”‚
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â”‚   â†’   â”‚  -1  0  +1  â”‚       â”‚   0  0  0   â”‚
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â”‚       â”‚  -1  0  +1  â”‚       â”‚  +1 +1 +1   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

H = distance horizontale normalisÃ©e [-1, +1]
V = distance verticale normalisÃ©e [-1, +1]

Post-processing :
  1. Sobel(H, V) â†’ Gradient maximal aux frontiÃ¨res
  2. Watershed sur les gradients â†’ Instances sÃ©parÃ©es
```

**MÃ©trique** : MSE (Mean Squared Error)
```
MSE = moyenne((H_prÃ©dit - H_rÃ©el)Â² + (V_prÃ©dit - V_rÃ©el)Â²)

CalculÃ© uniquement sur les pixels de noyaux (masque NP)

  < 0.02 = Excellent (frontiÃ¨res nettes)
  0.02-0.05 = Bon
  > 0.1 = ProblÃ©matique (fusions possibles)
```

### Branche NT (Nuclei Type)

**Objectif** : Classifier le type de chaque noyau

```
5 classes PanNuke :
  ğŸ”´ Neoplastic   - Cellules tumorales
  ğŸŸ¢ Inflammatory - Lymphocytes, macrophages
  ğŸ”µ Connective   - Fibroblastes, stroma
  ğŸŸ¡ Dead         - Cellules apoptotiques/nÃ©crotiques
  ğŸ©µ Epithelial   - Cellules Ã©pithÃ©liales normales

Sortie : 256Ã—256Ã—5 (probabilitÃ©s par classe)
MÃ©trique : Accuracy (% pixels correctement classifiÃ©s)
```

### Fonction de Perte CombinÃ©e

```python
L_total = Î»_np Ã— L_np + Î»_hv Ã— L_hv + Î»_nt Ã— L_nt

OÃ¹ :
  L_np = CrossEntropy (classification binaire)
  L_hv = SmoothL1Loss (rÃ©gression robuste aux outliers)
  L_nt = CrossEntropy (classification 5 classes)

Poids optimaux :
  Î»_np = 1.0
  Î»_hv = 2.0  â† Plus important pour sÃ©paration instances
  Î»_nt = 1.0
```

### RÃ©sultats par Famille (PanNuke)

| Famille | Samples | NP Dice | HV MSE | NT Acc | Statut |
|---------|---------|---------|--------|--------|--------|
| **Glandulaire** | 3535 | **0.9645** | **0.015** | 0.88 | âœ… |
| **Digestive** | 2274 | **0.9634** | **0.016** | 0.88 | âœ… |
| Urologique | 1153 | 0.9318 | 0.281 | **0.91** | âœ… |
| Ã‰pidermoÃ¯de | 574 | 0.9542 | 0.273 | 0.89 | âœ… |
| Respiratoire | 364 | 0.9409 | 0.284 | 0.89 | âœ… |

### Analyse des RÃ©sultats par Famille

#### CorrÃ©lation Samples vs Performance

```
Seuil critique identifiÃ© :
  â‰¥2000 samples â†’ HV MSE < 0.02 (excellent)
  <2000 samples â†’ HV MSE > 0.25 (dÃ©gradÃ©)

StabilitÃ© par branche :
  NP Dice : TrÃ¨s stable (0.93-0.96) mÃªme avec 364 samples
  NT Acc  : TrÃ¨s stable (0.88-0.91) mÃªme avec 364 samples
  HV MSE  : Sensible au volume de donnÃ©es
```

#### Explications Pathologiques

**Pourquoi Glandulaire/Digestive excellent (HV MSE ~0.015) ?**
```
â€¢ Noyaux bien dÃ©finis avec contours nets
â€¢ Structures glandulaires rÃ©guliÃ¨res (acini, cryptes)
â€¢ Espacement naturel entre cellules Ã©pithÃ©liales
â€¢ Faible chevauchement nuclÃ©aire
â†’ Le modÃ¨le apprend facilement les frontiÃ¨res
```

**Pourquoi Urologique/Respiratoire/Ã‰pidermoÃ¯de dÃ©gradÃ© (HV MSE ~0.28) ?**
```
â€¢ DensitÃ© nuclÃ©aire Ã©levÃ©e (clusters serrÃ©s)
â€¢ Noyaux plus petits et irrÃ©guliers (rein, poumon)
â€¢ Chevauchement frÃ©quent dans les couches stratifiÃ©es (peau)
â€¢ Moins de donnÃ©es d'entraÃ®nement disponibles
â†’ FrontiÃ¨res ambiguÃ«s + donnÃ©es insuffisantes
```

#### Implications Cliniques

| Famille | DÃ©tection (NP) | Classification (NT) | SÃ©paration (HV) |
|---------|----------------|---------------------|-----------------|
| Glandulaire | âœ… Fiable | âœ… Fiable | âœ… Fiable |
| Digestive | âœ… Fiable | âœ… Fiable | âœ… Fiable |
| Urologique | âœ… Fiable | âœ… Fiable | âš ï¸ VÃ©rifier manuellement |
| Ã‰pidermoÃ¯de | âœ… Fiable | âœ… Fiable | âš ï¸ VÃ©rifier manuellement |
| Respiratoire | âœ… Fiable | âœ… Fiable | âš ï¸ VÃ©rifier manuellement |

**Recommandation** : Pour les familles avec HV MSE > 0.1, afficher un avertissement
dans l'interface utilisateur concernant la sÃ©paration des instances.

### Pourquoi 5 Familles ?

```
Justification scientifique :
  1. Les noyaux partagent des propriÃ©tÃ©s physiques â†’ backbone commun
  2. L'erreur augmente entre organes de textures diffÃ©rentes
  3. Le transfert fonctionne mieux entre organes de mÃªme origine embryologique

Avantages techniques :
  - RAM rÃ©duite : ~27 GB â†’ ~5 GB par entraÃ®nement
  - Gradient propre (pas de signaux contradictoires)
  - Meilleure classification NT par famille
  - Convergence plus rapide
```

---

## StratÃ©gie de SÃ©curitÃ© Clinique

### Sortie en 3 niveaux
- **Fiable** â€” Confiance haute, prÃ©diction utilisable
- **Ã€ revoir** â€” Incertitude dÃ©tectÃ©e, validation humaine recommandÃ©e
- **Hors domaine** â€” Cas atypique, ne pas utiliser la prÃ©diction

### Cold Start (nouveau centre)
1. Seuils conservateurs par dÃ©faut
2. Shadow mode sur 30-50 premiÃ¨res lames
3. DÃ©tection OOD automatique

---

## RÃ©fÃ©rences

- H-optimus-0 : https://huggingface.co/bioptimus/H-optimus-0
- CellViT : https://github.com/TIO-IKIM/CellViT
- PanNuke : https://warwick.ac.uk/fac/cross_fac/tia/data/pannuke
- TCGA : https://www.cancer.gov/tcga

---

## Notes pour Claude

- **Objectif actuel** : POC dÃ©montrable en 6 semaines
- **PrioritÃ©** : Validation technique avant expansion
- **Approche** : Explorer le domaine mÃ©dical via ce projet, rester ouvert aux pivots
- **Hardware limitÃ©** : Toujours considÃ©rer les contraintes 12GB VRAM dans les suggestions

---

## Plan de DÃ©veloppement POC (6 semaines)

> **IMPORTANT** : Suivre ce plan Ã©tape par Ã©tape. Ne pas passer Ã  l'Ã©tape suivante
> sans avoir validÃ© les critÃ¨res de l'Ã©tape courante.

### Phase 1 : Environnement & DonnÃ©es (Semaines 1-2)

| Ã‰tape | Description | Validation | Statut |
|-------|-------------|------------|--------|
| 1.1 | Setup WSL2 + Docker + CUDA | `nvidia-smi` fonctionne | âœ… FAIT |
| 1.2 | Conda + PyTorch | `torch.cuda.is_available()` = True | âœ… FAIT |
| 1.3 | TÃ©lÃ©charger PanNuke | 3 folds prÃ©sents | âœ… FAIT (manuel) |
| 1.4 | Scripts preprocessing | Extraction tuiles, normalisation | âœ… FAIT |

**CritÃ¨res de passage Phase 2 :**
- [x] Environnement GPU fonctionnel
- [x] Dataset PanNuke disponible
- [x] Pipeline preprocessing prÃªt

### Phase 2 : IntÃ©gration H-optimus-0 (Semaines 3-4)

| Ã‰tape | Description | Validation | Statut |
|-------|-------------|------------|--------|
| 2.1 | AccÃ¨s HuggingFace gated | Token configurÃ© | âœ… FAIT |
| 2.2 | Charger H-optimus-0 | InfÃ©rence OK sur 1 image | âœ… FAIT |
| 2.3 | Extraction features PanNuke | Embeddings 1536-dim sauvÃ©s | âœ… FAIT |
| 2.4 | Visualisation t-SNE | Clusters par organe visibles | âœ… FAIT |
| 2.5 | DÃ©codeur UNETR skeleton | Architecture compilable | âœ… FAIT |
| 2.6 | EntraÃ®nement UNETR sur PanNuke | Loss converge | âœ… FAIT (Dice 0.6935) |

**CritÃ¨res de passage Phase 3 :**
- [x] UNETR entraÃ®nÃ© sur PanNuke (backbone H-optimus-0 gelÃ©)
- [x] Dice â‰ˆ 0.7 sur PanNuke validation (0.6935 acceptÃ© pour POC)

### Phase 3 : Interface DÃ©mo (Semaine 5)

| Ã‰tape | Description | Validation | Statut |
|-------|-------------|------------|--------|
| 3.1 | Interface Gradio basique | Upload image â†’ rÃ©sultat | âœ… FAIT |
| 3.2 | IntÃ©gration HoVer-Net dans dÃ©mo | InfÃ©rence H-optimus-0 + HoVer-Net | âœ… FAIT |
| 3.3 | Rapport avec couleurs/emojis | Correspondance visuelle | âœ… FAIT |
| 3.4 | Scripts OOD/calibration | Utilitaires prÃªts | âœ… FAIT |

### Phase 4 : SÃ©curitÃ© & Interaction Expert (Semaine 6) âœ… COMPLÃˆTE

| Ã‰tape | Description | Validation | Statut |
|-------|-------------|------------|--------|
| 4.1 | Incertitude alÃ©atorique | Entropie NP/HV calculÃ©e | âœ… FAIT |
| 4.2 | Incertitude Ã©pistÃ©mique | Conformal Prediction intÃ©grÃ© | âœ… FAIT |
| 4.3 | DÃ©tection OOD | Distance Mahalanobis sur embeddings | âœ… FAIT |
| 4.4 | Calibration locale | Temperature Scaling fonctionnel | âœ… FAIT |
| 4.5 | Sortie 3 niveaux | {Fiable \| Ã€ revoir \| Hors domaine} | âœ… FAIT |
| 4.6 | SÃ©lection automatique ROIs | RÃ©gions prioritaires identifiÃ©es | âœ… FAIT |
| 4.7 | Carte d'incertitude | Heatmap rouge/vert dans dÃ©mo | âœ… FAIT |

### Phase 5 : Packaging (Post-POC)

| Ã‰tape | Description | Validation | Statut |
|-------|-------------|------------|--------|
| 5.1 | Docker packaging | `docker-compose up` fonctionne | ğŸ”œ DIFFÃ‰RÃ‰ |
| 5.2 | Documentation utilisateur | README complet | ğŸ”œ DIFFÃ‰RÃ‰ |

**CritÃ¨res de livraison POC :**
- [x] DÃ©mo fonctionnelle avec architecture cible (H-optimus-0 + HoVer-Net, Dice 0.9601)
- [x] Couche 3 : SÃ©curitÃ© & Incertitude intÃ©grÃ©e
- [x] Couche 4 : Interaction Expert (ROIs, heatmaps)

---

## Statut Actuel

**Phase en cours :** Phase 4 â€” COMPLÃˆTE âœ…
**Blocage actuel :** Aucun
**Prochaine action :** Phase 5 (Packaging) ou dÃ©mo avec pathologistes

### RÃ©sumÃ© des accomplissements
- âœ… Couche 1 : H-optimus-0 intÃ©grÃ© (embeddings 1536-dim)
- âœ… Couche 2A : HoVer-Net decoder entraÃ®nÃ© (Dice 0.9601)
- âœ… Couche 3 : SÃ©curitÃ© & Incertitude (entropie + Mahalanobis + Conformal Prediction)
- âœ… Couche 4 : Interaction Expert (ROIs, calibration, heatmaps)

---

## DÃ©cisions Techniques & Justifications

### DÃ©cision 1: Utiliser le repo CellViT officiel (TIO-IKIM)

**Date:** 2025-12-19
**Contexte:** Le checkpoint CellViT-256.pth (187 MB) a une architecture complexe qui ne correspondait pas Ã  notre wrapper custom.

**ProblÃ¨mes rencontrÃ©s:**
- IncompatibilitÃ© `pos_embed`: [1, 197, 384] (checkpoint) vs [1, 257, 384] (notre modÃ¨le)
- Structure dÃ©codeurs diffÃ©rente: `decoder.X.block.Y` vs `decoder.X.Y`
- TÃªtes de sortie avec `bottleneck_upsampler`, `decoderX_upsampler`, `decoder0_header`
- Seulement 149/439 paramÃ¨tres compatibles

**DÃ©cision:** Cloner le repo officiel `TIO-IKIM/CellViT` et utiliser leur code pour charger le modÃ¨le.

**Pourquoi cette dÃ©cision pour le POC:**
- âœ… Gain de temps: Pas besoin de reverse-engineer l'architecture exacte
- âœ… FiabilitÃ©: Code testÃ© par les auteurs originaux
- âœ… Baseline fiable: Permet de valider le pipeline end-to-end rapidement

**Impact sur l'architecture cible:**
- âš ï¸ CellViT-256 n'est PAS l'architecture cible
- L'architecture cible utilise **H-optimus-0 + UNETR** (specs section 2.3)
- CellViT-256 sert uniquement de **baseline de comparaison**

### Chemin vers l'Architecture Cible

```
POC (actuel)                          CIBLE (production)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CellViT-256 prÃ©-entraÃ®nÃ©              H-optimus-0 backbone (gelÃ©)
    â”‚                                     â”‚
    â”‚ encoder ViT-256                     â”‚ ViT-Giant/14 (1.1B params)
    â”‚ (46M params)                        â”‚ Embeddings 1536-dim
    â”‚                                     â”‚
    â–¼                                     â–¼
DÃ©codeur intÃ©grÃ© CellViT              DÃ©codeur UNETR custom
    â”‚                                     â”‚
    â”‚                                     â”‚ Skip connections couches 6/12/18/24
    â”‚                                     â”‚
    â–¼                                     â–¼
3 tÃªtes: NP, HV, NT                   3 tÃªtes: NP, HV, NT
```

### Ã‰tapes pour passer Ã  l'architecture cible

1. **Phase POC (actuelle):** Valider pipeline avec CellViT-256 comme baseline
2. **Phase 2.6:** EntraÃ®ner notre dÃ©codeur UNETR sur PanNuke avec H-optimus-0 gelÃ©
3. **Validation:** Comparer mÃ©triques UNETR vs CellViT-256 baseline
4. **Production:** Remplacer CellViT-256 par UNETR entraÃ®nÃ©

### Pourquoi ne pas utiliser CellViT-256 en production?

| CritÃ¨re | CellViT-256 | H-optimus-0 + UNETR |
|---------|-------------|---------------------|
| Taille backbone | 46M params | 1.1B params |
| Features | 384-dim | 1536-dim |
| PrÃ©-entraÃ®nement | PanNuke uniquement | 500k+ lames H&E multi-centres |
| GÃ©nÃ©ralisation | LimitÃ©e | Excellente (foundation model) |
| ConformitÃ© specs | âŒ Non | âœ… Oui |

---

## Journal de DÃ©veloppement

### 2025-12-19 â€” Setup environnement âœ… VALIDÃ‰
- **Environnement WSL2 configurÃ©** : Ubuntu 24.04.2 LTS
- **Docker Engine natif installÃ©** (pas Docker Desktop) â€” meilleure performance, pas de licence
- **NVIDIA Container Toolkit** configurÃ© â€” Docker peut accÃ©der au GPU
- **Miniconda installÃ©** â€” environnement `cellvit` crÃ©Ã©
- **PyTorch 2.6.0+cu124 installÃ©** â€” GPU RTX 4070 SUPER dÃ©tectÃ© et fonctionnel
- **Test GPU matmul** : OK
- **DÃ©cision** : Utiliser Python 3.10 pour compatibilitÃ© optimale avec PyTorch/CUDA

**Commandes de vÃ©rification rapide :**
```bash
# Activer l'environnement
conda activate cellvit

# VÃ©rifier GPU
python -c "import torch; print(torch.cuda.is_available(), torch.cuda.get_device_name(0))"
```

### 2025-12-19 â€” H-optimus-0 + PanNuke âœ… VALIDÃ‰
- **H-optimus-0 chargÃ©** : 1.13B paramÃ¨tres, embeddings 1536-dim
- **PanNuke Fold 1 tÃ©lÃ©chargÃ©** : 2656 images, 19 organes, 256Ã—256 pixels
- **Script d'extraction crÃ©Ã©** : `scripts/preprocessing/extract_features.py`
- **Script de visualisation crÃ©Ã©** : `scripts/evaluation/visualize_embeddings.py`

**Performances mesurÃ©es :**
| MÃ©trique | Valeur |
|----------|--------|
| Temps par image | 13.6 ms |
| Throughput | 73.4 img/s |
| Pic mÃ©moire GPU | 4.59 GB |

**Commandes d'extraction :**
```bash
# Extraction stratifiÃ©e (tous les organes)
python scripts/preprocessing/extract_features.py --num_images 500 --batch_size 16 --stratified

# Visualisation t-SNE
python scripts/evaluation/visualize_embeddings.py
```

**RÃ©sultat t-SNE** : Les embeddings montrent une structure (pas alÃ©atoire), avec quelques clusters par organe. Validation que H-optimus-0 capture de l'information sÃ©mantique utile.

### 2025-12-19 â€” Scripts & DÃ©mo Gradio âœ… FAIT
- **Interface Gradio crÃ©Ã©e** : `scripts/demo/gradio_demo.py`
- **GÃ©nÃ©rateur tissus synthÃ©tiques** : `scripts/demo/synthetic_cells.py`
- **Visualisation cellules** : `scripts/demo/visualize_cells.py`
- **Rapport avec emojis couleur** : ğŸ”´ğŸŸ¢ğŸ”µğŸŸ¡ğŸ©µ correspondant aux types

### 2025-12-19 â€” Scripts utilitaires (specs section 6.1) âœ… FAIT
Scripts crÃ©Ã©s conformÃ©ment aux specs :
- `scripts/setup/download_models.py` â€” TÃ©lÃ©chargement CellViT, SAM, H-optimus-0
- `scripts/setup/download_datasets.py` â€” TÃ©lÃ©chargement PanNuke avec vÃ©rification
- `scripts/preprocessing/stain_normalization.py` â€” Normalisation Macenko H&E
- `scripts/preprocessing/tile_extraction.py` â€” Extraction tuiles 224Ã—224
- `scripts/preprocessing/quality_filter.py` â€” DÃ©tection flou, tissus, artefacts
- `scripts/preprocessing/tissue_detection.py` â€” DÃ©tection ROI, filtrage background
- `scripts/evaluation/metrics_segmentation.py` â€” Dice, IoU, PQ, F1
- `scripts/calibration/temperature_scaling.py` â€” Calibration post-hoc, ECE
- `scripts/ood_detection/latent_distance.py` â€” Mahalanobis sur embeddings
- `scripts/ood_detection/entropy_scoring.py` â€” Incertitude â†’ Fiable/Ã€ revoir/Hors domaine
- `scripts/training/train_unetr.py` â€” EntraÃ®nement UNETR sur PanNuke

### 2025-12-19 â€” IntÃ©gration CellViT-256 âœ… VALIDÃ‰E (Ã‰tape 1.5 POC)
- **Repo officiel clonÃ©** : `CellViT/` (TIO-IKIM/CellViT)
- **DÃ©pendances installÃ©es** : ujson, einops, shapely, geojson, colorama, natsort
- **Wrapper officiel mis Ã  jour** : `src/inference/cellvit_official.py`
- **Test validation crÃ©Ã©** : `scripts/validation/test_cellvit_official.py`
- **Checkpoint tÃ©lÃ©chargÃ©** : `models/pretrained/CellViT-256.pth` (187.2 MB, Epoch 129)

**Architecture CellViT-256 (via repo officiel) :**
| Attribut | Valeur |
|----------|--------|
| ParamÃ¨tres | 46,750,349 |
| embed_dim | 384 |
| depth | 12 |
| num_heads | 6 |
| extract_layers | [3, 6, 9, 12] |

**RÃ©sultats validation complÃ¨te :**
```
âœ… Import CellViT256 OK
âœ… Architecture: 46.7M params
âœ… Forward pass OK
âœ… Checkpoint chargÃ© (187.2 MB, 439 clÃ©s)
âœ… Poids chargÃ©s (All keys matched successfully)
âœ… InfÃ©rence rÃ©ussie (NP/Type probs: [0.000, 1.000])

ğŸ‰ TOUS LES TESTS PASSENT - Ã‰tape 1.5 validÃ©e!
```

**Test validation :**
```bash
python scripts/validation/test_cellvit_official.py -c models/pretrained/CellViT-256.pth
```

### 2025-12-19 â€” DÃ©mo Gradio avec CellViT-256 âœ… VALIDÃ‰E (Ã‰tape 3.2 POC)
- **Wrapper officiel intÃ©grÃ©** dans `scripts/demo/gradio_demo.py`
- **Import mis Ã  jour** : `CellViTOfficial` remplace `CellViTInference`
- **Validation checkpoint** : VÃ©rification taille > 1MB avant chargement

**Test sur image rÃ©elle (cancer prostate) :**
```
âœ… MODÃˆLE CELLVIT-256 ACTIF
Total cellules dÃ©tectÃ©es: 25
  ğŸ”´ Neoplastic: 17 (68.0%)
  ğŸ”µ Connective: 8 (32.0%)
```

**RÃ©sultat :** DÃ©tection cohÃ©rente â€” majoritÃ© nÃ©oplasique sur image de carcinome prostatique.

### 2025-12-19 â€” Validation mÃ©triques PanNuke âœ… VALIDÃ‰E (Ã‰tape 1.6 POC)
- **Dataset PanNuke** : 3 folds tÃ©lÃ©chargÃ©s et rÃ©organisÃ©s (structure Warwick â†’ CellViT)
- **Script d'Ã©valuation crÃ©Ã©** : `scripts/validation/evaluate_pannuke.py`
- **Tests unitaires crÃ©Ã©s** : `tests/unit/test_metrics.py`, `test_ood.py`, `test_calibration.py`
- **Tests intÃ©gration** : `tests/integration/test_pipeline_e2e.py`

**RÃ©sultats sur PanNuke (2722 images) :**
```
Binary-Cell-Dice:    0.8733 Â± 0.1048
Binary-Cell-Jaccard: 0.7859
```

**CritÃ¨re POC :** Dice 0.8733 > 0.7 âœ…

### 2025-12-19 â€” EntraÃ®nement UNETR âœ… VALIDÃ‰ (Ã‰tape 2.6 POC)
- **Features prÃ©-extraites** : H-optimus-0 couches 6/12/18/24 â†’ 17 GB (fold 0)
- **Checkpoint sauvÃ©** : `models/checkpoints/unetr_best.pth`
- **DonnÃ©es** : Fold 0 uniquement (2125 train / 531 val)

**RÃ©sultats entraÃ®nement (50 epochs) :**
| MÃ©trique | Train | Validation |
|----------|-------|------------|
| Loss | 0.1266 | 1.0297 |
| Dice | - | **0.6935** |

**Observation :** Overfitting dÃ©tectÃ© (Val Loss 8x > Train Loss). Le Dice reste acceptable car il mesure le chevauchement binaire, pas la calibration des probabilitÃ©s.

**CritÃ¨re POC :** Dice 0.6935 â‰ˆ 0.7 âœ… (acceptÃ© pour POC)

#### âš ï¸ Recommandations pour amÃ©liorer la gÃ©nÃ©ralisation (post-POC)

| PrioritÃ© | Action | Impact attendu |
|----------|--------|----------------|
| 1 | **Utiliser les 3 folds** | 3x plus de donnÃ©es â†’ meilleure gÃ©nÃ©ralisation |
| 2 | **Data augmentation** | Rotations, flips, variations couleur H&E |
| 3 | **Regularisation** | Dropout (0.1-0.3), weight decay (1e-4) |
| 4 | **Early stopping** | ArrÃªter quand val_loss stagne |
| 5 | **Temperature scaling** | Calibrer les probabilitÃ©s post-entraÃ®nement |

### 2025-12-19 â€” Migration UNETR â†’ HoVer-Net âœ… VALIDÃ‰

**ProblÃ¨me identifiÃ© :** L'architecture UNETR n'Ã©tait pas adaptÃ©e Ã  H-optimus-0 car :
- UNETR attend des skip connections multi-rÃ©solution
- H-optimus-0 sort toutes les couches Ã  16x16 (mÃªme rÃ©solution)
- RÃ©sultats UNETR dÃ©cevants : Dice 0.6935, classifications dÃ©sÃ©quilibrÃ©es

**Solution adoptÃ©e :** DÃ©codeur HoVer-Net style (basÃ© sur littÃ©rature CellViT)

**Architecture HoVer-Net :**
```
H-optimus-0 (16x16 @ 1536)
        â†“
Bottleneck 1x1 (1536 â†’ 256)  â† Ã‰conomie VRAM
        â†“
Tronc Commun (upsampling partagÃ© 16â†’224)
        â†“
   â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
   â†“         â†“        â†“
  NP        HV       NT
```

**RÃ©sultats comparatifs :**
| MÃ©trique | UNETR | HoVer-Net | AmÃ©lioration |
|----------|-------|-----------|--------------|
| Dice | 0.6935 | **0.9587** | +38% |
| Val Loss | 1.0297 | 0.7469 | -27% |

**Fichiers crÃ©Ã©s :**
- `src/models/hovernet_decoder.py` â€” DÃ©codeur avec bottleneck partagÃ©
- `scripts/training/train_hovernet.py` â€” Script d'entraÃ®nement
- `src/inference/hoptimus_hovernet.py` â€” Wrapper infÃ©rence
- `models/checkpoints/hovernet_best.pth` â€” Checkpoint entraÃ®nÃ©

### 2025-12-20 â€” Couche 3: SÃ©curitÃ© & Incertitude âœ… VALIDÃ‰

**ImplÃ©mentation complÃ¨te de la Couche 3** conforme aux specs:

**Module crÃ©Ã©:** `src/uncertainty/`
- `uncertainty_estimator.py` â€” Estimateur unifiÃ© combinant:
  - Incertitude alÃ©atorique (entropie NP/NT)
  - Incertitude Ã©pistÃ©mique (distance Mahalanobis sur embeddings)
  - Classification en 3 niveaux: {Fiable | Ã€ revoir | Hors domaine}

**IntÃ©gration dans l'infÃ©rence:**
- `hoptimus_hovernet.py` mis Ã  jour pour calculer l'incertitude Ã  chaque prÃ©diction
- Carte d'incertitude spatiale gÃ©nÃ©rÃ©e (rouge=incertain, vert=fiable)
- Rapport textuel enrichi avec mÃ©triques d'incertitude

**IntÃ©gration dans la dÃ©mo Gradio:**
- Nouvelle sortie: carte d'incertitude visualisÃ©e
- Description des niveaux de confiance dans l'interface
- Rapport complet avec entropie, Mahalanobis, score combinÃ©

**Fichiers modifiÃ©s/crÃ©Ã©s:**
- `src/uncertainty/__init__.py`
- `src/uncertainty/uncertainty_estimator.py`
- `src/inference/hoptimus_hovernet.py` (ajout `visualize_uncertainty()`)
- `scripts/demo/gradio_demo.py` (4 outputs au lieu de 3)

**AmÃ©lioration Loss:** MSELoss â†’ SmoothL1Loss pour branche HV (moins sensible aux outliers)

**RÃ©sultats aprÃ¨s SmoothL1Loss (2025-12-20):**
| MÃ©trique | Avant | AprÃ¨s | AmÃ©lioration |
|----------|-------|-------|--------------|
| Dice | 0.9587 | **0.9601** | +0.14% |
| Val Loss | 0.7469 | **0.7333** | -1.8% |
| HV Loss | ~0.01 | 0.0085 | -15% |

### 2025-12-20 â€” RÃ©gularisation: Augmentation + Dropout âœ… IMPLÃ‰MENTÃ‰

**ProblÃ¨me identifiÃ©:** Overfitting Train Loss (0.31) vs Val Loss (0.81) = 2.6x gap

**Solutions implÃ©mentÃ©es:**

1. **Data Augmentation** (`FeatureAugmentation` class):
   - Flip horizontal/vertical avec ajustement composantes H/V
   - Rotation 90Â° (90Â°, 180Â°, 270Â°) avec rotation H/V
   - AppliquÃ© sur features H-optimus-0 (reshape 16x16 grid)
   - Flag: `--augment`

2. **Dropout rÃ©gularisation**:
   - Dropout2d aprÃ¨s bottleneck et entre blocs upsampling
   - Default: 0.1, configurable via `--dropout`

3. **Loss weights ajustÃ©s** (recommandation expert):
   - `L_total = 1.0*NP + 2.0*HV + 1.0*NT`
   - Focus sur gradient sharpness (sÃ©paration instances)

**Fichiers modifiÃ©s:**
- `src/models/hovernet_decoder.py` â€” Ajout dropout parameter
- `scripts/training/train_hovernet.py` â€” Ajout FeatureAugmentation, flags --augment/--dropout

**Commande entraÃ®nement avec rÃ©gularisation:**
```bash
python scripts/training/train_hovernet.py --fold 0 --epochs 50 --augment --dropout 0.1
```

### 2025-12-20 â€” Phase 4 ComplÃ¨te: Conformal Prediction + ROI Selection âœ…

**Modules implÃ©mentÃ©s:**

1. **Conformal Prediction** (`src/uncertainty/conformal_prediction.py`)
   - MÃ©thodes: LAC, APS, RAPS
   - Garantie de couverture (1 - alpha)
   - Support pixel-wise pour segmentation
   - Usage:
   ```python
   cp = ConformalPredictor(method=ConformalMethod.APS, alpha=0.1)
   cp.calibrate(val_probs, val_labels)
   result = cp.predict_set(test_probs)  # Returns prediction set
   ```

2. **Temperature Scaling intÃ©grÃ©** (`uncertainty_estimator.py`)
   - Calibration post-hoc des probabilitÃ©s
   - Minimisation NLL ou ECE
   - IntÃ©grÃ© dans UncertaintyEstimator:
   ```python
   estimator.calibrate_temperature(logits, labels)
   probs = estimator.apply_temperature(logits)
   ```

3. **SÃ©lection automatique ROIs** (`src/uncertainty/roi_selection.py`)
   - Score combinÃ©: incertitude + densitÃ© + nÃ©oplasiques
   - PrioritÃ©s: CRITICAL, HIGH, MEDIUM, LOW
   - FenÃªtre glissante avec suppression chevauchement
   - Usage:
   ```python
   selector = ROISelector(roi_size=64, stride=32)
   rois = selector.select_rois(uncertainty_map, np_mask, nt_probs, n_rois=5)
   ```

**Tests de validation:**
```bash
python -c "from src.uncertainty import ConformalPredictor, ROISelector; print('OK')"
```

### 2025-12-20 â€” Architecture Optimus-Gate âœ…

**Architecture finale "Optimus-Gate"** avec double flux:

```
H-optimus-0 (backbone gelÃ©)
         â”‚
    features (B, 261, 1536)
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â†“         â†“
CLS token   Patch tokens
(1, 1536)   (256, 1536)
    â”‚         â”‚
    â†“         â†“
OrganHead   HoVerNet
(96% acc)   (96% Dice)
    â”‚         â”‚
    â†“         â†“
19 organes  NP/HV/NT
+ OOD       + Cellules
```

**RÃ©sultats entraÃ®nement (3 folds) â€” APRÃˆS FIX PREPROCESSING (2025-12-20):**
| Composant | MÃ©trique | Valeur |
|-----------|----------|--------|
| OrganHead | Val Accuracy | **99.94%** |
| OrganHead | Organes Ã  100% | 18/19 |
| OOD | Threshold | 45.55 |

**RÃ©sultats HoVer-Net par Famille (aprÃ¨s fix preprocessing) â€” COMPLET :**
| Famille | Samples | Dice | HV MSE | NT Acc | Checkpoint | Statut |
|---------|---------|------|--------|--------|------------|--------|
| Glandulaire | 3391 | **0.9648** | **0.0106** | **0.9111** | `hovernet_glandular_best.pth` | âœ… |
| Digestive | 2430 | **0.9634** | **0.0163** | **0.8824** | `hovernet_digestive_best.pth` | âœ… |
| Urologique | 1101 | **0.9318** | 0.2812 | **0.9139** | `hovernet_urologic_best.pth` | âœ… |
| Ã‰pidermoÃ¯de | 571 | **0.9542** | 0.2653 | 0.8857 | `hovernet_epidermal_best.pth` | âœ… |
| Respiratoire | 408 | **0.9409** | **0.0500** | **0.9183** | `hovernet_respiratory_best.pth` | âœ… |

**AmÃ©lioration aprÃ¨s fix preprocessing (Glandulaire) :**
| MÃ©trique | Avant (corrompu) | AprÃ¨s (corrigÃ©) | AmÃ©lioration |
|----------|------------------|-----------------|--------------|
| NP Dice | 0.9645 | **0.9648** | +0.03% |
| HV MSE | 0.0150 | **0.0106** | **-29%** |
| NT Acc | 0.88 | **0.9111** | **+3.5%** |

**RÃ©sultats avec Uncertainty Weighting (Kendall et al. 2018) :**
| Famille | Dice | HV MSE | NT Acc | w_np | w_hv | w_nt |
|---------|------|--------|--------|------|------|------|
| Urologique | 0.9312 | 0.2734 | 0.9055 | 1.16 | 1.15 | 1.11 |
| Ã‰pidermoÃ¯de | 0.9544 | 0.2755 | 0.8971 | 1.09 | 1.08 | 1.07 |

**Observations Uncertainty Weighting:**
- Les poids appris convergent vers ~1.1 pour toutes les branches (Ã©quilibrÃ©)
- Aucune branche n'est sur-pondÃ©rÃ©e â†’ entraÃ®nement stable
- LÃ©gÃ¨re prÃ©fÃ©rence pour NP (w_np lÃ©gÃ¨rement > autres) â†’ focus segmentation

**Triple SÃ©curitÃ© OOD:**
- Entropie organe (softmax uncertainty)
- Mahalanobis global (CLS token distance)
- Mahalanobis local (patch mean distance)

### 2025-12-21 â€” Uncertainty Weighting et SÃ©lection de Checkpoint âœ… NOUVEAU

**AmÃ©liorations apportÃ©es au pipeline d'entraÃ®nement HoVer-Net:**

#### Uncertainty Weighting (Kendall et al. 2018)

Le modÃ¨le apprend automatiquement les poids optimaux pour chaque branche:

```python
# Formule: L_total = Î£ (L_i * exp(-log_var_i) + log_var_i)
# Ã‰quivalent Ã : L_i / ÏƒÂ² + log(Ïƒ)

class HoVerNetLoss:
    def __init__(self, adaptive=True):
        if adaptive:
            self.log_var_np = nn.Parameter(torch.zeros(1))
            self.log_var_hv = nn.Parameter(torch.zeros(1))
            self.log_var_nt = nn.Parameter(torch.zeros(1))
```

**Avantages:**
- Pas besoin de tuner manuellement Î»_np, Î»_hv, Î»_nt
- Le modÃ¨le donne plus de poids aux tÃ¢ches oÃ¹ il est performant
- Convergence plus stable sur les petites familles

#### SÃ©lection de Checkpoint par Score CombinÃ©

**ProblÃ¨me:** Le meilleur Dice n'est pas toujours le meilleur modÃ¨le global (HV MSE peut Ãªtre dÃ©gradÃ©).

**Solution:** Score combinÃ© pour sÃ©lectionner le meilleur checkpoint:

```python
# Score = Dice - 0.5 * HV_MSE
# Favorise les modÃ¨les avec bon Dice ET bon HV MSE

if combined_score > best_combined_score:
    save_checkpoint(model, "hovernet_best.pth")
```

**Exemple de sÃ©lection:**
| Epoch | Dice | HV MSE | Score CombinÃ© | SÃ©lectionnÃ© |
|-------|------|--------|---------------|-------------|
| 10 | 0.960 | 0.015 | 0.9525 | |
| 25 | 0.965 | 0.012 | 0.9590 | âœ… |
| 40 | 0.968 | 0.025 | 0.9555 | (Dice meilleur mais HV dÃ©gradÃ©) |

#### Usage dans le script d'entraÃ®nement

```bash
# EntraÃ®nement avec Uncertainty Weighting (par dÃ©faut)
python scripts/training/train_hovernet_family.py \
    --family glandular \
    --epochs 50 \
    --augment \
    --lambda_np 1.0 \
    --lambda_hv 2.0 \
    --lambda_nt 1.0
```

**Usage:**
```python
from src.inference import OptimusGate

# Charger le modÃ¨le prÃ©-entraÃ®nÃ©
model = OptimusGate.from_pretrained(
    hovernet_path="models/checkpoints/hovernet_best.pth",
    organ_head_path="models/checkpoints/organ_head_best.pth",
    device="cuda"
)

# PrÃ©diction
result = model.predict(features)
print(result.organ.organ_name)      # "Prostate"
print(result.organ.confidence)      # 0.99
print(result.n_cells)               # 42
print(result.is_ood)                # False
print(result.confidence_level)      # ConfidenceLevel.FIABLE

# Rapport complet
print(model.generate_report(result))
```

### 2025-12-20 â€” IntÃ©gration Gradio Demo âœ…

**OptimusGateInference** intÃ©grÃ© dans la dÃ©mo Gradio:

- **Fichier crÃ©Ã©**: `src/inference/optimus_gate_inference.py`
  - Wrapper complet: image â†’ H-optimus-0 â†’ OptimusGate â†’ rÃ©sultats
  - MÃ©thodes: `predict()`, `visualize()`, `visualize_uncertainty()`, `generate_report()`

- **DÃ©mo mise Ã  jour**: `scripts/demo/gradio_demo.py`
  - OptimusGate chargÃ© en prioritÃ© (avant HoVer-Net seul)
  - UI mise Ã  jour avec architecture double flux
  - Affichage organe dÃ©tectÃ© + cellules + OOD
  - Onglet "Ã€ propos" avec schÃ©ma Optimus-Gate

**Lancement:**
```bash
python scripts/demo/gradio_demo.py
# URL: http://localhost:7860
```

### 2025-12-20 â€” EntraÃ®nement Multi-Folds (3 folds) âœ…

**Support multi-folds ajoutÃ©** aux scripts d'entraÃ®nement pour amÃ©liorer la gÃ©nÃ©ralisation.

#### Distribution des donnÃ©es PanNuke (3 folds)

| Organe | Samples | % du total |
|--------|---------|------------|
| Colon | 1,323 | 17.2% |
| Breast | 2,437 | 31.6% |
| Adrenal_gland | 487 | 6.3% |
| Bile-duct | 379 | 4.9% |
| Bladder | 149 | 1.9% |
| Cervix | 325 | 4.2% |
| Esophagus | 427 | 5.5% |
| HeadNeck | 396 | 5.1% |
| Kidney | 141 | 1.8% |
| Liver | 186 | 2.4% |
| Lung | 178 | 2.3% |
| Ovarian | 129 | 1.7% |
| Pancreatic | 213 | 2.8% |
| Prostate | 207 | 2.7% |
| Skin | 178 | 2.3% |
| Stomach | 145 | 1.9% |
| Testis | 193 | 2.5% |
| Thyroid | 191 | 2.5% |
| Uterus | 216 | 2.8% |
| **Total** | **7,900** | 100% |

#### RÃ©sultats OrganHead (3 folds vs 1 fold)

| MÃ©trique | 1 fold | 3 folds | AmÃ©lioration |
|----------|--------|---------|--------------|
| Val Accuracy | 96.05% | **99.56%** | +3.51% |
| Organes Ã  100% | 14/19 | 15/19 | +1 |
| OOD Threshold | 39.26 | **46.69** | +19% |
| DonnÃ©es train | ~2,100 | ~6,300 | 3x |

#### Accuracy par organe (validation, 3 folds)

| Organe | Accuracy | Samples Val |
|--------|----------|-------------|
| Bladder | 100.0% | 30 |
| Cervix | 100.0% | 65 |
| Colon | 100.0% | 265 |
| Esophagus | 100.0% | 85 |
| Kidney | 100.0% | 28 |
| Liver | 100.0% | 37 |
| Lung | 100.0% | 36 |
| Ovarian | 100.0% | 26 |
| Pancreatic | 100.0% | 43 |
| Prostate | 100.0% | 41 |
| Skin | 100.0% | 36 |
| Stomach | 100.0% | 29 |
| Testis | 100.0% | 39 |
| Thyroid | 100.0% | 38 |
| Uterus | 100.0% | 43 |
| Breast | 99.4% | 487 |
| Adrenal_gland | 99.0% | 97 |
| HeadNeck | 98.7% | 79 |
| Bile-duct | 97.4% | 76 |

**Commandes d'entraÃ®nement (3 folds) :**
```bash
# OrganHead (~10 min)
python scripts/training/train_organ_head.py --folds 0 1 2 --epochs 50

# HoVerNet par famille (voir section suivante)
python scripts/training/train_hovernet_family.py --family glandular --epochs 50 --augment
```

### 2025-12-20 â€” Architecture 5 Familles HoVer-Net âœ…

**DÃ©cision architecturale** : Au lieu d'un seul HoVer-Net global, utiliser 5 dÃ©codeurs spÃ©cialisÃ©s par famille d'organes.

**Justification scientifique** (littÃ©rature MICCAI, Nature Communications) :
- **Feature Sharing** : Les noyaux partagent des propriÃ©tÃ©s physiques â†’ backbone commun
- **Domain-Specific Variance** : L'erreur augmente entre organes de textures diffÃ©rentes
- **Domain Adaptation** : Le transfert fonctionne mieux entre organes de mÃªme famille embryologique

**Avantages techniques** :
- RAM par entraÃ®nement : ~27 GB â†’ **~5-6 GB** âœ…
- Gradient propre (pas de signaux contradictoires)
- Meilleure classification NT par famille
- Convergence plus rapide

#### Distribution par Famille (PanNuke)

| Famille | Organes | Samples | % | RAM estimÃ©e |
|---------|---------|---------|---|-------------|
| **Glandulaire** | Breast, Prostate, Thyroid, Pancreatic, Adrenal_gland | 3,535 | 45% | ~5 GB |
| **Digestive** | Colon, Stomach, Esophagus, Bile-duct | 2,274 | 29% | ~3.5 GB |
| **Urologique** | Kidney, Bladder, Testis, Ovarian, Uterus, Cervix | 1,153 | 15% | ~2 GB |
| **Ã‰pidermoÃ¯de** | Skin, HeadNeck | 574 | 7% | ~1 GB |
| **Respiratoire** | Lung, Liver | 364 | 5% | ~0.6 GB |

#### Mapping Organe â†’ Famille

```python
ORGAN_TO_FAMILY = {
    # Glandulaire & Hormonale (acini, sÃ©crÃ©tions)
    "Breast": "glandular",
    "Prostate": "glandular",
    "Thyroid": "glandular",
    "Pancreatic": "glandular",
    "Adrenal_gland": "glandular",

    # Digestive (formes tubulaires)
    "Colon": "digestive",
    "Stomach": "digestive",
    "Esophagus": "digestive",
    "Bile-duct": "digestive",

    # Urologique & Reproductif (densitÃ© nuclÃ©aire)
    "Kidney": "urologic",
    "Bladder": "urologic",
    "Testis": "urologic",
    "Ovarian": "urologic",
    "Uterus": "urologic",
    "Cervix": "urologic",

    # Respiratoire & HÃ©patique (structures ouvertes)
    "Lung": "respiratory",
    "Liver": "respiratory",

    # Ã‰pidermoÃ¯de (couches stratifiÃ©es)
    "Skin": "epidermal",
    "HeadNeck": "epidermal",
}

FAMILIES = ["glandular", "digestive", "urologic", "respiratory", "epidermal"]
```

#### Pipeline d'InfÃ©rence

```python
# 1. OrganHead prÃ©dit l'organe (99.56% accuracy)
organ = organ_head.predict(cls_token)  # "Prostate"

# 2. Router sÃ©lectionne le bon dÃ©codeur
family = ORGAN_TO_FAMILY[organ]  # "glandular"

# 3. DÃ©codeur spÃ©cialisÃ© segmente
cells = hovernet_decoders[family].predict(patch_tokens)
```

### 2025-12-20 â€” EntraÃ®nement Famille Digestive âœ…

**RÃ©sultats finaux (50 epochs):**
| MÃ©trique | Train | Validation | Best |
|----------|-------|------------|------|
| Loss | 0.6369 | 0.6890 | 0.6995 |
| NP Dice | 0.9677 | 0.9627 | **0.9634** |
| HV MSE | 0.0227 | 0.0152 | **0.0163** |
| NT Acc | 0.8748 | 0.8748 | **0.8824** |

**Observations:**
- HV MSE amÃ©liorÃ© de 0.27 (epoch 6) â†’ 0.016 (epoch 50) = **94% d'amÃ©lioration**
- Pas d'overfitting : Train Loss (0.64) â‰ˆ Val Loss (0.69)
- Performances comparables Ã  Glandulaire

**Checkpoint:** `models/checkpoints/hovernet_digestive_best.pth`

### 2025-12-20 â€” EntraÃ®nement 5 Familles ComplÃ©tÃ© âœ…

**Toutes les familles HoVer-Net sont maintenant entraÃ®nÃ©es.**

#### RÃ©sultats Urologique (1153 samples)
| MÃ©trique | Best |
|----------|------|
| NP Dice | 0.9318 |
| HV MSE | 0.2812 |
| NT Acc | **0.9139** |

#### RÃ©sultats Ã‰pidermoÃ¯de (574 samples)
| MÃ©trique | Best |
|----------|------|
| NP Dice | 0.9542 |
| HV MSE | 0.2733 |
| NT Acc | 0.8871 |

#### RÃ©sultats Respiratoire (364 samples) â€” Stress Test
| MÃ©trique | Best |
|----------|------|
| NP Dice | 0.9409 |
| HV MSE | 0.2836 |
| NT Acc | 0.8947 |

#### Analyse de StabilitÃ©

**DÃ©couverte clÃ©** : Le volume de donnÃ©es impacte principalement la branche HV.

```
CorrÃ©lation Samples â†’ HV MSE :
  3535 samples (Glandulaire)  â†’ 0.015 âœ… Excellent
  2274 samples (Digestive)    â†’ 0.016 âœ… Excellent
  1153 samples (Urologique)   â†’ 0.281 âš ï¸ DÃ©gradÃ©
   574 samples (Ã‰pidermoÃ¯de)  â†’ 0.273 âš ï¸ DÃ©gradÃ©
   364 samples (Respiratoire) â†’ 0.284 âš ï¸ DÃ©gradÃ©

Seuil critique : ~2000 samples pour HV MSE < 0.05
```

**Explication pathologique** :
- Glandulaire/Digestive : noyaux bien espacÃ©s, contours nets â†’ facile
- Urologique/Respiratoire : densitÃ© nuclÃ©aire Ã©levÃ©e, clusters serrÃ©s â†’ difficile
- Ã‰pidermoÃ¯de : couches stratifiÃ©es, chevauchement frÃ©quent â†’ difficile

**Conclusion** : Le systÃ¨me est stable pour dÃ©tection (NP) et classification (NT).
Seule la sÃ©paration d'instances (HV) nÃ©cessite plus de donnÃ©es ou vÃ©rification manuelle.

#### Commandes d'entraÃ®nement par famille

```bash
# Famille Glandulaire (prioritÃ© - 45% des donnÃ©es)
python scripts/training/train_hovernet_family.py --family glandular --epochs 50 --augment

# Famille Digestive
python scripts/training/train_hovernet_family.py --family digestive --epochs 50 --augment

# Famille Urologique
python scripts/training/train_hovernet_family.py --family urologic --epochs 50 --augment

# Famille Ã‰pidermoÃ¯de
python scripts/training/train_hovernet_family.py --family epidermal --epochs 50 --augment

# Famille Respiratoire
python scripts/training/train_hovernet_family.py --family respiratory --epochs 50 --augment
```

### 2025-12-20 â€” FIX CRITIQUE: Preprocessing ToPILImage âš ï¸ IMPORTANT

**ProblÃ¨me dÃ©couvert:** Le script `extract_features.py` utilisait `ToPILImage()` avec des images `float64 [0, 255]`. `ToPILImage` multiplie les floats par 255, causant un overflow â†’ **features corrompues**.

```python
# BUG: ToPILImage avec float64 [0,255]
img_float64 = [100, 150, 200]  # Pixel rose H&E
â†’ ToPILImage multiplie par 255
â†’ [25500, 38250, 51000] â†’ overflow uint8
â†’ [156, 106, 56]  # Couleur FAUSSE !
```

**Impact:** Tous les modÃ¨les entraÃ®nÃ©s avant ce fix utilisaient des features corrompues.

**Solution appliquÃ©e:**
1. `extract_features.py` : Convertir en `uint8` avant `ToPILImage`
2. Scripts d'infÃ©rence : Utiliser `create_hoptimus_transform()` identique
3. Optimisation RAM : `mmap_mode='r'` + traitement par chunks

**Fichiers modifiÃ©s:**
- `scripts/preprocessing/extract_features.py` â€” Conversion uint8 + optimisation RAM
- `src/inference/optimus_gate_inference_multifamily.py` â€” Transform unifiÃ©
- `src/inference/optimus_gate_inference.py` â€” Transform unifiÃ©
- `src/inference/hoptimus_hovernet.py` â€” Transform unifiÃ©

**RÃ©-entraÃ®nement complet effectuÃ©:**

| Composant | Avant (corrompu) | AprÃ¨s (corrigÃ©) |
|-----------|------------------|-----------------|
| OrganHead Accuracy | 99.56% | **99.94%** |
| Glandular NP Dice | 0.9645 | **0.9648** |
| Glandular HV MSE | 0.0150 | **0.0106** (-29%) |
| Glandular NT Acc | 0.88 | **0.9111** (+3.5%) |

**Scripts de vÃ©rification crÃ©Ã©s:**
- `scripts/validation/verify_pipeline.py` â€” VÃ©rification complÃ¨te avant entraÃ®nement
- `scripts/validation/diagnose_ood_issue.py` â€” Diagnostic des problÃ¨mes OOD
- `scripts/setup/download_and_prepare_pannuke.py` â€” TÃ©lÃ©chargement + rÃ©organisation PanNuke

### 2025-12-21 â€” EntraÃ®nement 5 Familles COMPLET âœ…

**Toutes les familles HoVer-Net sont maintenant entraÃ®nÃ©es:**

| Famille | Statut | NP Dice | HV MSE | NT Acc |
|---------|--------|---------|--------|--------|
| Glandulaire | âœ… | 0.9648 | 0.0106 | 0.9111 |
| Digestive | âœ… | 0.9634 | 0.0163 | 0.8824 |
| Urologique | âœ… | 0.9318 | 0.2812 | 0.9139 |
| Ã‰pidermoÃ¯de | âœ… | 0.9542 | 0.2653 | 0.8857 |
| Respiratoire | âœ… | 0.9409 | 0.0500 | 0.9183 |

**Observations clÃ©s:**
- **Glandulaire et Digestive** (>2000 samples): HV MSE excellent (<0.02)
- **Respiratoire** (408 samples): Surprise positive! HV MSE = 0.05 malgrÃ© peu de donnÃ©es
- **Urologique et Ã‰pidermoÃ¯de**: HV MSE dÃ©gradÃ© (~0.27) mais NP Dice et NT Acc trÃ¨s bons
- **Seuil critique**: ~2000 samples pour HV MSE < 0.05 (exception Respiratoire)

**Analyse Respiratoire (surprise):**
La famille Respiratoire (Lung + Liver) obtient un excellent HV MSE (0.05) malgrÃ© seulement 408 samples. HypothÃ¨ses:
- Structures ouvertes (alvÃ©oles, travÃ©es hÃ©patiques) â†’ noyaux naturellement espacÃ©s
- Moins de chevauchement nuclÃ©aire â†’ frontiÃ¨res plus faciles Ã  apprendre
- HomogÃ©nÃ©itÃ© morphologique Lung/Liver

**Tous les objectifs POC atteints:**
- OrganHead: 99.94% accuracy
- 5/5 familles: Dice â‰¥ 0.93
- Pipeline complet fonctionnel

### 2025-12-21 â€” FIX CRITIQUE: LayerNorm Mismatch âš ï¸ SOLUTION CIBLE

**ProblÃ¨me dÃ©couvert:** Erreur de prÃ©diction organe â€” Breast prÃ©dit comme Prostate (87% confiance).

**Cause racine:** IncohÃ©rence entre extraction de features et infÃ©rence:
- `extract_features.py` utilisait des hooks sur `blocks[23]` (SANS LayerNorm final)
- Les fichiers d'infÃ©rence utilisaient `forward_features()` (AVEC LayerNorm final)
- RÃ©sultat: CLS std ~0.28 (entraÃ®nement) vs ~0.77 (infÃ©rence) = ratio 2.7x!

```
AVANT (BUG):
  extract_features.py â†’ hooks blocks[23] â†’ std ~0.28 (sans LayerNorm)
  inference/*.py â†’ forward_features() â†’ std ~0.77 (avec LayerNorm)
  â†’ MISMATCH â†’ PrÃ©dictions incorrectes

APRÃˆS (SOLUTION CIBLE):
  extract_features.py â†’ forward_features() â†’ std ~0.77 (avec LayerNorm)
  inference/*.py â†’ forward_features() â†’ std ~0.77 (avec LayerNorm)
  â†’ COHÃ‰RENT â†’ PrÃ©dictions correctes
```

**Solution cible implÃ©mentÃ©e:**

1. **Modification `extract_features.py`:**
   - Utilise `forward_features()` au lieu de hooks
   - Ajoute vÃ©rification CLS std (attendu: 0.70-0.90)
   - Sauvegarde avec clÃ© `features` (shape N, 261, 1536)

2. **Script de vÃ©rification crÃ©Ã©:** `scripts/validation/verify_features.py`
   - VÃ©rifie CLS std dans la plage attendue
   - DÃ©tecte features corrompues (std < 0.40 = sans LayerNorm)
   - Option `--verify_fresh` pour comparaison avec extraction fraÃ®che

3. **Simplification des fichiers d'infÃ©rence:**
   - `src/inference/optimus_gate_inference.py`
   - `src/inference/optimus_gate_inference_multifamily.py`
   - `src/inference/hoptimus_hovernet.py`
   - `scripts/validation/diagnose_organ_prediction.py`
   - Tous utilisent maintenant `forward_features()` directement

**CritÃ¨res de validation:**
| MÃ©trique | Valeur attendue | Signification |
|----------|----------------|---------------|
| CLS std | 0.70 - 0.90 | Features avec LayerNorm âœ… |
| CLS std | < 0.40 | Features CORROMPUES âŒ |

**Ã‰tapes de rÃ©-entraÃ®nement requises:**
```bash
# 1. VÃ©rifier features existantes (avant rÃ©-extraction)
python scripts/validation/verify_features.py --features_dir data/cache/pannuke_features

# 2. RÃ©-extraire les features pour les 3 folds (avec chunking pour Ã©conomiser la RAM)
for fold in 0 1 2; do
    python scripts/preprocessing/extract_features.py \
        --data_dir /home/amar/data/PanNuke \
        --fold $fold \
        --batch_size 8 \
        --chunk_size 500
done

# 3. VÃ©rifier aprÃ¨s extraction
python scripts/validation/verify_features.py --features_dir data/cache/pannuke_features

# 4. RÃ©-entraÃ®ner OrganHead
python scripts/training/train_organ_head.py --folds 0 1 2 --epochs 50

# 5. VÃ©rifier sur image de test
python scripts/validation/diagnose_organ_prediction.py --image path/to/breast_01.png --expected Breast
```

**Fichiers modifiÃ©s:**
- `scripts/preprocessing/extract_features.py` â€” forward_features() + vÃ©rification
- `scripts/validation/verify_features.py` â€” ğŸ†• Script de vÃ©rification
- `scripts/validation/diagnose_organ_prediction.py` â€” forward_features()
- `src/inference/optimus_gate_inference.py` â€” Suppression hooks
- `src/inference/optimus_gate_inference_multifamily.py` â€” Suppression hooks
- `src/inference/hoptimus_hovernet.py` â€” Suppression hooks

### 2025-12-21 â€” Confiance CalibrÃ©e et Top-3 PrÃ©dictions âœ… NOUVEAU

**ImplÃ©mentation du Temperature Scaling (T=0.5) dans l'IHM:**

#### Modifications OrganHead (`src/models/organ_head.py`)

```python
@dataclass
class OrganPrediction:
    # Nouveaux champs
    confidence_calibrated: float  # Confiance aprÃ¨s Temperature Scaling
    probabilities_calibrated: np.ndarray  # ProbabilitÃ©s calibrÃ©es
    top3: List[Tuple[str, float]]  # Top-3 prÃ©dictions avec confiances

    def get_confidence_level(self) -> str:
        """Retourne le niveau de confiance avec emoji."""
        conf = self.confidence_calibrated
        if conf >= 0.95:
            return "ğŸŸ¢ TrÃ¨s fiable"
        elif conf >= 0.85:
            return "ğŸŸ¡ Fiable"
        elif conf >= 0.70:
            return "ğŸŸ  Ã€ vÃ©rifier"
        else:
            return "ğŸ”´ Incertain"
```

#### Modifications Gradio Demo (`scripts/demo/gradio_demo.py`)

- Validation CLS std au dÃ©marrage (0.70-0.90)
- Jauge de confiance colorÃ©e avec barres de progression
- Affichage top-3 prÃ©dictions alternatives
- Alerte automatique si confiance < 70%

**Exemple d'affichage:**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ ğŸ”¬ ORGANE DÃ‰TECTÃ‰                                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘    Breast (Sein)                                       â•‘
â•‘    [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘] 91.2% ğŸŸ¡ Fiable          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ğŸ“Š ALTERNATIVES (Top-3)                                â•‘
â•‘    1. Breast       [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 91.2%        â•‘
â•‘    2. Thyroid      [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  5.3%        â•‘
â•‘    3. Pancreatic   [â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  2.1%        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Commit:** a6556d7 â€” "Add calibrated confidence display (T=0.5) and top-3 predictions"

### 2025-12-21 â€” IHM Clinical-Flow (Refonte Majeure) âœ… NOUVEAU

**ImplÃ©mentation complÃ¨te du layout Clinical-Flow** optimisÃ© pour les pathologistes en environnement laboratoire.

#### Architecture 3 Colonnes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLINICAL-FLOW LAYOUT                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CONTRÃ”LE     â”‚    VISUALISEUR HAUTE       â”‚   RAPPORT CLINIQUE      â”‚
â”‚ (15%)        â”‚    RÃ‰SOLUTION (55%)        â”‚   (30%)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“¤ Upload    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ ğŸ¯ Organe    â”‚ â”‚  H&E    â”‚ â”‚   IA    â”‚    â”‚ â”‚   SMART CARDS       â”‚ â”‚
â”‚ ğŸ”¬ Analyser  â”‚ â”‚  Brut   â”‚ â”‚ Marquageâ”‚    â”‚ â”‚ â€¢ Identification    â”‚ â”‚
â”‚              â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â”‚ â€¢ Anisocaryose      â”‚ â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚                            â”‚ â”‚ â€¢ Ratio NÃ©oplasique â”‚ â”‚
â”‚ ğŸ”Œ STATUS    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚ â€¢ TILs Hot/Cold     â”‚ â”‚
â”‚ â€¢ Glandular  â”‚ â”‚   CARTE INCERTITUDE  â”‚   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â€¢ Digestive  â”‚ â”‚  ğŸŸ¢ Fiable â†’ ğŸ”´ OOD  â”‚   â”‚                         â”‚
â”‚ â€¢ Urologic   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â€¢ Epidermal  â”‚                            â”‚ â”‚    DONUT CHART      â”‚ â”‚
â”‚ â€¢ Respirat.  â”‚ ğŸ” XAI: [Dropdown]  [âœ¨]   â”‚ â”‚  [Population SVG]   â”‚ â”‚
â”‚              â”‚                            â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚                            â”‚                         â”‚
â”‚ ğŸ›¡ï¸ INTÃ‰GRITÃ‰ â”‚                            â”‚ â–¼ Journal Anomalies     â”‚
â”‚ [OOD Badge]  â”‚                            â”‚   (collapsible)         â”‚
â”‚              â”‚                            â”‚                         â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚                            â”‚                         â”‚
â”‚ ğŸ¨ CALQUES   â”‚                            â”‚                         â”‚
â”‚ â—‹ H&E       â”‚                            â”‚                         â”‚
â”‚ â— SEG       â”‚                            â”‚                         â”‚
â”‚ â—‹ HEAT      â”‚                            â”‚                         â”‚
â”‚ â—‹ BOTH      â”‚                            â”‚                         â”‚
â”‚              â”‚                            â”‚                         â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚                            â”‚                         â”‚
â”‚ ğŸ”§ SAV       â”‚                            â”‚                         â”‚
â”‚ [ğŸ“¸ Snapshot]â”‚                            â”‚                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Fonctions Helper AjoutÃ©es

| Fonction | Description |
|----------|-------------|
| `generate_family_status_html()` | Indicateurs visuels pour les 5 familles HoVer-Net |
| `generate_ood_badge(score)` | Badge OOD colorÃ© (vert/orange/rouge) |
| `generate_donut_chart_html(counts)` | Graphique donut SVG avec lÃ©gende |
| `generate_smart_cards(...)` | Cartes d'alerte cliniques avec niveaux de risque |
| `export_debug_snapshot(...)` | Export SAV (image + mÃ©tadonnÃ©es + masques) |
| `DARK_LAB_CSS` | ThÃ¨me anthracite pour environnement laboratoire |

#### Smart Cards â€” Alertes Cliniques

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ”¬ IDENTIFICATION                    â”‚
â”‚ Breast â€” 92.0% ğŸŸ¡ Fiable             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ”´ ANISOCARYOSE MARQUÃ‰E              â”‚
â”‚ CV = 0.47 (seuil: 0.35)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸŸ¡ RATIO NÃ‰OPLASIQUE                 â”‚
â”‚ 68.2% (5+ cellules tumeur)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ”¥ TILs CHAUDS                       â”‚
â”‚ Infiltration intra-tumorale active   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### SAV Debug Snapshot

Export pour diagnostic technique:
```python
export_debug_snapshot(image, result_data, output_dir="data/snapshots")
# GÃ©nÃ¨re:
# - snapshot_YYYYMMDD_HHMMSS.json  (mÃ©tadonnÃ©es complÃ¨tes)
# - snapshot_YYYYMMDD_HHMMSS.png   (image originale)
# - snapshot_YYYYMMDD_HHMMSS_masks.npz (masques NP/NT/instance)
```

**Commit:** d74adad â€” "Implement Clinical-Flow IHM layout for laboratory pathologists"

---

## Fichiers CrÃ©Ã©s (Inventaire)

```
src/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ unetr_decoder.py          # DÃ©codeur UNETR (obsolÃ¨te)
â”‚   â”œâ”€â”€ hovernet_decoder.py       # DÃ©codeur HoVer-Net (Flux Local)
â”‚   â””â”€â”€ organ_head.py             # OrganHead (Flux Global)
â”œâ”€â”€ inference/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ optimus_gate.py           # Architecture unifiÃ©e Optimus-Gate
â”‚   â”œâ”€â”€ optimus_gate_inference.py # ğŸ†• Wrapper Gradio (image â†’ rÃ©sultats)
â”‚   â”œâ”€â”€ hoptimus_hovernet.py      # Wrapper H-optimus-0 + HoVer-Net
â”‚   â”œâ”€â”€ hoptimus_unetr.py         # Wrapper H-optimus-0 + UNETR (fallback)
â”‚   â””â”€â”€ cellvit_official.py       # Wrapper pour repo officiel TIO-IKIM
â”œâ”€â”€ uncertainty/                   # Couche 3 & 4: SÃ©curitÃ© & Interaction Expert
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ uncertainty_estimator.py  # Entropie + Mahalanobis + Temperature Scaling
â”‚   â”œâ”€â”€ conformal_prediction.py   # Conformal Prediction (APS/LAC/RAPS)
â”‚   â””â”€â”€ roi_selection.py          # SÃ©lection automatique ROIs
â”œâ”€â”€ feedback/                      # ğŸ†• Active Learning (Couche 5)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ active_learning.py        # FeedbackCollector pour corrections expertes
â””â”€â”€ metrics/
    â””â”€â”€ morphometry.py            # Analyse morphomÃ©trique clinique

scripts/
â”œâ”€â”€ setup/
â”‚   â”œâ”€â”€ download_models.py
â”‚   â””â”€â”€ download_datasets.py
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ extract_features.py        # Extraction embeddings H-optimus-0
â”‚   â”œâ”€â”€ stain_normalization.py
â”‚   â”œâ”€â”€ tile_extraction.py
â”‚   â”œâ”€â”€ quality_filter.py
â”‚   â””â”€â”€ tissue_detection.py
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ visualize_embeddings.py
â”‚   â””â”€â”€ metrics_segmentation.py
â”œâ”€â”€ calibration/
â”‚   â””â”€â”€ temperature_scaling.py
â”œâ”€â”€ ood_detection/
â”‚   â”œâ”€â”€ latent_distance.py
â”‚   â””â”€â”€ entropy_scoring.py
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train_unetr.py            # EntraÃ®nement UNETR (obsolÃ¨te)
â”‚   â”œâ”€â”€ train_hovernet.py         # EntraÃ®nement HoVer-Net (Flux Local)
â”‚   â””â”€â”€ train_organ_head.py       # EntraÃ®nement OrganHead (Flux Global)
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ inspect_checkpoint.py
â”œâ”€â”€ validation/
â”‚   â”œâ”€â”€ test_cellvit256_inference.py  # Test Ã©tape 1.5 POC
â”‚   â”œâ”€â”€ test_optimus_gate.py          # Test Optimus-Gate complet
â”‚   â”œâ”€â”€ verify_features.py            # ğŸ†• VÃ©rification features H-optimus-0
â”‚   â””â”€â”€ diagnose_organ_prediction.py  # Diagnostic prÃ©diction organe
â””â”€â”€ demo/
    â”œâ”€â”€ gradio_demo.py             # Interface principale
    â”œâ”€â”€ synthetic_cells.py         # GÃ©nÃ©rateur tissus
    â””â”€â”€ visualize_cells.py         # Fonctions visualisation

models/
â”œâ”€â”€ pretrained/
â”‚   â””â”€â”€ CellViT-256.pth            # 187 MB (baseline)
â””â”€â”€ checkpoints/
    â”œâ”€â”€ hovernet_best.pth          # HoVer-Net (Dice 0.9601)
    â””â”€â”€ organ_head_best.pth        # OrganHead (Acc 96.05%)
```

---

## ProblÃ¨mes Connus & Solutions

| ProblÃ¨me | Solution |
|----------|----------|
| Conda ToS non acceptÃ©es | `conda tos accept --override-channels --channel <url>` |
| Docker "command not found" dans WSL | Installer Docker Engine natif, pas Docker Desktop |
| H-optimus-0 accÃ¨s refusÃ© (401/403) | Voir section "AccÃ¨s H-optimus-0" ci-dessous |
| Token HuggingFace "fine-grained" sans accÃ¨s gated | Activer "Read access to public gated repos" dans les permissions du token |

---

## AccÃ¨s H-optimus-0 (Gated Model)

H-optimus-0 est un modÃ¨le "gated" sur HuggingFace. Configuration requise :

### Ã‰tape 1 : Demander l'accÃ¨s
1. CrÃ©er un compte sur https://huggingface.co
2. Aller sur https://huggingface.co/bioptimus/H-optimus-0
3. Cliquer sur "Agree and access repository"

### Ã‰tape 2 : CrÃ©er un token avec les bonnes permissions
1. Aller sur https://huggingface.co/settings/tokens
2. CrÃ©er un nouveau token avec ces permissions :
   - âœ… **Read access to contents of all public gated repos you can access**
   - âœ… Read access to contents of all repos under your personal namespace

### Ã‰tape 3 : Se connecter
```bash
huggingface-cli login
# Coller le token quand demandÃ©
```

### VÃ©rification
```bash
huggingface-cli whoami
```

---

## Guide d'Installation ComplÃ¨te (depuis zÃ©ro)

### PrÃ©requis Windows
- Windows 10/11 avec WSL2 activÃ©
- GPU NVIDIA avec drivers rÃ©cents

### 1. WSL2 + Ubuntu
```powershell
# PowerShell Admin
wsl --install -d Ubuntu-24.04
wsl --set-default-version 2
```

### 2. Docker Engine natif (dans WSL)
```bash
# DÃ©pendances
sudo apt update && sudo apt upgrade -y
sudo apt install -y ca-certificates curl gnupg

# ClÃ© GPG Docker
sudo install -m 0755 -d /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
sudo chmod a+r /etc/apt/keyrings/docker.gpg

# Repository Docker
echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# Installation
sudo apt update
sudo apt install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
sudo usermod -aG docker $USER
# Fermer et rouvrir le terminal
```

### 3. NVIDIA Container Toolkit
```bash
# Repository NVIDIA
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
  sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
  sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

# Installation
sudo apt update
sudo apt install -y nvidia-container-toolkit
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker

# Test
docker run --rm --gpus all nvidia/cuda:12.4.0-base-ubuntu22.04 nvidia-smi
```

### 4. Miniconda + Environnement
```bash
# Installer Miniconda
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh
bash ~/miniconda.sh -b -p $HOME/miniconda3
~/miniconda3/bin/conda init zsh  # ou bash
rm ~/miniconda.sh
# Fermer et rouvrir le terminal

# Accepter ToS
conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main
conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r

# CrÃ©er environnement
conda create -n cellvit python=3.10 -y
conda activate cellvit
```

### 5. PyTorch + DÃ©pendances
```bash
# PyTorch avec CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124

# DÃ©pendances projet
pip install timm transformers huggingface_hub
pip install scikit-learn scipy pandas matplotlib seaborn
pip install tifffile opencv-python netcal mapie gradio
```

### 6. Test final
```bash
python -c "
import torch
print('PyTorch:', torch.__version__)
print('CUDA:', torch.cuda.is_available())
print('GPU:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A')
"
```

---

## DÃ©pendances ClÃ©s (Ã  installer)

```
# Core ML
torch>=2.0
torchvision
timm
transformers

# Histopathologie
openslide-python
tifffile
staintools  # ou torchstain

# Ã‰valuation
scikit-learn
scipy
pandas
matplotlib

# Calibration & Incertitude
netcal
mapie

# API/DÃ©mo
fastapi
gradio  # ou streamlit
```

---

## FonctionnalitÃ©s Futures (Roadmap Expert)

### Suggestions d'un pathologiste expert pour transformer le prototype en outil clinique.

### 1. Incertitude Technique vs Biologique (PrioritÃ© Haute)

**ProblÃ¨me actuel:** Le calque HEAT mÃ©lange deux types d'incertitude.

**Solution proposÃ©e:** Diviser en deux calques distincts:

```
HEAT_TECH (Incertitude Technique - OOD)
â”œâ”€â”€ ProblÃ¨mes de focus
â”œâ”€â”€ Plis du tissu
â”œâ”€â”€ Artefacts (bulles, poussiÃ¨res)
â””â”€â”€ Zones hors domaine (coloration atypique)

HEAT_BIO (Incertitude Biologique)
â”œâ”€â”€ Classification ambiguÃ« (Inflammatory â†” Neoplastic)
â”œâ”€â”€ Bordures de noyaux floues
â””â”€â”€ Types cellulaires intermÃ©diaires
```

**BÃ©nÃ©fice clinique:** Le mÃ©decin ne rÃ©agit pas de la mÃªme faÃ§on Ã  une bulle d'air qu'Ã  une cellule de type "indÃ©terminÃ©".

### 2. Galerie de Noyaux de RÃ©fÃ©rence (Visual Benchmarking)

**Concept:** Afficher une galerie comparative:
- Noyau "typique sain" de l'organe dÃ©tectÃ©
- Noyau "atypique" sÃ©lectionnÃ© par l'alerte

**ImplÃ©mentation suggÃ©rÃ©e:**
```python
class ReferenceNucleiGallery:
    def __init__(self, organ: str):
        # Charger noyaux de rÃ©fÃ©rence par organe
        self.healthy_refs = load_reference_nuclei(organ, "healthy")
        self.atypical_refs = load_reference_nuclei(organ, "atypical")

    def compare(self, nucleus_crop: np.ndarray) -> np.ndarray:
        # Afficher cÃ´te Ã  cÃ´te: [Healthy] [Query] [Atypical]
        return create_comparison_strip(
            self.healthy_refs[0], nucleus_crop, self.atypical_refs[0]
        )
```

**BÃ©nÃ©fice clinique:** Ã‰chelle de comparaison visuelle immÃ©diate.

### 3. Navigation WSI avec Mini-Map (PrioritÃ© Haute pour Production)

**Concept:** Interface de navigation pour lames entiÃ¨res (Whole Slide Images).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚ â”‚ Mini-Mapâ”‚  â† Vue d'ensemble de la lame                  â”‚
â”‚ â”‚ â—â—â—‹â—‹â—   â”‚    â€¢ = Points d'intÃ©rÃªt (POIs) prÃ©-calculÃ©s  â”‚
â”‚ â”‚ â—‹â—â—â—‹â—‹   â”‚                                               â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚                                                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚                                                       â”‚ â”‚
â”‚ â”‚              PATCH HAUTE RÃ‰SOLUTION                   â”‚ â”‚
â”‚ â”‚              (Clic sur POI â†’ zoom ici)                â”‚ â”‚
â”‚ â”‚                                                       â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚ â”‚ PANNEAU MORPHOMÃ‰TRIQUE (temps rÃ©el)     â”‚               â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Workflow proposÃ©:**
1. PrÃ©-calculer les POIs (ROIs Ã  haute incertitude ou nÃ©oplasie)
2. Le pathologiste clique sur un POI dans la Mini-Map
3. L'IHM saute au patch correspondant
4. Le panneau morphomÃ©trique s'actualise

**ImplÃ©mentation:**
- Utiliser OpenSlide pour lecture WSI pyramidale
- PrÃ©-calculer les POIs avec `ROISelector` existant
- Stocker les embeddings H-optimus-0 par patch pour navigation rapide

### 4. Export vers DICOM-SR (Structured Report)

**Concept:** GÃ©nÃ©rer un rapport DICOM-SR compatible avec les PACS hospitaliers.

**Champs suggÃ©rÃ©s:**
- NumÃ©ro d'analyse
- Date/Heure
- MÃ©triques morphomÃ©triques
- Alertes cliniques
- Niveau de confiance
- Captures d'Ã©cran annotÃ©es

### 5. Mode "DeuxiÃ¨me Lecture" (Quality Assurance) âœ… IMPLÃ‰MENTÃ‰ (v1)

**Concept:** Comparer automatiquement la prÃ©diction du modÃ¨le avec la lecture du pathologiste.

**ImplÃ©mentÃ© (commit 003bba7):**
- âœ… Module `FeedbackCollector` pour stocker les corrections
- âœ… Onglet Gradio "ğŸ“ Feedback Expert"
- âœ… Types de feedback: cell type, mitose FP/FN, TILs, organe
- âœ… Niveaux de sÃ©vÃ©ritÃ©: low, medium, high, critical
- âœ… Export JSON pour retraining

**Ã€ faire (v2):**
- ğŸ”œ Comparaison automatique prÃ©diction vs correction
- ğŸ”œ Statistiques de concordance par session
- ğŸ”œ Alertes sur patterns d'erreur rÃ©currents
- ğŸ”œ Pipeline de retraining automatisÃ©

### 6. Temperature Scaling & Calibration UX âœ… IMPLÃ‰MENTÃ‰

**Date:** 2025-12-21
**Statut:** âœ… IMPLÃ‰MENTÃ‰ (commit a6556d7)

#### Contexte

Le modÃ¨le OrganHead atteint 100% d'accuracy mais les confiances brutes (T=1.0) sont sous-calibrÃ©es:
- Breast: 44-49% de confiance (alors que 100% correct)
- Colon: 58-63%
- Prostate: 81-94%

**Temperature Scaling** permet d'ajuster les confiances sans changer les prÃ©dictions.

#### RÃ©sultats ExpÃ©rimentaux (test sur 15 images)

| TempÃ©rature | Accuracy | Conf. Moy. | Conf. Min | Conf. Max |
|-------------|----------|------------|-----------|-----------|
| T = 1.0 (brut) | 100% | 65.9% | 44.7% | 94.6% |
| **T = 0.5** | 100% | **96.4%** | 91.0% | 100.0% |
| T = 0.25 | 100% | 100.0% | 99.9% | 100.0% |
| T = 0.1 | 100% | 100.0% | 100.0% | 100.0% |

**Recommandation:** Utiliser **T = 0.5** pour un bon Ã©quilibre.

#### FonctionnalitÃ©s UX ImplÃ©mentÃ©es

**1. âœ… Affichage de la confiance calibrÃ©e dans l'IHM:**

ImplÃ©mentÃ© dans `scripts/demo/gradio_demo.py` avec `format_organ_header()`:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ”¬ ORGANE DÃ‰TECTÃ‰                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    Breast                                               â”‚
â”‚    [â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘] 92.0%                         â”‚
â”‚    ğŸŸ¡ Fiable                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“Š TOP-3 PRÃ‰DICTIONS                                    â”‚
â”‚    1. Breast       [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 92.0%         â”‚
â”‚    2. Thyroid      [â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  5.0%         â”‚
â”‚    3. Prostate     [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]  2.0%         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**2. âœ… Jauge de confiance avec zones colorÃ©es:**

ImplÃ©mentÃ© dans `get_confidence_color()` et `format_confidence_gauge()`:
```python
def get_confidence_color(conf: float) -> str:
    if conf >= 0.95:
        return "ğŸŸ¢ TrÃ¨s fiable"
    elif conf >= 0.85:
        return "ğŸŸ¡ Fiable"
    elif conf >= 0.70:
        return "ğŸŸ  Ã€ vÃ©rifier"
    else:
        return "ğŸ”´ Incertain"
```

**3. ğŸ”œ Slider tempÃ©rature (mode expert):**
- Ã€ implÃ©menter dans une future version
- Valeur par dÃ©faut actuelle: T = 0.5 (hardcodÃ© dans OrganHead)

**4. âœ… Comparaison multi-organes (top-3):**

ImplÃ©mentÃ© dans `OrganHead.get_top_k()` et `OrganPrediction.top3`:
```python
# Dans OrganHead
top3 = model.get_top_k(probs_calibrated, k=3)
# Retourne: [('Breast', 0.92), ('Thyroid', 0.05), ('Prostate', 0.02)]
```

**5. âœ… Alerte pour confiance basse:**
- Affiche warning dans `format_organ_header()` si confiance < 70%
- Message: "âš ï¸ ATTENTION: Confiance faible - VÃ©rification manuelle recommandÃ©e"

#### Scripts Existants

| Script | Description |
|--------|-------------|
| `scripts/calibration/calibrate_organ_head.py` | Calibration Temperature Scaling |
| `scripts/calibration/temperature_scaling.py` | Classes TemperatureScaler, ECE, MCE |
| `scripts/validation/test_organ_prediction_batch.py` | Test avec `--compare_temps` |

#### Code d'IntÃ©gration (Ã  ajouter dans infÃ©rence)

```python
# Dans OrganHead ou OptimusGate
class CalibratedOrganHead:
    def __init__(self, temperature: float = 0.5):
        self.temperature = temperature

    def predict_calibrated(self, cls_token: torch.Tensor) -> dict:
        logits = self.organ_head(cls_token)
        scaled_logits = logits / self.temperature
        probs = torch.softmax(scaled_logits, dim=1)

        top3_probs, top3_idx = probs.topk(3, dim=1)

        return {
            'organ': PANNUKE_ORGANS[top3_idx[0, 0]],
            'confidence': top3_probs[0, 0].item(),
            'confidence_level': self.get_confidence_color(top3_probs[0, 0].item()),
            'top3': [(PANNUKE_ORGANS[idx], prob.item())
                     for idx, prob in zip(top3_idx[0], top3_probs[0])],
        }
```

#### PrioritÃ©

| FonctionnalitÃ© | PrioritÃ© | Effort |
|----------------|----------|--------|
| Affichage confiance calibrÃ©e | Haute | 1h |
| Jauge colorÃ©e | Haute | 30min |
| Top-3 prÃ©dictions | Moyenne | 1h |
| Slider tempÃ©rature (expert) | Basse | 2h |
| Alerte confiance basse | Haute | 30min |

### 7. Normalisation des DonnÃ©es dans l'IHM âœ… IMPLÃ‰MENTÃ‰

**Date:** 2025-12-21
**Statut:** âœ… ImplÃ©mentÃ© dans l'IHM
**PrioritÃ©:** âœ… COMPLÃ‰TÃ‰ - Pipeline cohÃ©rent entre entraÃ®nement et infÃ©rence

#### Contexte

> **ATTENTION:** L'IHM DOIT utiliser EXACTEMENT le mÃªme pipeline de normalisation
> que l'entraÃ®nement. Sinon, les prÃ©dictions seront FAUSSES.

Deux bugs critiques ont Ã©tÃ© dÃ©couverts et corrigÃ©s:
1. **ToPILImage + float64** â†’ Overflow couleurs â†’ Features corrompues
2. **LayerNorm mismatch** â†’ CLS std 0.28 vs 0.77 â†’ PrÃ©dictions fausses

#### Pipeline Obligatoire pour l'IHM

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 PIPELINE IHM (IDENTIQUE Ã€ L'ENTRAÃNEMENT)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  UPLOAD IMAGE (Gradio/API)                                      â”‚
â”‚         â”‚                                                       â”‚
â”‚         â–¼                                                       â”‚
â”‚  âš ï¸ Ã‰TAPE 1: Conversion uint8                                   â”‚
â”‚     if image.dtype != np.uint8:                                â”‚
â”‚         image = image.clip(0, 255).astype(np.uint8)            â”‚
â”‚         â”‚                                                       â”‚
â”‚         â–¼                                                       â”‚
â”‚  Ã‰TAPE 2: Transform torchvision (CANONIQUE)                    â”‚
â”‚     â€¢ ToPILImage()                                              â”‚
â”‚     â€¢ Resize((224, 224))                                        â”‚
â”‚     â€¢ ToTensor()                                                â”‚
â”‚     â€¢ Normalize(HOPTIMUS_MEAN, HOPTIMUS_STD)                   â”‚
â”‚         â”‚                                                       â”‚
â”‚         â–¼                                                       â”‚
â”‚  âš ï¸ Ã‰TAPE 3: forward_features() (PAS blocks[X])                â”‚
â”‚     features = backbone.forward_features(tensor)               â”‚
â”‚         â”‚                                                       â”‚
â”‚         â–¼                                                       â”‚
â”‚  Ã‰TAPE 4: PrÃ©diction OrganHead / HoVer-Net                     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Code Ã  IntÃ©grer dans l'IHM (Gradio)

```python
# âš ï¸ CE CODE DOIT ÃŠTRE IDENTIQUE PARTOUT
from torchvision import transforms
import numpy as np

HOPTIMUS_MEAN = (0.707223, 0.578729, 0.703617)
HOPTIMUS_STD = (0.211883, 0.230117, 0.177517)

def create_hoptimus_transform():
    """Transform CANONIQUE - NE PAS MODIFIER."""
    return transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=HOPTIMUS_MEAN, std=HOPTIMUS_STD),
    ])

def preprocess_for_inference(image: np.ndarray) -> torch.Tensor:
    """
    PrÃ©traitement pour infÃ©rence dans l'IHM.

    âš ï¸ CRITIQUE: Ce code DOIT Ãªtre identique Ã  extract_features.py
    """
    # Ã‰TAPE 1: Conversion uint8 OBLIGATOIRE
    if image.dtype != np.uint8:
        if image.max() <= 1.0:
            image = (image * 255).clip(0, 255).astype(np.uint8)
        else:
            image = image.clip(0, 255).astype(np.uint8)

    # Ã‰TAPE 2: Transform canonique
    transform = create_hoptimus_transform()
    tensor = transform(image).unsqueeze(0)

    return tensor.to(device)

def extract_features_for_inference(backbone, tensor: torch.Tensor) -> torch.Tensor:
    """
    Extraction features pour infÃ©rence.

    âš ï¸ CRITIQUE: Utiliser forward_features(), JAMAIS blocks[X]
    """
    with torch.no_grad():
        # forward_features() inclut le LayerNorm final
        features = backbone.forward_features(tensor)
    return features.float()
```

#### Validation dans l'IHM

```python
def validate_preprocessing(image: np.ndarray, backbone) -> bool:
    """
    VÃ©rifie que le preprocessing est correct.
    Ã€ appeler au dÃ©marrage de l'IHM pour valider le pipeline.
    """
    tensor = preprocess_for_inference(image)
    features = extract_features_for_inference(backbone, tensor)
    cls_token = features[:, 0, :]

    # CLS std DOIT Ãªtre entre 0.70 et 0.90
    cls_std = cls_token.std().item()

    if not (0.70 <= cls_std <= 0.90):
        raise ValueError(
            f"âš ï¸ ERREUR PREPROCESSING: CLS std = {cls_std:.3f} "
            f"(attendu: 0.70-0.90). VÃ©rifier le pipeline!"
        )

    return True
```

#### Checklist IntÃ©gration IHM

| # | VÃ©rification | Fichier | Statut |
|---|--------------|---------|--------|
| 1 | Import `create_hoptimus_transform()` | `gradio_demo.py` | âœ… |
| 2 | Conversion uint8 avant ToPILImage | `gradio_demo.py` | âœ… |
| 3 | `forward_features()` utilisÃ© | `gradio_demo.py` | âœ… |
| 4 | Validation CLS std au dÃ©marrage | `gradio_demo.py` | âœ… |
| 5 | Test avec images de rÃ©fÃ©rence | CI/CD | âœ… (validÃ© manuellement) |

#### Fichiers IHM Ã  VÃ©rifier/Modifier

| Fichier | RÃ´le | Action |
|---------|------|--------|
| `scripts/demo/gradio_demo.py` | Interface principale | âœ… CorrigÃ© (validation CLS std au dÃ©marrage) |
| `src/inference/hoptimus_hovernet.py` | InfÃ©rence HoVer-Net | âœ… CorrigÃ© |
| `src/inference/optimus_gate_inference.py` | InfÃ©rence OptimusGate | âœ… CorrigÃ© |
| `src/inference/optimus_gate_inference_multifamily.py` | Multi-famille | âœ… CorrigÃ© |

#### Test de Non-RÃ©gression

```bash
# Tester que l'IHM produit les mÃªmes rÃ©sultats que le script batch
python scripts/validation/test_organ_prediction_batch.py --samples_dir data/samples

# RÃ©sultat attendu: 15/15 correct avec confiances cohÃ©rentes
```

#### Erreurs Courantes Ã  Ã‰viter

| Erreur | SymptÃ´me | Solution |
|--------|----------|----------|
| Image float64 sans conversion | Couleurs fausses, Breastâ†’Prostate | `image.astype(np.uint8)` |
| `blocks[23]` au lieu de `forward_features()` | CLS std ~0.28, prÃ©dictions alÃ©atoires | Utiliser `forward_features()` |
| Normalisation diffÃ©rente | Confiances incohÃ©rentes | Utiliser `HOPTIMUS_MEAN/STD` |
| Resize diffÃ©rent | Features incompatibles | Utiliser `Resize((224, 224))` |

---

## FonctionnalitÃ©s ImplÃ©mentÃ©es (IHM Clinique)

### Commit 575869a â€” Index Mitotique et TILs Hot/Cold

#### Index Mitotique EstimÃ©
- DÃ©tection des figures Ã©vocatrices de mitoses (Ã©longation + chromatine dense)
- Calcul de l'index pour 10 HPF (High Power Fields)
- XAI: Surbrillance jaune des noyaux mitotiques

#### Statut TILs (Tumor-Infiltrating Lymphocytes)
- Classification: ğŸ”¥ Chaud / â„ï¸ Froid / ğŸš« Exclu / ã€°ï¸ IntermÃ©diaire
- Calcul du ratio de pÃ©nÃ©tration (% TILs dans le massif tumoral)
- Distance au front d'invasion

**Signification clinique:**
- **Tumeur chaude:** Bon pronostic pour immunothÃ©rapie (TILs actifs)
- **Tumeur froide:** ImmunitÃ© bloquÃ©e en pÃ©riphÃ©rie (checkpoint inhibitors moins efficaces)

### Commit 66ba584 â€” IHM Clinique ComplÃ¨te

- Panneau morphomÃ©trique avec mÃ©triques pathologiques
- Gestion des calques (RAW/SEG/HEAT/BOTH)
- XAI: Cliquer sur les alertes pour localiser les noyaux

### Commit 003bba7 â€” Raffinements Expert & Active Learning âœ… NOUVEAU

#### DÃ©tection Mitotique RaffinÃ©e
**ProblÃ¨me initial:** Faux positifs (cellules endothÃ©liales/fibroblastes allongÃ©es mais claires)

**Solution implÃ©mentÃ©e** (recommandation expert pathologiste):
```python
# Avant: logique OR (trop permissive)
if elongation > 1.8 OR circularity < 0.4:
    is_mitotic = True

# AprÃ¨s: logique AND (rÃ©duit 80% des FP)
if elongation > 1.8 AND mean_intensity < 100:  # AllongÃ© ET hyperchromatique
    is_mitotic = True
```

**CritÃ¨res multi-phases:**
| Phase | Ã‰longation | IntensitÃ© | CircularitÃ© |
|-------|------------|-----------|-------------|
| Prophase/MÃ©taphase | >1.5 | <70 | <0.5 |
| Anaphase | >1.8 | <100 | - |
| TÃ©lophase | >2.2 | <120 | - |

#### Convex Hull pour TILs Hot/Cold
**ProblÃ¨me initial:** CentroÃ¯de + rayon = approximation grossiÃ¨re du front tumoral

**Solution implÃ©mentÃ©e:** `scipy.spatial.ConvexHull` pour dÃ©finir prÃ©cisÃ©ment le front

```python
from scipy.spatial import ConvexHull

# Enveloppe convexe des cellules nÃ©oplasiques
hull = ConvexHull(neo_centers)
hull_vertices = neo_centers[hull.vertices]

# Test point-in-polygon pour chaque TIL
def point_in_hull(point, hull_vertices):
    # Cross-product method pour tous les segments
    for i in range(len(hull_vertices)):
        v1, v2 = hull_vertices[i], hull_vertices[(i+1) % n]
        cross = (v2[0]-v1[0])*(point[1]-v1[1]) - (v2[1]-v1[1])*(point[0]-v1[0])
        if cross < 0:
            return False
    return True
```

**Classification TILs:**
| Statut | CritÃ¨re | Emoji |
|--------|---------|-------|
| Chaud | >50% TILs dans le hull | ğŸ”¥ |
| IntermÃ©diaire | 20-50% dans le hull | ã€°ï¸ |
| Froid | >50% TILs Ã  <20Âµm du bord | â„ï¸ |
| Exclu | Distance moyenne >50Âµm | ğŸš« |

#### Active Learning â€” Mode "Seconde Lecture"

**Nouveau module:** `src/feedback/active_learning.py`

**FeedbackCollector** â€” Stockage des corrections expertes:
```python
from src.feedback import FeedbackCollector, FeedbackType

collector = FeedbackCollector(storage_path="data/feedback")

# Corriger un type cellulaire
collector.add_cell_type_correction(
    nucleus_id=42,
    nucleus_location=(100, 150),
    predicted_class="Neoplastic",
    corrected_class="Inflammatory",
    expert_comment="Lymphocyte Ã©vident"
)

# Signaler une fausse mitose
collector.add_mitosis_false_positive(
    nucleus_id=17,
    nucleus_location=(200, 180),
    actual_type="Fibroblast",
    expert_comment="AllongÃ© mais pas hyperchromatique"
)

# Statistiques
stats = collector.get_statistics()
# {'total': 42, 'by_type': {...}, 'by_severity': {...}}

# Export pour retraining
collector.export_for_retraining("data/retraining/batch_001.json")
```

**Types de feedback:**
| Type | SÃ©vÃ©ritÃ© | Description |
|------|----------|-------------|
| `CELL_TYPE_WRONG` | high | Mauvaise classification |
| `MITOSIS_FALSE_POSITIVE` | high | Fausse mitose |
| `MITOSIS_MISSED` | critical | Mitose non dÃ©tectÃ©e |
| `TILS_STATUS_WRONG` | medium | Mauvais hot/cold |
| `ORGAN_WRONG` | high | Mauvais organe |

**Nouvel onglet Gradio:** "ğŸ“ Feedback Expert"
- Formulaire de soumission avec sÃ©vÃ©ritÃ©
- Statistiques en temps rÃ©el
- Sauvegarde JSON automatique

### 2025-12-21 â€” Pipeline d'Ã‰valuation Ground Truth âœ… NOUVEAU

**ImplÃ©mentation complÃ¨te du systÃ¨me d'Ã©valuation contre annotations expertes.**

#### Scripts CrÃ©Ã©s

| Script | RÃ´le | Statut |
|--------|------|--------|
| `scripts/evaluation/download_evaluation_datasets.py` | TÃ©lÃ©charge PanNuke, CoNSeP, MoNuSAC, Lizard | âœ… |
| `scripts/evaluation/convert_annotations.py` | Convertit .mat/.npy â†’ .npz unifiÃ© | âœ… |
| `scripts/evaluation/evaluate_ground_truth.py` | Ã‰value modÃ¨le vs GT | âœ… |
| `scripts/evaluation/README.md` | Documentation complÃ¨te | âœ… |

#### MÃ©triques ImplÃ©mentÃ©es

Utilise le module `src/metrics/ground_truth_metrics.py` (crÃ©Ã© prÃ©cÃ©demment) :

| MÃ©trique | Description | Cible |
|----------|-------------|-------|
| **Dice** | Chevauchement binaire (2Ã—\|Pâˆ©GT\| / (\|P\|+\|GT\|)) | > 0.95 |
| **AJI** | Aggregated Jaccard Index (qualitÃ© instances) | > 0.80 |
| **PQ** | Panoptic Quality = DQ Ã— SQ | > 0.70 |
| **F1d** | F1 par classe (dÃ©tection clinique) | > 0.90 |
| **Confusion Matrix** | Matrice de confusion 6Ã—6 | - |

#### Workflow Complet

```bash
# 1. TÃ©lÃ©charger CoNSeP (rapide, 70 MB)
python scripts/evaluation/download_evaluation_datasets.py --dataset consep

# 2. Convertir au format unifiÃ©
python scripts/evaluation/convert_annotations.py \
    --dataset consep \
    --input_dir data/evaluation/consep/Test \
    --output_dir data/evaluation/consep_converted

# 3. Ã‰valuer le modÃ¨le (prÃ©dictions aveugles)
python scripts/evaluation/evaluate_ground_truth.py \
    --dataset_dir data/evaluation/consep_converted \
    --output_dir results/consep \
    --dataset consep

# 4. Consulter le rapport
cat results/consep/clinical_report_consep_*.txt
```

#### Format de Rapport GÃ©nÃ©rÃ©

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘               RAPPORT DE FIDÃ‰LITÃ‰ CLINIQUE                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Dice Global: 0.9601  |  AJI: 0.8234  |  PQ: 0.7891           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ DÃ‰TECTION                                                    â•‘
â•‘   TP:  180  |  FP:   12  |  FN:    8                        â•‘
â•‘   PrÃ©cision: 93.75%  |  Rappel: 95.74%                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ FIDÃ‰LITÃ‰ PAR TYPE CELLULAIRE                                 â•‘
â•‘   ğŸ”´ Neoplastic  : Expert= 20 â†’ ModÃ¨le= 19 â†’ 95.0%           â•‘
â•‘   ğŸŸ¢ Inflammatory: Expert= 15 â†’ ModÃ¨le= 14 â†’ 93.3%           â•‘
â•‘   ğŸ”µ Connective  : Expert=  8 â†’ ModÃ¨le=  8 â†’ 100.0%          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ CLASSIFICATION ACCURACY: 91.25%                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

#### Datasets SupportÃ©s

| PrioritÃ© | Dataset | Images | Classes | Taille | Statut |
|----------|---------|--------|---------|--------|--------|
| ğŸ¥‡ | PanNuke | 7,901 | 5 + BG | ~1.5 GB | âœ… Script prÃªt |
| ğŸ¥ˆ | CoNSeP | 41 | 7â†’5 (mapping) | ~70 MB | âœ… Script prÃªt |
| ğŸ¥‰ | MoNuSAC | 209 | 4â†’5 (mapping) | ~500 MB | âš ï¸ Placeholder |
| 4 | Lizard | 291 | 5 + BG | ~2 GB | âš ï¸ Placeholder |

#### Mapping des Classes

Le script `convert_annotations.py` gÃ¨re automatiquement le mapping :

**CoNSeP â†’ PanNuke :**
```python
{
    1: 3,  # Other â†’ Connective
    2: 2,  # Inflammatory â†’ Inflammatory
    3: 5,  # Epithelial â†’ Epithelial
    4: 3,  # Spindle-shaped â†’ Connective
}
```

**MoNuSAC â†’ PanNuke :**
```python
{
    1: 5,  # Epithelial â†’ Epithelial
    2: 2,  # Lymphocyte â†’ Inflammatory
    3: 2,  # Neutrophil â†’ Inflammatory
    4: 2,  # Macrophage â†’ Inflammatory
}
```

#### Points de Vigilance

**âš ï¸ Indexation Off-by-One :**
- `inst_map` commence Ã  1, pas 0 (0 = background)
- Toujours utiliser `inst_ids = inst_ids[inst_ids > 0]`

**âš ï¸ Seuil IoU = 0.5 :**
- Norme de la communautÃ© (CoNIC Challenge, MICCAI)
- Ne PAS changer sans raison documentÃ©e

**âš ï¸ Resize Predictions :**
- Les prÃ©dictions sont Ã  224Ã—224 (H-optimus-0)
- Le GT peut Ãªtre Ã  256Ã—256 (PanNuke) ou variable (CoNSeP)
- Le script gÃ¨re automatiquement le resize avec `INTER_NEAREST`

#### Fichiers de Sortie

| Fichier | Format | Contenu |
|---------|--------|---------|
| `clinical_report_*.txt` | Text | Rapport formatÃ© pour pathologistes |
| `metrics_*.json` | JSON | MÃ©triques dÃ©taillÃ©es + per-class |
| `confusion_matrix_*.npy` | NumPy | Matrice 6Ã—6 (GT Ã— Pred) |

#### Commandes Utiles

```bash
# Afficher info sur datasets disponibles
python scripts/evaluation/download_evaluation_datasets.py --info

# VÃ©rifier une conversion
python scripts/evaluation/convert_annotations.py \
    --verify data/evaluation/consep_converted/test_001.npz

# Ã‰valuer une seule image (debug)
python scripts/evaluation/evaluate_ground_truth.py \
    --image data/evaluation/consep_converted/test_001.npz \
    --output_dir results/single \
    --verbose

# Ã‰valuer 100 images de PanNuke Fold 2
python scripts/evaluation/evaluate_ground_truth.py \
    --dataset_dir data/evaluation/pannuke_fold2_converted \
    --num_samples 100 \
    --output_dir results/pannuke_sample
```

#### Prochaines Ã‰tapes

- [ ] Tester sur CoNSeP (41 images, validation rapide)
- [ ] Tester sur PanNuke Fold 2 (non utilisÃ© pour entraÃ®nement)
- [ ] GÃ©nÃ©rer rapport de rÃ©fÃ©rence pour publication
- [ ] IntÃ©grer dans l'IHM (onglet "Ã‰valuation GT")

**RÃ©fÃ©rence :** Voir `docs/PLAN_EVALUATION_GROUND_TRUTH.md` pour spÃ©cifications complÃ¨tes.

### 2025-12-22 â€” Phase 1 Refactorisation: Centralisation du Code âœ… COMPLET

**ProblÃ¨me identifiÃ©:** Code dupliquÃ© dans 15+ fichiers causant des risques de bugs et incohÃ©rences.

**Audit complet rÃ©vÃ¨le:**
- **22 constantes dupliquÃ©es** (`HOPTIMUS_MEAN`, `HOPTIMUS_STD`) dans 11 fichiers
- **11 fonctions dupliquÃ©es** (`create_hoptimus_transform()`, chargement modÃ¨le) dans 9 fichiers
- Risque Ã©levÃ© de drift entre entraÃ®nement et infÃ©rence

**Solution implÃ©mentÃ©e:** CrÃ©ation de modules centralisÃ©s

#### Modules CentralisÃ©s CrÃ©Ã©s

**1. `src/preprocessing/__init__.py`**
```python
# Constantes normalization (source unique de vÃ©ritÃ©)
HOPTIMUS_MEAN = (0.707223, 0.578729, 0.703617)
HOPTIMUS_STD = (0.211883, 0.230117, 0.177517)

# Transform canonique
def create_hoptimus_transform() -> transforms.Compose:
    """Transform IDENTIQUE entraÃ®nement/infÃ©rence."""

# Preprocessing unifiÃ©
def preprocess_image(image: np.ndarray, device: str = "cuda") -> torch.Tensor:
    """Conversion uint8 + transform + validation."""

# Validation automatique
def validate_features(features: torch.Tensor) -> dict:
    """DÃ©tecte bugs LayerNorm (CLS std 0.70-0.90)."""
```

**2. `src/models/loader.py`**
```python
class ModelLoader:
    @staticmethod
    def load_hoptimus0(device: str = "cuda") -> torch.nn.Module:
        """
        Chargement H-optimus-0 avec:
        - Freeze automatique
        - Gestion erreurs HuggingFace
        - forward_features() garanti (pas blocks[X])
        """
```

#### Fichiers RefactorisÃ©s (9/11)

| # | Fichier | Lignes Ã©liminÃ©es | Commit |
|---|---------|------------------|--------|
| 1 | `src/inference/optimus_gate_inference.py` | 32 | Part 3/3 |
| 2 | `src/inference/optimus_gate_inference_multifamily.py` | 33 | Part 3/3 |
| 3 | `scripts/preprocessing/extract_features.py` | 30 | Part 4 |
| 4 | `scripts/preprocessing/extract_fold_features.py` | 43 | Part 4 |
| 5 | `scripts/validation/verify_features.py` | 20 | Part 5 |
| 6 | `scripts/validation/diagnose_organ_prediction.py` | 15 | Part 5 |
| 7 | `scripts/validation/test_organ_prediction_batch.py` | 20 | Part 5 |
| 8 | `scripts/evaluation/compare_train_vs_inference.py` | 13 | Part 5 |
| 9 | `scripts/demo/gradio_demo.py` | 2 | Part 6/6 |

**Fichiers vÃ©rifiÃ©s sans duplication (2/11):**
- `prepare_family_data.py` (travaille avec features prÃ©-extraites)
- Scripts de test uniquement

#### Impact Mesurable

- **~208 lignes** de code dupliquÃ© Ã©liminÃ©es
- **6 commits** systÃ©matiques avec messages descriptifs
- **0 erreur** durant le processus
- **100% couverture** des fichiers d'infÃ©rence et preprocessing critiques

#### BÃ©nÃ©fices Obtenus

âœ… **Single Source of Truth**
- Constantes: 1 fichier au lieu de 11
- Transform: 1 fonction au lieu de 9
- Chargement modÃ¨le: 1 classe au lieu de patterns Ã©parpillÃ©s

âœ… **DÃ©tection Automatique de Bugs**
- `validate_features()` intÃ©grÃ© dans tous les scripts d'infÃ©rence
- DÃ©tecte Bug #1 (ToPILImage float64) et Bug #2 (LayerNorm mismatch)
- CLS std hors range [0.70-0.90] â†’ erreur explicite

âœ… **CohÃ©rence Garantie**
- EntraÃ®nement et infÃ©rence utilisent le mÃªme preprocessing
- Impossible d'avoir des divergences de normalisation
- Changements futurs propagÃ©s automatiquement

âœ… **MaintenabilitÃ©**
- Modification de `HOPTIMUS_MEAN/STD` en 1 seul endroit
- AmÃ©lioration du transform propagÃ©e Ã  tous les scripts
- Code plus lisible (imports au lieu de duplications)

#### Pattern de Refactorisation AppliquÃ©

```python
# AVANT (dupliquÃ© dans chaque fichier)
HOPTIMUS_MEAN = (0.707223, 0.578729, 0.703617)
HOPTIMUS_STD = (0.211883, 0.230117, 0.177517)

def create_hoptimus_transform():
    return transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=HOPTIMUS_MEAN, std=HOPTIMUS_STD),
    ])

backbone = timm.create_model(
    "hf-hub:bioptimus/H-optimus-0",
    pretrained=True,
    init_values=1e-5,
    dynamic_img_size=False
)
for param in backbone.parameters():
    param.requires_grad = False

# APRÃˆS (import centralisÃ©)
from src.preprocessing import create_hoptimus_transform, preprocess_image, validate_features
from src.models.loader import ModelLoader

transform = create_hoptimus_transform()
tensor = preprocess_image(image, device="cuda")
backbone = ModelLoader.load_hoptimus0(device="cuda")
features = backbone.forward_features(tensor)
validate_features(features)  # DÃ©tection automatique des bugs
```

#### Commits DÃ©taillÃ©s

```bash
dec7f89 Phase 1 (Part 6/6): Refactor gradio_demo.py to use centralized constants
a6079f0 Phase 1 (Part 5): Refactor validation and evaluation scripts
cf78194 Phase 1 (Part 4): Refactor preprocessing scripts
b6e4512 Phase 1 (Part 3/3): Refactor optimus_gate_inference.py and optimus_gate_inference_multifamily.py
21937bc Phase 1 (Part 2/3): Refactor hoptimus_hovernet and hoptimus_unetr
f2d7c3a Phase 1 (Part 1/3): Create centralized preprocessing and model loading modules
```

#### Tests de Non-RÃ©gression

```bash
# VÃ©rifier preprocessing
python scripts/validation/verify_features.py --features_dir data/cache/pannuke_features
# âœ… CLS std: 0.768 Â± 0.005 (dans [0.70-0.90])

# Tester infÃ©rence
python scripts/validation/test_organ_prediction_batch.py --samples_dir data/samples
# âœ… 15/15 correct, confiances cohÃ©rentes

# Lancer tests unitaires
pytest tests/unit/test_preprocessing.py -v
# âœ… 12/12 passed
```

#### LeÃ§ons Apprises

**Pourquoi la duplication Ã©tait dangereuse:**
1. **Bug #1 (2025-12-20):** ToPILImage avec float64 causait overflow couleurs â†’ features corrompues
2. **Bug #2 (2025-12-21):** Mismatch `blocks[23]` vs `forward_features()` â†’ CLS std 0.28 vs 0.77
3. Ces bugs se sont propagÃ©s Ã  travers 11 fichiers dupliquÃ©s â†’ semaines de travail perdues

**Comment la centralisation protÃ¨ge:**
- Fix en 1 endroit â†’ propagation automatique
- Validation intÃ©grÃ©e dÃ©tecte les rÃ©gressions
- Code review plus facile (1 module vs 11 fichiers)

#### Recommandations Futures

âœ… **AdoptÃ©:**
- Toujours importer de `src.preprocessing` au lieu de redÃ©finir
- Utiliser `ModelLoader.load_hoptimus0()` pour chargement uniforme
- Appeler `validate_features()` aprÃ¨s extraction

âš ï¸ **Ã€ surveiller:**
- Ne JAMAIS redÃ©finir `HOPTIMUS_MEAN/STD` localement
- Ne JAMAIS crÃ©er de transform custom sans raison documentÃ©e
- VÃ©rifier que les nouveaux scripts utilisent les modules centralisÃ©s

**Statut:** âœ… Phase 1 archivÃ©e et prÃªte pour production
