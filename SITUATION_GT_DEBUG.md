# ğŸš¨ Situation Debug Ground Truth â€” Ã‰TAT DES LIEUX

**Date**: 2025-12-21 (suite)
**Statut**: ğŸ”§ Debugging en cours â€” Fix diagnostic script appliquÃ©
**PrioritÃ©**: **BLOQUANT** pour dÃ©ploiement

---

## âœ… Ce qui est FAIT

### 1. EntraÃ®nement Complet (5/5 familles)

| Famille | Samples | NP Dice | HV MSE | NT Acc | Statut |
|---------|---------|---------|--------|--------|--------|
| **Glandular** | 3391 | **0.9641** | **0.0105** | **0.9107** | âœ… |
| **Digestive** | 2430 | **0.9636** | **0.0116** | **0.8784** | âœ… |
| **Urologic** | 1101 | **0.9311** | **0.0230** | **0.9064** | âœ… ğŸ |
| **Respiratory** | 408 | **0.9339** | **0.0565** | **0.8894** | âœ… |
| **Epidermal** | 571 | **0.9533** | **0.2620** | **0.8753** | âœ… |

**Tous les critÃ¨res POC atteints** :
- NP Dice â‰¥ 0.93 âœ…
- NT Acc â‰¥ 0.85 âœ…
- HV MSE < 0.1 pour familles >2000 samples âœ…

### 2. Scripts d'Ã‰valuation GT

| Script | RÃ´le | Statut |
|--------|------|--------|
| `scripts/evaluation/convert_annotations.py` | Convertir PanNuke â†’ .npz | âœ… |
| `scripts/evaluation/evaluate_ground_truth.py` | Ã‰valuer Dice/AJI/PQ | âœ… |
| `scripts/evaluation/quick_test_fixed.sh` | Test rapide (5 samples) | âœ… |
| `scripts/evaluation/test_fixed_models_ground_truth.sh` | Test complet (50 samples) | âœ… |
| `scripts/evaluation/diagnose_gt_failure.py` | Diagnostic visuel | âœ… **FIX APPLIQUÃ‰** |
| `scripts/evaluation/test_watershed_params.py` | Test seuils watershed | âœ… |

### 3. Fixes AppliquÃ©s au Diagnostic Script

**Commit**: `Fix diagnose_gt_failure.py - handle different result key names`

**Changements** :
```python
# Debug: afficher les clÃ©s disponibles
print(f"ğŸ” ClÃ©s dans result: {list(result.keys())}")

# Support multiple key names
pred_inst = result.get('instance_map', result.get('inst_map', np.zeros_like(gt_inst)))
pred_type = result.get('type_map', result.get('nt_map', np.zeros_like(gt_type)))
pred_np = result.get('np_prob', result.get('np_mask', np.zeros_like(pred_inst, dtype=np.float32)))
pred_hv = result.get('hv_map', result.get('hv', np.zeros((2, *gt_inst.shape), dtype=np.float32)))
```

---

## ğŸš¨ PROBLÃˆME CRITIQUE DÃ©tectÃ©

### RÃ©sultats Test Rapide (5 Ã©chantillons)

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              RÃ‰SULTATS GROUND TRUTH - CATASTROPHE             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Dice Global: 0.8866  |  AJI: 0.3091  |  PQ: 0.1623            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ DÃ‰TECTION                                                     â•‘
â•‘   TP:   5  |  FP:  30  |  FN:   9                            â•‘
â•‘   PrÃ©cision: 14.29%  |  Rappel: 35.71%                       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ TYPE CELLULAIRE (Exemple le plus flagrant)                   â•‘
â•‘   Epithelial: Expert=9 â†’ ModÃ¨le=31 (3.4x sur-dÃ©tection!)     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Observation critique** :
- **30 faux positifs** vs **5 vrais positifs** â†’ 6x plus de FP que de TP !
- Le modÃ¨le crÃ©e **trop d'instances** (sur-segmentation massive)
- Dice reste acceptable (0.8866) car il mesure le chevauchement binaire
- Mais **AJI 0.31** (cible 0.80) et **PQ 0.16** (cible 0.70) = CATASTROPHE

### Disconnect Train vs Ground Truth

| Phase | NP Dice | HV MSE | NT Acc | Statut |
|-------|---------|--------|--------|--------|
| **Training (Glandular)** | 0.9641 | 0.0105 | 0.9107 | âœ… Excellent |
| **Validation (10 samples)** | 0.9655 | 0.0266 | 0.9517 | âœ… Excellent |
| **Ground Truth (5 samples)** | 0.8866 | ? | ? | âŒ Catastrophe |

**Pourquoi ce disconnect ?**

1. **Training/Validation** : Compare prÃ©dictions vs targets gÃ©nÃ©rÃ©s par `prepare_family_data_FIXED.py`
2. **Ground Truth** : Compare prÃ©dictions vs annotations **expertes PanNuke originales**

**â†’ Si `compute_hv_maps()` ou post-processing watershed sont incorrects**, les mÃ©triques train/val peuvent Ãªtre bonnes (le modÃ¨le apprend correctement les targets), mais les prÃ©dictions ne matchent pas les annotations expertes.

---

## ğŸ”¬ HypothÃ¨ses (Par Ordre de ProbabilitÃ©)

### 1. ğŸ¯ Watershed Post-Processing DÃ©faillant (90% probable)

**SymptÃ´mes** :
- FP = 30 (6x plus que TP)
- Sur-dÃ©tection massive Epithelial (9 â†’ 31)

**Cause probable** : Seuils watershed **trop permissifs** crÃ©ent trop de seeds.

**ParamÃ¨tres actuels** (`src/inference/hoptimus_hovernet.py:211-216`) :
```python
markers[edge > 0.3] = 0  # Supprimer bords (gradient HV)
markers = (markers > 0.7).astype(np.uint8)  # Seuil NP prob
markers = ndimage.label(markers * (dist > 2))[0]  # Distance seeds
```

**ProblÃ¨mes potentiels** :
- `edge > 0.3` : **Trop permissif** ? (devrait Ãªtre 0.5-0.7 pour frontiÃ¨res nettes)
- `dist > 2` : **Distance minimale trop faible** â†’ Trop de seeds crÃ©Ã©s
- RÃ©sultat : Chaque petit pic de probabilitÃ© NP crÃ©e une instance

**Test disponible** : `scripts/evaluation/test_watershed_params.py`

### 2. ğŸ§ª compute_hv_maps() Incorrect (50% probable)

**Cause possible** : Les targets HV pendant l'entraÃ®nement ne correspondent pas aux vraies frontiÃ¨res d'instances.

**Ã€ vÃ©rifier** :
- Est-ce que `compute_hv_maps()` utilise les **vrais IDs d'instances** de PanNuke ?
- Ou est-ce qu'on recalcule avec `connectedComponents` qui fusionne les cellules qui se touchent ?

**Code Ã  inspecter** (`scripts/preprocessing/prepare_family_data_FIXED.py`) :
```python
# Si on fait Ã§a, c'est FAUX:
_, labels = cv2.connectedComponents(binary_mask)  # Fusionne cellules touchantes
hv_targets = compute_hv_maps(labels)  # HV maps avec instances FUSIONNÃ‰ES

# Il faut faire Ã§a:
inst_map = extract_true_instance_ids_from_pannuke(mask)  # IDs rÃ©els
hv_targets = compute_hv_maps(inst_map)  # HV maps avec vraies frontiÃ¨res
```

### 3. ğŸ“ RÃ©solution Mismatch (30% probable)

**SymptÃ´me** : Resize 224â†’256 pendant l'Ã©valuation

**Cause possible** : L'interpolation bilinÃ©aire floute les gradients HV prÃ©cis

**Test** :
- Ã‰valuer directement Ã  224Ã—224 (sans resize)
- Ou utiliser INTER_NEAREST pour prÃ©server les gradients

---

## â­ï¸ PROCHAINES Ã‰TAPES (Ordre d'ExÃ©cution)

### Ã‰TAPE 1 : Diagnostic Visuel (URGENT - 5 min)

**Commandes** :
```bash
# 1. Pull le fix
git pull origin claude/evaluation-ground-truth-zJB9O

# 2. Lancer diagnostic sur une image
bash scripts/evaluation/quick_test_fixed.sh

# 3. RÃ©cupÃ©rer le premier .npz crÃ©Ã©
FIRST_NPZ=$(find data/evaluation/pannuke_fold2_converted -name "*.npz" | head -1)
echo "Premier fichier: $FIRST_NPZ"

# 4. Lancer diagnostic visuel
python scripts/evaluation/diagnose_gt_failure.py \
    --npz_file "$FIRST_NPZ" \
    --checkpoint_dir models/checkpoints_FIXED \
    --output_dir results/diagnostic_gt

# 5. Examiner l'image gÃ©nÃ©rÃ©e
ls -lh results/diagnostic_gt/diagnostic_*.png
```

**Sortie attendue** :
```
ğŸ” ClÃ©s dans result: ['instance_map', 'type_map', 'np_prob', 'hv_map', ...]

PrÃ©dictions:
  Instances: 31
  Types: [1 2 5]
  HV range: [-0.987, 0.991]

âœ… Diagnostic saved: results/diagnostic_gt/diagnostic_*.png
```

**Analyser visuellement** :
- Les gradients HV sont-ils suffisamment forts ?
- Y a-t-il trop de seeds de watershed ?
- Les instances GT sont-elles correctes ?

### Ã‰TAPE 2 : Test Watershed Thresholds (30 min)

**SI** le diagnostic visuel montre trop de seeds/instances :

```bash
python scripts/evaluation/test_watershed_params.py \
    --npz_file "$FIRST_NPZ" \
    --checkpoint_dir models/checkpoints_FIXED \
    --output_dir results/watershed_sweep

# Examiner les heatmaps
ls -lh results/watershed_sweep/*.png
cat results/watershed_sweep/*.json
```

**Objectif** : Trouver meilleure combinaison (edge_threshold, dist_threshold) qui :
- RÃ©duit FP (actuellement 30)
- AmÃ©liore Rappel (actuellement 35%)
- Augmente AJI (actuellement 0.31 â†’ cible 0.70+)

### Ã‰TAPE 3 : VÃ©rifier compute_hv_maps() (1h)

**SI** watershed ne suffit pas :

```bash
# Inspecter le script de prÃ©paration
cat scripts/preprocessing/prepare_family_data_FIXED.py | grep -A 20 "connectedComponents"

# Comparer avec masks PanNuke originaux
python -c "
import numpy as np
data = np.load('/home/amar/data/PanNuke/fold2/masks.npy')
print(f'Mask shape: {data.shape}')
print(f'Channels: {data.shape[-1]}')  # Devrait Ãªtre 6 (BG + 5 classes)
"
```

**VÃ©rifier** :
- Si on utilise les vrais IDs d'instances (canaux 1-5 de PanNuke)
- Ou si `connectedComponents` fusionne les cellules qui se touchent

**Si bug trouvÃ©** : RÃ©-entraÃ®nement complet requis (~10h)

### Ã‰TAPE 4 : Test Sans Resize (15 min)

```bash
# Modifier evaluate_ground_truth.py pour Ã©valuer Ã  224Ã—224
# Comparer mÃ©triques
```

---

## ğŸ“Š CritÃ¨res de SuccÃ¨s (Post-Fix)

| MÃ©trique | Actuel | Cible GO | Cible EXCELLENT |
|----------|--------|----------|-----------------|
| **Dice** | 0.8866 | > 0.93 | > 0.95 |
| **AJI** | 0.3091 | > 0.70 | > 0.75 |
| **PQ** | 0.1623 | > 0.60 | > 0.65 |
| **PrÃ©cision** | 14.29% | > 70% | > 85% |
| **Rappel** | 35.71% | > 70% | > 85% |

---

## âš™ï¸ Impact sur le Projet

### Si Watershed Fix Suffit : ~30 min
- Ajuster seuils dans `hoptimus_hovernet.py`
- Re-tester GT
- DÃ©ployer si OK

### Si compute_hv_maps() Bug : ~10h
- Corriger preprocessing
- RÃ©-entraÃ®ner 5 familles
- Re-tester GT

### Si ProblÃ¨me Fondamental Architecture : ~1 semaine
- Revoir HoVer-Net decoder
- RÃ©-entraÃ®ner
- Valider

---

## ğŸ“ Fichiers ClÃ©s pour Debug

| Fichier | RÃ´le |
|---------|------|
| `src/inference/hoptimus_hovernet.py` | Post-processing watershed (lignes 211-216) |
| `scripts/preprocessing/prepare_family_data_FIXED.py` | GÃ©nÃ©ration targets HV |
| `scripts/evaluation/diagnose_gt_failure.py` | Diagnostic visuel âœ… FIX APPLIQUÃ‰ |
| `scripts/evaluation/test_watershed_params.py` | Test seuils watershed |
| `DIAGNOSTIC_GT_FAILURE.md` | Plan d'investigation complet |

---

**CrÃ©Ã© le** : 2025-12-21
**Par** : Claude (Debug Ground Truth)
**Statut** : ğŸ”§ FIX APPLIQUÃ‰ - Attente diagnostic visuel
**Action immÃ©diate** : Pull + Lancer `diagnose_gt_failure.py`
