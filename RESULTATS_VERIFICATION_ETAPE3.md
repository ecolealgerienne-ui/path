# RÃ©sultats VÃ©rification - Ã‰tape 3

**Date** : 2025-12-23
**Objectif** : Comparer architecture et loss functions (HoVer-Net vs Notre systÃ¨me)

---

## ğŸ—ï¸ PARTIE 1 : Comparaison Architecture

### HoVer-Net Original

**Fichier** : `/tmp/hover_net/models/hovernet/net_desc.py`

```
INPUT (256Ã—256 ou 270Ã—270 RGB)
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ENCODER (ResNet-50 Preact)         â”‚
â”‚  â€¢ conv0: 7Ã—7 conv + BN + ReLU      â”‚
â”‚  â€¢ d0: ResBlock 64  â†’ 256  (Ã—3)     â”‚
â”‚  â€¢ d1: ResBlock 256 â†’ 512  (Ã—4)     â”‚
â”‚  â€¢ d2: ResBlock 512 â†’ 1024 (Ã—6)     â”‚
â”‚  â€¢ d3: ResBlock 1024â†’ 2048 (Ã—3)     â”‚
â”‚  â€¢ conv_bot: 1Ã—1 conv 2048â†’1024     â”‚
â”‚                                     â”‚
â”‚  ParamÃ¨tres : ~25M                  â”‚
â”‚  PrÃ©-entraÃ®nÃ© : ImageNet            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DECODER (3 branches parallÃ¨les)    â”‚
â”‚                                     â”‚
â”‚  Pour chaque branche (NP, HV, TP):  â”‚
â”‚  â€¢ u3: Conv + DenseBlock + Conv     â”‚
â”‚  â€¢ u2: Conv + DenseBlock + Conv     â”‚
â”‚  â€¢ u1: Conv (padded)                â”‚
â”‚  â€¢ u0: BN + ReLU + Conv 1Ã—1         â”‚
â”‚                                     â”‚
â”‚  Skip connections: d3+u3, d2+u2, etcâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
OUTPUT (80Ã—80 ou 164Ã—164)
  â€¢ NP: 2 channels (background, nuclei)
  â€¢ HV: 2 channels (horizontal, vertical)
  â€¢ TP: n_types channels (si classification)
```

### Notre SystÃ¨me (OptimusGate)

**Fichier** : `/home/user/path/src/models/hovernet_decoder.py`

```
INPUT (224Ã—224 RGB)
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  H-OPTIMUS-0 (gelÃ©)                 â”‚
â”‚  â€¢ ViT-Giant/14                     â”‚
â”‚  â€¢ 1.1 milliard paramÃ¨tres          â”‚
â”‚  â€¢ PrÃ©-entraÃ®nÃ©: 500k+ lames H&E    â”‚
â”‚                                     â”‚
â”‚  Output: (B, 261, 1536)             â”‚
â”‚    - 1 CLS token                    â”‚
â”‚    - 256 patch tokens (16Ã—16)       â”‚
â”‚    - 4 register tokens              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HOVERNET DECODER                   â”‚
â”‚                                     â”‚
â”‚  Bottleneck (Ã©conomie VRAM):        â”‚
â”‚  â€¢ 1Ã—1 conv: 1536 â†’ 256             â”‚
â”‚  â€¢ Reshape tokens â†’ spatial (16Ã—16) â”‚
â”‚                                     â”‚
â”‚  Tronc commun (upsampling):         â”‚
â”‚  â€¢ up1: 16â†’32  (256â†’128)            â”‚
â”‚  â€¢ up2: 32â†’64  (128â†’64)             â”‚
â”‚  â€¢ up3: 64â†’128 (64â†’64)              â”‚
â”‚  â€¢ up4: 128â†’224 (64â†’64)             â”‚
â”‚                                     â”‚
â”‚  TÃªtes spÃ©cialisÃ©es (lÃ©gÃ¨res):      â”‚
â”‚  â€¢ NP: Convâ†’Conv 64â†’2               â”‚
â”‚  â€¢ HV: Convâ†’Conv 64â†’2 + Tanh        â”‚
â”‚  â€¢ NT: Convâ†’Conv 64â†’5               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
OUTPUT (224Ã—224)
  â€¢ NP: 2 channels
  â€¢ HV: 2 channels (avec Tanh [-1, 1])
  â€¢ NT: 5 channels
```

### DiffÃ©rences Architecturales

| Aspect | HoVer-Net Original | Notre SystÃ¨me |
|--------|-------------------|---------------|
| **Backbone** | ResNet-50 (25M params) | H-optimus-0 (1.1B params) |
| **PrÃ©-entraÃ®nement** | ImageNet (photos naturelles) | 500k+ lames H&E (domaine spÃ©cifique) |
| **Features** | 2048-dim (spatial) | 1536-dim (tokens) |
| **DÃ©codeur** | DenseBlocks + skip connections | UpsampleBlocks simples |
| **Bottleneck** | âŒ Non (2048 direct) | âœ… Oui (1536â†’256, Ã©conomie VRAM) |
| **Skip connections** | âœ… Oui (encoderâ†’decoder) | âŒ Non (backbone gelÃ©) |
| **Input size** | 256Ã—256 ou 270Ã—270 | 224Ã—224 (fixe H-optimus-0) |
| **Output size** | 164Ã—164 ou 80Ã—80 | 224Ã—224 |
| **Activation HV** | âŒ Non (outputs directs) | âœ… Tanh (force [-1, 1]) |

**Impact thÃ©orique** :
- âœ… **Avantage** : Backbone 44Ã— plus gros, prÃ©-entraÃ®nÃ© sur domaine
- âš ï¸ **InconvÃ©nient** : Pas de skip connections (backbone gelÃ©)
- âš ï¸ **InconvÃ©nient** : DÃ©codeur plus simple (pas de DenseBlocks)

---

## âš–ï¸ PARTIE 2 : Comparaison Loss Functions

### HoVer-Net Original

**Fichier** : `/tmp/hover_net/models/hovernet/utils.py`

**Configuration** (`opt.py` lignes 47-51):
```python
"loss": {
    "np": {"bce": 1, "dice": 1},
    "hv": {"mse": 1, "msge": 1},  # â† MSE + MSGE
    "tp": {"bce": 1, "dice": 1},
},
```

**ImplÃ©mentation Loss HV:**

#### 1. MSE Loss (lignes 87-102)
```python
def mse_loss(true, pred):
    """Mean squared error."""
    loss = pred - true
    loss = (loss * loss).mean()
    return loss
```

**CaractÃ©ristiques** :
- MSE simple **NON MASQUÃ‰**
- CalculÃ© sur **TOUS les pixels** (background + noyaux)
- Sensible aux outliers (pÃ©nalitÃ© quadratique)

#### 2. MSGE Loss (lignes 106-172)
```python
def msge_loss(true, pred, focus):
    """Mean squared error of gradients."""
    # Sobel 5Ã—5 kernel
    kernel_h, kernel_v = get_sobel_kernel(5)

    # Calcul gradients
    true_grad = get_gradient_hv(true)  # Sobel sur H et V
    pred_grad = get_gradient_hv(pred)

    # MSE sur gradients MASQUÃ‰ par focus (noyaux uniquement)
    loss = pred_grad - true_grad
    loss = focus * (loss * loss)
    loss = loss.sum() / (focus.sum() + 1e-8)
    return loss
```

**CaractÃ©ristiques** :
- **Sobel 5Ã—5** pour calculer gradients (smoothing + dÃ©rivÃ©e)
- MSE sur gradients **MASQUÃ‰** (noyaux uniquement via `focus`)
- Normalisation par nombre de pixels de noyaux

### Notre SystÃ¨me

**Fichier** : `/home/user/path/src/models/hovernet_decoder.py`

**Configuration** (lignes 206-208):
```python
lambda_np = 1.0
lambda_hv = 2.0  # â† PondÃ©ration 2Ã— pour HV
lambda_nt = 1.0
```

**ImplÃ©mentation Loss HV:**

#### 1. SmoothL1Loss MASQUÃ‰ (lignes 299-313)
```python
# CrÃ©er masque des noyaux
mask = np_target.float().unsqueeze(1)  # (B, 1, H, W)

# Masquer pred et target
hv_pred_masked = hv_pred * mask
hv_target_masked = hv_target * mask

# SmoothL1 sur versions masquÃ©es
hv_l1_sum = F.smooth_l1_loss(hv_pred_masked, hv_target_masked, reduction='sum')
hv_l1 = hv_l1_sum / (mask.sum() * 2)  # Normaliser par nb pixels noyaux
```

**CaractÃ©ristiques** :
- **SmoothL1Loss** (Huber) : moins sensible aux outliers que MSE
- **MASQUÃ‰** (noyaux uniquement)
- Normalisation par nombre de pixels de noyaux

#### 2. Gradient Loss (lignes 244-277)
```python
def gradient_loss(self, pred, target, mask=None):
    """SmoothL1 sur gradients par diffÃ©rences finies."""
    # Gradient horizontal (diffÃ©rences finies)
    pred_h = pred[:, :, :, 1:] - pred[:, :, :, :-1]
    target_h = target[:, :, :, 1:] - target[:, :, :, :-1]

    # Gradient vertical
    pred_v = pred[:, :, 1:, :] - pred[:, :, :-1, :]
    target_v = target[:, :, 1:, :] - target[:, :, :-1, :]

    if mask is not None:
        # Masquer gradients
        mask_h = mask[:, :, :, 1:]
        mask_v = mask[:, :, 1:, :]

        grad_loss_h = F.smooth_l1_loss(pred_h * mask_h, target_h * mask_h, reduction='sum')
        grad_loss_v = F.smooth_l1_loss(pred_v * mask_v, target_v * mask_v, reduction='sum')

        grad_loss = (grad_loss_h + grad_loss_v) / (mask_h.sum() + mask_v.sum() + 1e-8)
        return grad_loss
```

**CaractÃ©ristiques** :
- **DiffÃ©rences finies** (pas Sobel) pour gradients
- **SmoothL1Loss** au lieu de MSE
- **MASQUÃ‰** (noyaux uniquement)

#### 3. Loss Totale HV (ligne 319)
```python
hv_loss = hv_l1 + 0.5 * hv_gradient  # Poids 0.5Ã— pour gradient
```

---

## âŒ DIFFÃ‰RENCES CRITIQUES IDENTIFIÃ‰ES

### DiffÃ©rence #1 : MSE vs SmoothL1Loss

| MÃ©trique | HoVer-Net (MSE) | Notre SystÃ¨me (SmoothL1) |
|----------|-----------------|--------------------------|
| **Formule** | `(pred - true)Â²` | `0.5*(pred - true)Â² si |diff|<1, sinon |diff|-0.5` |
| **SensibilitÃ© outliers** | Haute (pÃ©nalitÃ© quadratique) | Basse (pÃ©nalitÃ© linÃ©aire pour |diff|>1) |
| **Convergence** | Plus rapide sur donnÃ©es propres | Plus stable sur donnÃ©es bruitÃ©es |

**Impact thÃ©orique** :
- âš ï¸ SmoothL1Loss peut produire des **gradients plus faibles** que MSE
- âš ï¸ Sur donnÃ©es histopathologiques (parfois bruitÃ©es), SmoothL1 peut Ãªtre **trop conservatif**

**Test requis** :
```python
# Comparer sur un batch
batch_mse = F.mse_loss(hv_pred, hv_target)
batch_smooth_l1 = F.smooth_l1_loss(hv_pred, hv_target)
print(f"Ratio: {batch_smooth_l1 / batch_mse:.3f}")
```

### DiffÃ©rence #2 : Sobel 5Ã—5 vs DiffÃ©rences Finies

| MÃ©trique | HoVer-Net (Sobel 5Ã—5) | Notre SystÃ¨me (DiffÃ©rences Finies) |
|----------|----------------------|-----------------------------------|
| **Noyau** | 5Ã—5 avec smoothing | 1Ã—2 (horizontal), 2Ã—1 (vertical) |
| **Effet** | Lisse + dÃ©rive | DÃ©rive brute (sensible au bruit) |
| **DÃ©tection frontiÃ¨res** | Robuste | PrÃ©cise mais bruitÃ©e |

**Impact thÃ©orique** :
- âš ï¸ DiffÃ©rences finies sont **plus sensibles au bruit** que Sobel
- âš ï¸ Sobel dÃ©tecte mieux les **frontiÃ¨res nettes** (smoothing intÃ©grÃ©)

### DiffÃ©rence #3 : Masquage

| Aspect | HoVer-Net | Notre SystÃ¨me |
|--------|-----------|---------------|
| **MSE/SmoothL1 masquÃ© ?** | âŒ Non (MSE sur tous pixels) | âœ… Oui (masque noyaux) |
| **MSGE/Gradient masquÃ© ?** | âœ… Oui (via `focus`) | âœ… Oui (via `mask`) |

**Impact** :
- âœ… **Avantage nous** : MSE masquÃ© Ã©vite que background (70-80% pixels) domine la loss
- âŒ **Bug potentiel HoVer-Net** : MSE non masquÃ© pourrait pousser le modÃ¨le vers HV=0 partout

**âš ï¸ ATTENTION** : Le code HoVer-Net montre MSE **NON masquÃ©** (ligne 101 de utils.py). Cela semble Ãªtre un **bug** ou une version diffÃ©rente. Ã€ vÃ©rifier dans leur README/paper.

---

## ğŸ“Š TABLEAU RÃ‰CAPITULATIF

| Composant | HoVer-Net Original | Notre SystÃ¨me | Conforme ? |
|-----------|-------------------|---------------|------------|
| **Backbone** | ResNet-50 (25M) | H-optimus-0 (1.1B) | âŒ DiffÃ©rent (mais meilleur) |
| **PrÃ©-entraÃ®nement** | ImageNet | 500k+ H&E | âŒ DiffÃ©rent (mais meilleur) |
| **Skip connections** | âœ… Oui | âŒ Non | âŒ |
| **DÃ©codeur** | DenseBlocks | UpsampleBlocks | âŒ Plus simple |
| **NP Loss** | BCE + Dice | BCE + Dice | âœ… Identique |
| **HV Loss (base)** | MSE | SmoothL1Loss | âŒ **DIFFÃ‰RENT** |
| **HV Loss (gradient)** | MSGE (Sobel 5Ã—5) | Gradient Loss (Diff finies) | âŒ **DIFFÃ‰RENT** |
| **HV Masquage** | âŒ MSE non masquÃ© | âœ… SmoothL1 masquÃ© | âœ… Meilleur |
| **NT Loss** | BCE + Dice | CrossEntropy | âš ï¸ Similaire |
| **Activation HV** | âŒ Non | âœ… Tanh | âœ… Meilleur (force [-1, 1]) |

---

## ğŸ¯ HYPOTHÃˆSES SUR AJI 0.0863

### HypothÃ¨se #1 : DonnÃ©es OLD (connectedComponents) â† **PRINCIPALE**

**Preuve Ã‰tape 2** : HoVer-Net utilise instances sÃ©parÃ©es, nous utilisons OLD data fusionnÃ©es.

**Impact** : Gradients HV faibles â†’ Watershed ne peut pas sÃ©parer.

**Statut** : âœ… **CONFIRMÃ‰** (Ã‰tape 2)

### HypothÃ¨se #2 : SmoothL1Loss Trop Conservatif

**ThÃ©orie** : SmoothL1Loss pÃ©nalise moins les grandes erreurs â†’ gradients HV plus faibles que MSE.

**Impact** : MÃªme avec donnÃ©es FIXED, gradients HV pourraient Ãªtre insuffisants.

**Statut** : âš ï¸ **Ã€ TESTER**

**Test requis** :
```python
# RÃ©-entraÃ®ner UNE famille avec MSE au lieu de SmoothL1Loss
# Comparer HV MSE et AJI
```

### HypothÃ¨se #3 : Sobel vs DiffÃ©rences Finies

**ThÃ©orie** : Sobel 5Ã—5 dÃ©tecte mieux les frontiÃ¨res que diffÃ©rences finies brutes.

**Impact** : Gradient loss moins efficace pour forcer variations spatiales.

**Statut** : âš ï¸ **Ã€ TESTER**

**Test requis** :
```python
# ImplÃ©menter Sobel 5Ã—5 comme HoVer-Net
# Comparer convergence HV MSE
```

### HypothÃ¨se #4 : Skip Connections Manquantes

**ThÃ©orie** : Skip connections aident Ã  prÃ©server dÃ©tails haute rÃ©solution.

**Impact** : DÃ©codeur perd informations fines (frontiÃ¨res cellulaires).

**Statut** : âš ï¸ **POSSIBLE** (mais backbone 44Ã— plus gros devrait compenser)

---

## ğŸ”¬ TESTS RECOMMANDÃ‰S (Par Ordre de PrioritÃ©)

### PrioritÃ© 1 : RÃ©gÃ©nÃ©rer DonnÃ©es FIXED (Ã‰tape 2) â† **CRITIQUE**

**Effort** : 10h calcul
**Gain estimÃ©** : AJI 0.09 â†’ 0.60-0.70

**Justification** : Ã‰tape 2 a prouvÃ© que c'est la cause racine.

### PrioritÃ© 2 : Tester MSE vs SmoothL1Loss

**Effort** : 2h calcul (1 famille)
**Gain estimÃ©** : Si confirmÃ©, AJI +10-20%

**MÃ©thode** :
```bash
# EntraÃ®ner Glandular avec MSE
python scripts/training/train_hovernet_family.py \
    --family glandular \
    --loss_type mse \
    --epochs 50

# Comparer HV MSE et AJI
```

### PrioritÃ© 3 : ImplÃ©menter Sobel 5Ã—5

**Effort** : 1h dev + 2h calcul
**Gain estimÃ©** : Si confirmÃ©, AJI +5-10%

**MÃ©thode** :
```python
# Modifier gradient_loss() pour utiliser Sobel 5Ã—5
def sobel_gradient_loss(pred, target, mask):
    kernel = get_sobel_kernel_5x5()
    pred_grad = F.conv2d(pred, kernel, padding=2)
    target_grad = F.conv2d(target, kernel, padding=2)
    # ... reste identique
```

---

## âœ… DÃ‰CISION RECOMMANDÃ‰E

### Approche SÃ©quentielle

**Ã‰tape A** : RÃ©gÃ©nÃ©rer donnÃ©es FIXED (PrioritÃ© 1)
- Utiliser `prepare_family_data_FIXED.py`
- RÃ©-entraÃ®ner les 5 familles
- **VÃ©rifier AJI** â†’ Si > 0.60, problÃ¨me rÃ©solu âœ…

**Ã‰tape B** : SI AJI < 0.60 aprÃ¨s FIXED data
- Tester MSE vs SmoothL1Loss (PrioritÃ© 2)
- ImplÃ©menter Sobel 5Ã—5 (PrioritÃ© 3)

### Justification

1. **Ã‰tape 2 a identifiÃ© la cause racine** : DonnÃ©es OLD fusionnÃ©es
2. **RÃ©gÃ©nÃ©rer FIXED est obligatoire** de toute faÃ§on
3. **Tester loss avant rÃ©gÃ©nÃ©ration = perte de temps** si les donnÃ©es sont le vrai problÃ¨me

---

## ğŸ“ Ã‰tat du Plan

- [x] **Ã‰tape 1** : VÃ©rifier donnÃ©es utilisÃ©es â†’ **COMPLÃ‰TÃ‰**
- [x] **Ã‰tape 2** : Comparer preprocessing HoVer-Net â†’ **COMPLÃ‰TÃ‰**
- [x] **Ã‰tape 3** : Comparer architecture/loss â†’ **COMPLÃ‰TÃ‰** âœ…
- [ ] **Ã‰tape 4** : Comparer watershed
- [ ] **Ã‰tape 5** : Tester modÃ¨le officiel

**Prochaine action** : Ã‰tape 4 (Watershed) OU dÃ©cision de rÃ©gÃ©nÃ©rer donnÃ©es FIXED
